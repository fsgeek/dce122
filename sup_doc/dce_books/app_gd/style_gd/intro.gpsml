...\" @OSF_COPYRIGHT@
...\" COPYRIGHT NOTICE
...\" Copyright (c) 1990, 1991, 1992, 1993, 1994 Open Software Foundation, Inc.
...\" ALL RIGHTS RESERVED (DCE).  See the file named COPYRIGHT.DCE for
...\" the full copyright text.
...\" 
...\" 
...\" HISTORY
...\" $Log: intro.gpsml,v $
...\" Revision 1.1.4.1  1996/03/21  17:06:30  wardr
...\" 	{edit R1.2.1}
...\" 	Release Edits
...\" 	[1996/03/21  17:05:40  wardr]
...\"
...\" Revision 1.1.2.27  1995/06/27  17:04:11  buckler
...\" 	1.1 edits and Prentice Hall reformat
...\" 	[1995/06/27  17:02:48  buckler]
...\" 
...\" 	More 1.1 edits.
...\" 	[1995/06/23  13:35:02  buckler]
...\" 
...\" Revision 1.1.2.26  1995/06/19  13:16:48  rcb
...\" 	edited 1.1 version, PRENTICE HALL reformat
...\" 	[1995/06/19  13:15:57  rcb]
...\" 
...\" Revision 1.1.2.25  1994/11/15  20:47:59  neilson
...\" 	Converted book title references to macro form.
...\" 	[1994/11/15  18:58:05  neilson]
...\" 
...\" Revision 1.1.2.24  1994/11/15  16:22:47  weir
...\" 	Indexing added
...\" 	[1994/11/15  16:22:04  weir]
...\" 
...\" Revision 1.1.2.23  1994/10/25  14:10:53  jshirley
...\" 	{def,9830,R1.1} Added dced documentation (dce_server API).
...\" 	[1994/10/25  14:10:30  jshirley]
...\" 
...\" Revision 1.1.2.22  1994/10/21  16:53:17  weir
...\" 	Still more cross-references
...\" 	[1994/10/21  16:52:53  weir]
...\" 
...\" Revision 1.1.2.21  1994/10/20  20:56:19  weir
...\" 	Fixed a few typos
...\" 	[1994/10/20  20:55:50  weir]
...\" 
...\" Revision 1.1.2.20  1994/10/20  20:18:09  weir
...\" 	Corrected some cross-references
...\" 	[1994/10/20  20:17:30  weir]
...\" 
...\" Revision 1.1.2.19  1994/10/19  22:47:40  jshirley
...\" 	Fixed dce_server_register_data_t in Register the Server section
...\" 	[1994/10/19  22:47:17  jshirley]
...\" 
...\" Revision 1.1.2.18  1994/10/19  20:48:14  weir
...\" 	Review comments
...\" 	[1994/10/19  20:47:22  weir]
...\" 
...\" Revision 1.1.2.17  1994/10/19  16:02:48  weir
...\" 	Review comments and edits
...\" 	[1994/10/19  16:02:01  weir]
...\" 
...\" Revision 1.1.2.16  1994/09/30  17:05:51  zahn
...\" 	Made final updates to IDL sections in
...\" 	this chapter per discussion with J.  Shirley.
...\" 	[1994/09/30  17:05:36  zahn]
...\" 
...\" Revision 1.1.2.15  1994/09/28  20:58:08  weir
...\" 	Updates
...\" 	[1994/09/28  20:57:30  weir]
...\" 
...\" Revision 1.1.2.14  1994/09/28  20:21:06  neilson
...\" 	CR 10129 - additional material, finished.
...\" 	[1994/09/28  20:20:26  neilson]
...\" 
...\" Revision 1.1.2.13  1994/09/28  15:10:35  weir
...\" 	Updates to first sections
...\" 	[1994/09/28  15:09:58  weir]
...\" 
...\" Revision 1.1.2.12  1994/09/27  19:01:12  neilson
...\" 	CR 10129 - additional material.  Not completed yet.
...\" 	[1994/09/27  19:00:33  neilson]
...\" 
...\" Revision 1.1.2.11  1994/09/26  13:00:38  jshirley
...\" 	Made updates to the Server DCE Host Daemon section and the
...\" 	Server Initialization section with respect to dced and its API.
...\" 	[1994/09/26  12:59:26  jshirley]
...\" 
...\" Revision 1.1.2.10  1994/09/23  22:07:09  neilson
...\" 	CR 10129 - additional material.  Not completed yet.
...\" 	[1994/09/23  22:06:33  neilson]
...\" 
...\" Revision 1.1.2.9  1994/09/20  17:43:32  zahn
...\" 	Added missing "end comment" command.
...\" 	[1994/09/20  17:43:17  zahn]
...\" 
...\" Revision 1.1.2.8  1994/09/19  15:26:06  zahn
...\" 	Added information about interface definition
...\" 	development steps from app_gd/intro/CHAP1/*
...\" 	as planned.
...\" 
...\" 	Revised sections on UUID generator and IDL, IDL
...\" 	compiler copied to this file from app_gd/rpc/2_components.gpsml
...\" 	(old file name) to conform to IDL info from old chapter 1.
...\" 	Moved sections around to improve flow and for better
...\" 	organization and presentation of concepts.  Removed references
...\" 	to timop and some obsolete features in IDL sections.
...\" 	Removed references to old steps (A5/Section xxx).
...\" 	Commented out old calendar example.  Commented out
...\" 	2 sections that I think should be moved to RPC
...\" 	section of app_gd and made notes in the source
...\" 	about this.
...\" 	[1994/09/19  15:25:46  zahn]
...\" 
...\" Revision 1.1.2.7  1994/08/16  18:26:19  jshirley
...\" 	Changed section on DCE Host Daemon.  Removed extra '>'s and fixed
...\" 	book reference from *(Ac to \*(Ac.
...\" 	[1994/08/16  18:25:58  jshirley]
...\" 
...\" Revision 1.1.2.6  1994/08/15  19:06:24  neilson
...\" 	Added DCE Host Daemon material for jshirley.
...\" 	[1994/08/15  18:27:38  neilson]
...\" 
...\" 	Added sections from app_gd/intro/CHAP1, per plan.
...\" 	[1994/08/15  18:12:43  neilson]
...\" 
...\" Revision 1.1.2.5  1994/08/12  19:23:22  jshirley
...\" 	Updated Servier Initialization sections.  Added more for Serviceability
...\" 	and Server Termination.
...\" 	[1994/08/12  19:23:06  jshirley]
...\" 
...\" Revision 1.1.2.4  1994/08/11  21:08:35  jshirley
...\" 	Inserted and updated Server Initialization sections, first cut.
...\" 	[1994/08/11  21:08:12  jshirley]
...\" 
...\" Revision 1.1.2.3  1994/07/07  15:11:58  jshirley
...\" 	Added the new heading structure.
...\" 	[1994/07/07  15:11:26  jshirley]
...\" 
...\" Revision 1.1.2.2  1994/06/13  18:22:36  devobj
...\" 	cr10872 - fix copyright
...\" 	[1994/06/13  18:19:59  devobj]
...\" 
...\" Revision 1.1.2.1  1994/03/11  23:05:06  rom
...\" 	{enh, 10129, R1.1}
...\" 	Initial split of App Dev Guide into three books and creation of
...\" 	Intro and Style Guide.
...\" 	[1994/03/11  23:01:53  rom]
...\" 
...\" $EndLog$
...\"
...\" ----------------------------------------------------------------------
.H 1 "Introduction to DCE Application Programming"
...\" ----------------------------------------------------------------------
.P
The majority of this first chapter consists of a fairly detailed overview of
each of the separate steps that a developer usually has to perform (or have
the application perform) from the beginning of coding to the end of execution
of a successful DCE application.
.P
Before you begin a serious study of the contents of any part of this guide,
or indeed of any other book in the DCE documentation set, you should read
the \*(In.  It contains clear and comprehensive
overviews, with illustrations, of all the DCE components and of the
integrated DCE as a whole; many concepts and details are explained there
that are necessary to a full understanding of what is described here.
.P
If you do not find information about topics you are interested in either
in this guide or in the \*(Dr, 
you should also look in the \*(Ag and the
\*(Ar.  For example, the DCE Cell Directory Service (CDS)
is not accessed directly by applications (except through DCE RPC NSI or
through XDS) so most of the discussion of CDS as a separate component is
found in the administration documentation.  Although the DCE Security Service
is documented in the development books, certain aspects of it important to
application developers (for example, adding new principals to the security
registry database) are found only in the administration books.
.P
Several key methods underlie the successful development of DCE
applications programs.  These methods, explained in this chapter, are
as follows:
.ML
.LI
A set of tools for distinguishing the component applications programs,
for describing how they work together, and for manipulating and
managing DCE components both locally and remotely.
.LI
A method for establishing the interface between the component parts.
.LI
Methods to install and register a server, so that clients can use it.
.LI
Methods to set up clients so they can use servers.
.LE
...\" ----------------------------------------------------------------------
.H 2 "Development Overview"
...\" ----------------------------------------------------------------------
.P
Most of the effort of developing a DCE application usually lies in the
familiar steps of planning, writing and compiling the necessary C code,
linking the result with the DCE library and other modules, and executing it
(perhaps repeatedly).  However, there is an important preliminary task which
must be performed before you write any other code.  Before you can implement
the application's client and server, you must write and compile an interface
definition file in which you define the application's client/server interface.
.P
This interface, defined in the DCE Interface Definition Language (IDL),
consists of a set of \*Eprototypes\*O for the remote procedure
calls your client(s) will be requesting your server(s) to execute.  After
you have written this file, you compile it with the DCE IDL compiler.  The final
output of IDL compilation is a pair of object files, one for the server
.iX "IDL"
module and one for the client, which you must later link with the compiled
output of your server and client implementation code.  These two IDL output
files contain the server and client stub code, where all the details of remote
execution, data transfer, and so on, are managed (in conjunction with the
DCE runtime).
.P
The IDL compiler also generates a header file for inclusion in the server
and client source files.  It contains all the declarations
that result from the IDL file definitions.  Among these are, for example,
the interface specification identifier, which will be used at runtime to
describe the interface being defined in the programs.
.iX "interface"
.P
Once you have linked the stub files (and the DCE library) to their respective
client and server modules, the IDL-generated stubs make the client and server
.iX "stubs"
seem to communicate directly through the operation signatures you defined in the
original \*L.idl\*O file, although in actuality client/server communications
pass back and forth through layers of stub and runtime processing, which are
necessary to send and receive the data over the network.  
Figure 1-1 illustrates
how the combination of IDL (by means of the stubs it generates) and the RPC
runtime routines shields both client and server from the details of network
communications.
.P
...\" ------------------------------------
...\" ----------------------------------------------------------------------
...\" Figure figfirst: showing the effect of IDL on the "look" of RPC
...\" ----------------------------------------------------------------------
...\" ------------------------------------
...\" pix/figfirst.pic
.ne 3.6i
.FG "The Combined Effect of IDL and the RPC Runtime"
.sp .5
.PS
.in +.4i
scale = 1.2
.ps 12
box at 1.500i,5.625i wid 1.333i ht 0.750i;
box at 4.333i,5.625i same;
box at 1.500i,4.833i wid 1.333i ht 0.833i;
box at 4.333i,4.833i same;
box at 1.500i,3.833i wid 1.333i ht 0.667i;
box at 4.333i,3.833i same;
line from 0.833i,4.958i to 2.167i,4.958i;
line from 3.667i,4.958i to 5.000i,4.958i;
"\fR\s8RPC\s0\fP" at 1.458i,5.167i;
"\fR\s8interface\s0\fP" at 1.458i,5.021i;
"\fR\s8RPC\s0\fP" at 4.292i,5.167i;
"\fR\s8interface\s0\fP" at 4.292i,5.021i;
"\fR\s8Client\s0\fP" at 1.458i,4.708i;
"\fR\s8stub\s0\fP" at 1.458i,4.562i;
"\fR\s8Server\s0\fP" at 4.333i,4.708i;
"\fR\s8stub\s0\fP" at 4.333i,4.562i;
"\fR\s8RPC\s0\fP" at 1.500i,3.917i;
"\fR\s8runtime\s0\fP" at 1.500i,3.771i;
"\fR\s8RPC\s0\fP" at 4.292i,3.896i;
"\fR\s8runtime\s0\fP" at 4.292i,3.750i;
"\fR\s8Calling\s0\fP" at 1.458i,5.833i;
"\fR\s8code\s0\fP" at 1.458i,5.688i;
"\fR\s8Remote\s0\fP" at 4.292i,5.833i;
"\fR\s8procedure\s0\fP" at 4.292i,5.688i;
line -> dotted from 3.833i,5.417i to 3.833i,5.167i;
line -> dotted from 3.833i,4.167i to 3.833i,3.500i;
line -> from 1.000i,3.500i to 1.667i,3.000i;
line -> to 4.167i,3.000i;
line -> to 4.833i,3.500i;
"\fR\s8RPC Client\s0\fP" at 1.448i,6.177i;
"\fR\s8RPC Server\s0\fP" at 4.302i,6.156i;
"\fR\s8return\s0\fP" at 2.896i,3.354i;
"\fR\s8data\s0\fP" at 2.875i,3.177i;
"\fR\s8input arguments\s0\fP" at 2.760i,2.875i;
line -> dashed from 2.250i,5.750i to 3.583i,5.750i;
line -> dashed from 3.583i,5.583i to 2.250i,5.583i;
"\fR\s8apparent path\s0\fP" at 2.854i,5.854i;
"\fR\s8of data\s0\fP" at 2.865i,5.677i;
"\fR\s8due to IDL\s0\fP" at 2.865i,5.479i;
"\fR\s8Actual path of data\s0\fP" at 2.802i,2.646i;
"\fR\s8and RPC\s0\fP" at 2.896i,5.333i;
line -> from 1.000i,4.427i to 1.000i,4.167i;
line -> dotted to 1.000i,3.500i;
line -> dotted from 0.990i,4.958i to 1.000i,4.427i;
line -> dotted from 0.990i,5.396i to 0.990i,5.260i;
line -> dotted from 2.000i,3.500i to 2.000i,4.167i;
line -> dotted from 4.833i,3.500i to 4.833i,4.167i;
line -> dotted from 4.833i,4.427i to 4.833i,4.969i;
line -> dotted from 4.823i,5.250i to 4.823i,5.417i;
line -> dotted from 3.823i,4.969i to 3.823i,4.427i;
line -> dotted from 2.000i,4.427i to 2.000i,4.958i;
line -> dotted from 1.990i,5.250i to 1.979i,5.365i;
line -> from 2.000i,4.167i to 2.000i,4.427i;
line -> from 1.990i,4.969i to 1.990i,5.271i;
line -> from 0.990i,5.260i to 0.990i,4.958i;
line -> from 4.823i,4.969i to 4.823i,5.260i;
line -> from 3.823i,5.156i to 3.823i,4.958i;
line -> from 4.833i,4.167i to 4.833i,4.427i;
line -> from 3.823i,4.427i to 3.823i,4.177i;
line -> from 3.833i,3.500i to 3.562i,3.281i;
line -> to 2.281i,3.281i;
line -> to 2.000i,3.500i;
.in -.4i
.sp .5
.PE
.P
Once the work of defining an interface has been completed, the task of
implementing the interface (that is, coding the operations, along with
the rest of the necessary initialization and management routines, in some
programming language) begins.  The rest of this chapter consists of detailed
explanations of the DCE application development steps from start to finish.
For a practical example of the result of such a process, refer to the code
for the DCE sample application, which is reprinted in full in the appendix
of this book.
.P
Each of the DCE components (with the exception of CDS, which is accessed
through the RPC NS API) is discussed in depth in separate parts of
this guide.  You should also refer often to the
\*(Dr, which contains reference pages for all of the
DCE library routines mentioned in the following sections.
...\" ----------------------------------------------------------------------
.H 2 "Overview of DCE Application Development Steps"
...\" ----------------------------------------------------------------------
.P
The rest of this chapter consists of a step-by-step checklist of every single
one of the decisions that a programmer must make in developing a typical DCE
application.  Each set of decisions or choices is combined into one step.  The
combination of all these steps takes you from the initial coding stages into
and through the normal course of execution of the application itself.  The
underlying intention of this arrangement is to give you a useful mental model
of the overall code development process.
...\" .P
...\" Figure 1-2 summarizes the organization of the steps.
...\" ----------------------------------------------------------------------
...\" The 5 basic movements illustrated:
...\" 			      IDL
...\" 			   /       \
...\" 		         /   [1-5]   \
...\" 		       v               v
...\" 		    CLIENT	     SERVER
...\" 		      |		        | Set-up     [6-17]
...\" 		      |		        | Listen
...\" 		      v  .  .  .  .  .  v
...\" [18-20]    Bind |
...\" 	       Invoke |
...\" 		      v  .  .  .  .  .  |<--------^
...\" 				        | Service |  [21-27]
...\" 				        | Listen  |
...\" 		      |  .  .  .  .  .  v--------->
...\" [28-29]  Return |
...\" 	     Continue |
...\" 		      v
.P
The four basic phases of DCE application development are as follows:
...\" NEW TOTAL == 21
.VL .5i
.LI "\*LA.\*O"
\*LCLIENT and SERVER:\*O Define the IDL interface [Steps \*LA1\*O to
\*LA4\*O]
.LI "\*LB.\*O"
\*LSERVER:\*O Set up and listen [Steps \*LB1\*O to \*LB8\*O]
.LI "\*LC.\*O"
\*LCLIENT:\*O Bind to and invoke the server [Steps \*LC1\*O to \*LC4\*O]
.LI "\*LD.\*O"
\*LSERVER:\*O Service request(s) [Steps \*LD1\*O to \*LD5\*O]
.LE
.P
Following is an overview list of all 21 steps, separated into the four main
phases previously described.  Each step's numeral is followed by a
\*L/\*O (slash) and the terms \*LClient\*O and/or \*LServer\*O to
indicate whether it applies to the application's server or client, or both.
.VL .25i
.LI "\*LA.\*O"
\*LCLIENT and SERVER:\*O\ \ Define the IDL interface
.VL 2i
.LI "\*LA1/Client and Server:\*O"
Generate the interface UUID
.iX "interface" "UUID"
.LI "\*LA2/Client and Server:\*O"
Write the \*L.idl\*O file
.LI "\*LA3/Client and Server:\*O"
Write the \*L.acf\*O file (optional)
.iX "attribute configuration file"
.LI "\*LA4/Client and Server:\*O"
Process the files with the IDL compiler
.iX "IDL" "compiler"
.LE
.sp 
.LI "\*LB.\*O"
\*LSERVER:\*O\ \ Initialization
.VL 2i
.LI "\*LB1/Server:\*O"
Set up for serviceability
.iX "serviceability"
.LI "\*LB2/Server:\*O"
Set up the server's objects
.LI "\*LB3/Server:\*O"
Set up security
.LI "\*LB4/Server:\*O"
Define the manager entry point vectors
.LI "\*LB5/Server:\*O"
Register the server
.LI "\*LB6/Server:\*O"
Specify multithreadedness
.iX "multithreadedness"
.LI "\*LB7/Server:\*O"
Listen for incoming service requests
.LI "\*LB8/Server:\*O"
Clean up when server terminates
.LE
.sp
.LI "\*LC.\*O"
\*LCLIENT:\*O\ \ Bind to and invoke the server
.VL 2i
.LI "\*LC1/Client:\*O"
Multithreaded client design
.LI "\*LC2/Client:\*O"
Import the binding information from the namespace (CDS)
.LI "\*LC3/Client:\*O"
Annotate the binding handle for security
.LI "\*LC4/Client:\*O"
Invoke an RPC interface operation
.LE
.sp
.LI "\*LD.\*O"
\*LSERVER:\*O\ \ Service the request
.VL 2i
.LI "\*LD1/Server:\*O"
Get the client's credentials
.LI "\*LD2/Server:\*O"
Get the object's access control list
.LI "\*LD3/Server:\*O"
Make the authorization decision
.LI "\*LD4/Server:\*O"
Service the request
.LI "\*LD5/Server:\*O"
Return the results to the client and resume listening
.LE
.LE
...\" ----------------------------------------------------------------------
.H 2 "DCE Application Development Tools"
...\" ----------------------------------------------------------------------
.P
The following DCE tools allow developers to define and manage a set of
programs intended to run in a DCE environment.
.ML
.LI
Unique identification
.P
Because DCE involves the interaction of many distinct programs,
operating on several processors that may be quite remote from each
other, every entity (such as programs, interface definitions, and so
forth) needs a unique identifier.  This identifier is provided by the
UUID generator.
.iX "\*Luuidgen\*O"
.LI
Interface definition language
.iX "interface definition language (IDL)"
.P
Applications programs that are to work within DCE can be written in
any of several programming languages.  The two halves of a
client/server pair need not be in the same language.  In order to
permit this flexibility, each application's client/server interface
uses a common language, called IDL.  It is supported by an IDL Compiler.
.LI
Attribute configuration language
.iX "attribute configuration language"
.P
To allow developers to control the interface between local
applications code and the RPC interface, there is an optional
attribute configuration language supported by the IDL compiler.
.LI
Remote DCE management
.P
A host daemon (\*Ldced\*O) and a control program (\*Ldcecp\*O) provide
capabilities for management of a host and its servers.
.LE
...\" ----------------------------------------------------------------------
.H 3 "The DCE UUID Generator"
...\" ----------------------------------------------------------------------
.P
The 
.iX "UUID" "generator"
UUID generator \*Luuidgen\*O is an interactive utility
that creates UUIDs (universal unique identifiers). 
A UUID is a hexadecimal number that contains information that
makes it unique from all other UUIDs.  Applications use UUIDs to identify
many kinds of entities, including interface definitions.  Consequently,
application developers typically use the UUID generator when they
are creating their interface definition files.
.P
To run the UUID generator, issue the \*Luuidgen\*O command.
This command offers several options, including an option to
create a template interface definition file (an
\*L.idl\*O file) containing a newly generated interface UUID.
For complete information about generating UUIDs and template
interface definition files, see the \*(Dk.  See this volume also
for a discussion of UUIDs and their use in DCE applications.  Refer to 
the \*Luuidgen(1rpc)\*O reference page for a description of the \*Luuidgen\*O
utility and its options.
...\" ----------------------------------------------------------------------
.H 3 "DCE Interface Definition Language"
...\" ----------------------------------------------------------------------
.P
As was mentioned earlier in this chapter, developing a DCE application involves
writing and compiling an
...\" .gL "interface definition"
.iX "RPC" "interface" "definition"
interface definition, which defines the application's client/server interface.
Application developers use IDL to write
the interface definition.  IDL is a high-level descriptive language whose syntax
resembles that of ANSI C.  IDL is a declarative, not a procedural, language.  Some
of the important attributes specified with IDL are the following:
.ML
.LI
For interfaces
.VL 1.5i
.LI "\*Luuid\*O"
Specifies the interface's UUID.  
.LI "\*Lversion\*O"
Specifies the interface major and minor version number. 
.LE
.LI
For parameters
.VL 1.5i
.LI "\*Lin\*O"
.iX "parameters" "\*Lin\*O"
Signifies a parameter whose value is passed from the client to the
server.
.LI "\*Lout\*O"
.iX "parameters" "\*Lout\*O"
Signifies a parameter whose value is passed from the server to the
client.
.LE
.LI
For data types
.VL 1.5i
.LI "\*Lhandle\*O"
Specifies a customized binding handle.  Chapter 4 discusses binding
handles and binding methods in more detail.
.iX "handle" "binding"
.LI "\*Lcontext_handle\*O"
.iX "handle" "context"
Specifies a context handle, which is a pointer to state
information that the server uses and which is maintained across RPC
invocations.  An example of a context handle is a file pointer.
For more information about context handles,
see the \*(Dk. 
.LE
.LE
.P
IDL's operation attributes include specifiers for execution semantics:
.iX "execution semantics"
whether the operation can be safely executed more than once,
whether a response is expected, and so on.  The default is that operations
can be executed at-most-once.  Parameters (the arguments
supplied by the client when it makes the remote call) can be specified
as input to the server, output to the client, or both.
See the \*(Dk for a complete description of IDL syntax and usage.
...\" ----------------------------------------------------------------------
.H 3 "The DCE IDL Compiler"
...\" ----------------------------------------------------------------------
.P
The DCE IDL compiler \*Lidl\*O processes interface
.iX "IDL" "compiler"
definitions written in IDL and generates header files and stub object code.
(The compiler generates source code for the stubs in ANSI C.) The
code generated from an interface definition by the compiler includes client
and server stubs.
.P
The compiler also generates a data structure called 
.iX "RPC" "interface" "specification" 
the interface specification, 
which contains identifying and descriptive information about
the compiled interface, and creates a companion global variable, 
...\" .gL "interface handle"
.iX "RPC" "interface" "handle" 
.iX "interface" "handle" "RPC"
the interface handle, which 
is a reference to the interface specification. 
Each header file generated by the IDL compiler contains the reference 
the application code needs to access the interface handle.  The interface handle
allows the 
application code to refer to the interface specification in calls to the RPC
.iX "interface specification"
runtime.  Runtime operations obtain required information about the interface,
such as its UUID and version numbers, directly from the interface specification. 
.P
You run the IDL compiler by issuing the \*Lidl\*O command. See the 
\*Lidl(1rpc)\*O reference page for a description of the \*Lidl\*O command
and its options.
...\" ----------------------------------------------------------------------
.H 3 "The Attribute Configuration File"
...\" ----------------------------------------------------------------------
.P
Application developers can use an optional attribute configuration
file to tailor how an RPC interface appears to
local application code and how the local application code
interacts with the RPC interface.
The 
.iX "attribute configuration file"
attribute configuration file is written
in the attribute configuration language, which is a companion language
to IDL.  When the IDL compiler is invoked, it searches for an attribute
configuration file in addition to processing the interface definition file.
.P
An attribute configuration file
modifies how the IDL compiler interprets an interface definition.
For example, an attribute configuration
file can specify a subset of operations declarations
for a client stub so that the client stub contains declarations for
only the operations that the client application code needs for its
remote procedure calls.  Limiting the client's access to the
remote procedures offered by servers reduces the size of the client stub.
Another action you can control with an attribute configuration
file is defining how a client
establishes a binding with a server that implements the called
interface.
.P
For complete information on the set of attribute configuration
file attributes, see the \*(Dk.
...\" ----------------------------------------------------------------------
.H 3 "The DCE Host Daemon"
...\" ----------------------------------------------------------------------
.iX "DCE host daemon"
.iX "daemon" "DCE host"
.P
Each DCE host runs a DCE host daemon (\*Ldced\*O) to provide remote DCE
management services for a host and its servers.  The \*Ldced\*O provides
.iX "\*Ldced\*O"
remote management of DCE-related host and server data, it provides remote
control of a host's servers, and it maintains host-specific state for DCE
such as the host's login identity.
From the server's perspective, \*Ldced\*O is a central point where
all servers can consistently inform their host about themselves.
From the host's perspective, \*Ldced\*O gives clients, management
applications, and DCE administrators (via \*Ldcecp\*O) 
.iX "\*Ldcecp\*O"
a focal point from which to find out about (and even control) servers.
.P
The most important feature of the \*Ldced\*O is that it provides the 
.iX "endpoint" "map"
endpoint mapper service.  
This service maintains the host's local endpoint map for
local RPC servers and looks up endpoints for RPC clients. 
.iX "endpoint" "RPC"
An endpoint is the address of a specific instance of a server that is
executing in a particular address space on a given host.
.iX "RPC" "server instances"
.iX "instance, server"
Each endpoint can be used on a host by only one server at a time.
.iX "endpoint" "map"
The endpoint map is the system-specific database on each host, 
in which servers register their endpoints and associated addressing
information (information about communication protocols, objects, and so on).
A server registers separate endpoints for each of its RPC interfaces
and any objects the server offers with the interface.
.P
If a client makes a remote procedure call to a host without providing an
endpoint, the \*Ldced\*O searches its endpoint map for the
endpoint of a compatible server.   Upon finding a suitable endpoint, 
the endpoint mapper service (depending on the protocols used) 
forwards the call to that endpoint or
returns the endpoint to the client's runtime, 
which sends the call to the server at that endpoint.
.P
Other remote services of \*Ldced\*O include host data management, 
.iX "\*Ldced\*O" "host data management"
server control, security validation, and key table management.
.iX "\*Ldced\*O" "key table management"
.iX "\*Ldced\*O" "security validation"
.iX "\*Ldced\*O" "server control"
These are described in detail in the \*(Dk.
...\" ----------------------------------------------------------------------
.H 3 "The DCE API"
...\" ----------------------------------------------------------------------
.P
DCE provides a wide range of application programming interface
routines.  All of the following are available:
.ML
.LI
A set of general DCE routines routines provide the means for
configuration, handling messages, using the backing store, and managing
the DCE daemon, as well as other purposes. 
.LI
The DCE thread routines provide thread control, including thread creation,
conditional waiting, priorities, and locks.
.LI
The DCE remote procedure call routines provide tools to
establish and manage servers, and also include utilities for use by
clients and by servers.
.LI
The DCE directory service routines are a set of X/OPEN directory
service routines that provide access to the Global Directory Service
(GDS) and CDS. 
.LI
The DCE distributed time service routines obtain timestamps, translate
between timestamp formats, and perform time calculations.  The
routines can be used from server or clerk systems to determine event
sequencing, duration, and scheduling.
.LI
The DCE security service routines allow developers to create
network services with complete access to all the authentication and
authorization capabilities of DCE Security Service and facilities.
.LE
...\" ----------------------------------------------------------------------
.H 3 "The DCE Control Program"
...\" ----------------------------------------------------------------------
.P
Although the DCE control program, \*Ldcecp\*O, is intended as an
.iX "\*Ldcecp\*O"
administrator's tool, developers will find it invaluable for examining
and modifing many aspects of the DCE environment.  It can be used in
constructing installation scripts, as in the following examples:
.ML
.LI
For exporting binding information to a namespace, instead of putting C
.iX "binding" "exporting"
code in your application to call the NSI routines, \*Lrpc_ns_\*V*\*L(\|)\*O,
.iX "NSI routines"
you could write a \*Ldcecp\*O script that calls \*Lrpcentry export\*O
.iX "\*Lrpcentry export\*O"
and its related commands.
.LI
For installation, you might need to create a principal
name and/or set an access control list (ACL) 
on it.  Instead of writing C code in
.iX "ACL"
your application's initialization section to call \*Lsec_rgy_pgo_\*V*\*L(\|)\*O
and \*Lsec_acl_\*V*\*L(\|)\*O, you could ship a \*Ldcecp\*O script that
includes the following:
.oS
principal create ...
acl mod /.:/sec/principal/...
.oE
.LI
It is recommended that you have \*Ldced\*O start your application by
using server configuration information.  It is generally better to do
.iX "server" "configuration information"
this by writing a \*Ldcecp\*O script that sets up the server
configuration information (the arguments to start the executable)
rather than doing it with C code that calls the
\*Ldced_server_create(\)\*O API.
.LE
.P
In general, \*Ldcecp\*O scripts for server configuration allow better
.iX "\*Ldcecp\*O" "scripts"
flexibility than embedded C code.  Furthermore, unlike embedded code,
the script does not persist after configuration is done.
.P
The DCE control program can also be useful for debugging, as the
following examples show:
.ML
.LI
You can check exported infoformation in the namespace with
\*Lrpcentry show\*O or \*Lrpcgroup, rpcprofile show\*O.
.iX "\*Ldcecp\*O" "\*Lrpcprofile show\*O"
.iX "\*Ldcecp\*O" "\*Lrpcgroup show\*O"
.iX "\*Ldcecp\*O" "\*Lrpcentry show\*O"
.LI
You can use \*Lserver ping\*O to see if your server is
.iX "\*Ldcecp\*O" "\*Lserver ping\*O"
running and receiving requests.
.LI
If your server was set up to be started by \*Ldced\*O, you can start
it by using the \*Lserver start\*O command and can 
.iX "\*Ldcecp\*O" "\*Lserver start\*O"
view the startup parameters by using \*Lserver show -executing\*O.
.iX "\*Ldcecp\*O" "\*Lserver show -executing\*O"
.LE
...\" ----------------------------------------------------------------------
.H 2 "The Interface Definition"
...\" ----------------------------------------------------------------------
.P
Once you have designed your DCE application and have decided
which procedures are needed, and which will be remote procedures,
the next step in developing the application is to write one or
more interface definitions that describe the remote procedures
your application's clients will be requesting your application's
servers to run.
.P
.ne 4
To create an interface definition, use the following steps:
.AL
.LI
Generate an interface UUID and a skeleton \*L.idl\*O file with
the \*Luuidgen\*O utility.
.iX "\*Luuidgen\*O"
.LI
Write your interface operation declarations in IDL, using
the skeleton \*L.idl\*O file you generated with \*Luuidgen\*O
as a base.
.LI
Write the attribute configuration file.  This is an optional
.iX "attribute configuration file"
step that you take only if you want to alter the IDL output
in various ways.
.LI
Compile the completed interface definition file with the IDL compiler.
.LE
.P
The following sections describe these steps in more detail.
...\" ----------------------------------------------------------------------
.H 3 "Generating the Interface UUID"
...\" ----------------------------------------------------------------------
.P
Interfaces, like most other objects and entities in DCE, are identified by
associating each one with a 128-bit universal unique identifier
(UUID).  An interface's UUID serves to identify it far and wide throughout
.iX "UUID" "interface" "generating"
.iX "interface" "UUID" "generating"
DCE.  Every interface in a DCE application must have a UUID assigned to it.
.P
When you define a new interface, you must generate a UUID for it.
Consequently, the first step in developing an interface definition is to
run the \*Luuidgen\*O utility to generate a UUID for the interface.
.P
Typically, you run the \*Luuidgen\*O command with the \*L-i\*O option
when generating an interface UUID.  The command line has the following syntax:
.iS
uuidgen -i > \*Vyour_interface_name\*L.idl
.iE
.iX "\*Luuidgen\*O"
.P
where \*Vyour_interface_name\*O is the name you have given your interface,
and \*L.idl\*O is the suffix that all interface definitions use by convention.
The \*Luuidgen\*O utility generates a file named \*Vyour_interface_name\*L.idl\*O,
that contains a skeleton of an interface definition and includes the newly
generated UUID for the interface.  See the \*(Dk for more information about the
contents of this skeleton file.  Refer to the \*Luuidgen(1rpc)\*O reference page
for a complete description of \*Luuidgen\*O.
...\" ----------------------------------------------------------------------
.H 3 "Writing the Interface Definition File"
...\" ----------------------------------------------------------------------
.P
The \*L.idl\*O file is where the set of remote operations that
.iX "IDL" "file"
constitute the interface are defined.  The \*L.idl\*O file defines
and characterizes the interfaces to the server implementations
of the remote operations (which you write, in C source code,
then compile and link to the stub code output by the IDL compiler).
Thus, an \*L.idl\*O file's contents is like a set of
\*Enetwork prototypes\*O for a set of operations.  The IDL definitions
in the interface definition file determine not only how the
operations ``look'' to client and server (that is, the
operations' call signatures, parameter types, and so on), but also what the
data looks like when it is transmitted back and forth between clients and
servers in a distributed application.
.P
An interface definition file consists of the following two basic components: 
.ML
.LI
An interface header 
.PP
.iX "RPC" "interface" "header"
An interface header contains an interface UUID, interface
version numbers, and an interface name.  An
.iX "RPC" "interface" "name"
interface name 
is an easy-to-read local name that is not guaranteed to be 
unique; it is merely a convenience.  It is helpful if the interface name 
reflects the nature or purpose of the interface.
.LI
An interface body 
.PP
.iX "RPC" "interface" "body"
An interface body declares any application-specific data types and
constants, and contains directives for including data types and constants from
other interfaces.  The interface body also contains the operation
declaration of each remote procedure to be accessed through the interface.
An 
.iX "operations" "declaration of"
.iX "RPC" "interface" "operation declaration"
.iX "operations" "IDL"
.iX "IDL" "operations"
operation declaration identifies
the parameters of a procedure in terms of their data types, access method, and
call order, and declares the data type of the return value (if any).
.LE  
.P
The skeletal interface definition produced by the \*Luuidgen\*O utility
provides an interface header that contains the newly generated UUID for
the interface, a version number, and a dummy string \*LINTERFACENAME\*O.
.iX "interface" "version number"
Replace this dummy string with the name of your interface, then
add any additional interface header attributes your application 
requires.  (See the \*(Dk for a complete description of interface
header attributes).
.P
.ne 7
The skeletal interface definition file also provides an interface body,
which consists solely of \*L{\|}\*O, that is, an empty pair of braces.
You fill in the space between the braces with your RPC interface's
import, constant, type, and operation declarations, written in IDL.
The \*(Dk explains this process in more detail.  In addition, the same 
volume for a complete
description of the IDL syntax for specifying import, constant, type, and
operation declarations.
.P
Note that a server can implement more than one interface.
In this case, you define each interface in a separate \*L.idl\*O file
.iX "interface" "multiple definitions"
and compile it separately with the IDL compiler.  You then link the implemented
interface operations in various source code files with the IDL output.
...\" ----------------------------------------------------------------------
.H 3 "Writing the Attribute Configuration File"
...\" ----------------------------------------------------------------------
.P
The attribute configuration file (\*L.acf\*O) is an optional additional
.iX "attribute configuration file"
input file to the IDL compiler, that, if present, affects the IDL
compiler's output in various ways.  The difference between the purpose of
the \*L.idl\*O and an \*L.acf\*O file is that while the \*L.idl\*O file
defines how the network communications between the client and server are handled,
the \*L.acf\*O file, if one is present, affects only the interaction between
the stub code modules and the developer code that they support.  In other words,
changing the contents of an \*L.acf\*O file has no effect on the network
communications between the client and server.
.P
Nevertheless, some of the features offered by an \*L.acf\*O file are very
important, and they cannot be obtained by any other means.  For example,
The \*Lcomm_status\*O attribute configuration
file attribute allows the status code of a
.iX "\*Lcomm_status\*O attribute"
communications failure that occurs in an RPC to be stored as a parameter or
returned as a result, rather than being raised to the caller code as an
exception.  This attribute can only be declared in an \*L.acf\*O file; 
it cannot be declared in an \*L.idl\*O file.
Another very important function of the \*L.acf\*O file is the specification
of a binding method to be used by remote clients of the application.  Three
.iX "binding" "methods"
.iX "binding" "handle"
methods are available, as follows:
.ML
.LI
\*Lauto_handle\*O
.iX "binding" "automatic method"
.iX "binding" "implicit method"
.iX "binding" "explicit method"
.LI
\*Limplicit_handle\*O
.LI
\*Lexplicit_handle\*O (the default)
.LE
.P
.ne 3
These binding methods are described in Chapter 4 of this guide.
The binding method you choose determines how much attention your
server's clients will have to devote to the upkeep of their binding handles.
.P
See the \*(Dk for a description of the attribute configuration
file attributes
.iX "attribute configuration file"
available for use in attribute configuration files.
...\" ----------------------------------------------------------------------
.H 3 "Processing the Files with the IDL Compiler"
...\" ----------------------------------------------------------------------
.P
IDL's input is an \*Vxxx\*L.idl\*O and (optionally) an \*Vxxx\*L.acf\*O
.iX "IDL" "compiler"
file.  Its default output is a header (\*Vxxx\*L.h\*O) file, that contains
definitions and declarations derived from the input for general use in
the development source code, and two stub files, one for the client and
.iX "stubs" "files"
one for the server, which contain runtime code for marshalling and
unmarshalling, message handling, and all the other details of managing
network communications.  The stub files are output as object code
(\*Vxxx\*L_cstub.o\*O and \*Vxxx\*L_sstub.o\*O) suitable for linking with
the developer's compiled code.  The IDL compiler generates C source code
as an intermediate step in the compilation process, and the output of this
step can also be saved in a pair of files (\*Vxxx\*L_cstub.c\*O and
.iX "\*L_cstub.c\*O file"
.iX "\*L_sstub.c\*O file"
\*Vxxx\*L_sstub.c\*O).
.P
In order for a pair of client and server stubs to interoperate, they should
be generated from the same interface definition (\*L.idl\*O) file, but they
do \*Vnot\*O have to be generated with the same attribute configuration file
(\*L.acf\*O).  The compatibility rules for interface version numbers also
.iX "interface" "version number" "compatibility"
apply (see the \*(Dk).
.P
For further information on the IDL compiler, see the \*Lidl(1rpc)\*O
reference page.
...\" ----------------------------------------------------------------------
.H 2 "Server Initialization"
...\" ----------------------------------------------------------------------
.P
Servers must initialize some data and notify various DCE services
.iX "server" "initialization of"
about themselves prior to servicing RPC requests.  At a minimum, 
servers must register with DCE and then go into a wait state listening 
for remote procedure calls. 
In addition to these minimum tasks, your application may first
parse the input arguments,
obtain information about how it was started using \*Ldced\*O API calls,
and establish the proper message tables and locale for internationalization.
.P
DCE applications should be started in such a way that they can be
controlled by \*Ldced\*O.  When the server is installed, the \*Ldcecp
server create\*O operation (or a custom made server management
.iX "\*Ldcecp\*O" "\*Lserver create\*O"
application) is commonly used to establish the server's
configuration with its host \*Ldced\*O.  This configuration data
.iX "\*Ldced\*O" "configuration data for"
includes among other things the program name and its arguments, 
the CDS entry name to use for exporting to the name service, 
and the valid starting methods.
Installing your servers in this way does not compromise their security
because \*Ldced\*O operations are protected with ACLs,
and the major advantages include the following:
.ML
.LI
You do not have write any complex management code for each server
.LI
Your servers are like other DCE servers in that they can
all be managed consistently
.LE
.P
Depending on how the server is configured, the \*Ldced\*O can start
it in the following ways:
.ML
.LI
At boot time when the DCE daemon itself starts
.LI
Explicitly via the \*Ldcecp server start\*O operation (or from another
.iX "\*Ldcecp\*O" "\*Lserver start\*O"
.iX "\*Ldced_server_start(\|)\*O"
application that called \*Ldced_server_start(\|)\*O)
.LI
Automatically when a remote procedure call comes in for the server
.LI
After a failure of the server it can be restarted
.LE
.P
.ne 13
If \*Ldced\*O did not start the server, it cannot control it.
Therefore, one of the first things your server should do is to verify that
\*Ldced\*O started it by obtaining the configuration information, as in
the following:
.oS
server_t  *server_conf;
 \&. 
 \&.
 \&.
dce_server_inq_server(&server_conf, &status);
if(status != error_status_ok) { 
    \&.
    \&.    
    \&.
.oE
.P
Additional routines, such as \*Ldce_server_inq_uuids(\|)\*O and
.iX "\*Ldce_server_inq_uuids(\|)\*O"
\*Ldce_server_inq_attr(\|)\*O, are also useful for obtaining
.iX "\*Ldce_server_inq_attr(\|)\*O"
information from \*Ldced\*O about the running server.
.P
.ne 5
Robust servers usually perform some or all of the following
initialization tasks:
.iX "server" "initialization of"
.ML
.LI
Set up for serviceability which includes 
establishing message routing, 
debug levels, and
internal message tables.
.LI
Set up the server's objects.
This includes creating and storing UUIDs for all necessary objects 
and object types, and grouping objects by type.
.LI
Set up the security environment which includes
setting authentication information,
establishing the server's principal identity, and
creating ACL managers for each type of ACL object.
.LI
Define manager entry point vectors (EPVs) for each set of 
interface operations.
.LI
Register the server with DCE.  This includes the following:
registering the interfaces and the associated EPVs for the operations,
establishing the network protocol sequences and endpoints on which the
server will listen,
registering endpoints and other binding information in the endpoint
mapper service, 
and exporting binding information to the CDS namespace.
.LI
Specify how the server will be multithreaded.
.LI
Listen for incoming requests for remote procedure calls.
.LI
Clean up the program state and environment affected by the server prior
to the server's termination.
.LE
...\" ----------------------------------------------------------------------
.H 3 "Setting Up for Serviceability"
...\" ----------------------------------------------------------------------
.P
Serviceability standardizes the server messages displayed or logged. 
.iX "serviceability"
It acts on a set of standard message catalogs and application-specific
.iX "message catalogs"
catalogs generated from the \*Lsams\*O utility.  Some of the obvious
.iX "\*Lsams\*O utility"
advantages the serviceability facility gives servers over using the
standard C library routines such as \*Lprintf(\|)\*O and
\*Lfprintf(\|)\*O include the following:
.ML
.LI
Messages do not need to be hard-coded into applications
...\" .LI
...\" Internationalization issues such as locale and language can be automatic
.LI
Message routing can be better controlled
.LE
.P
The following routine shows how a server can report a status
code returned from an API routine:
.iX "\*Ldce_error_inq_text(\|)\*O"
.nL
.ps 11
.vs 13
.oS
void
print_server_error(
char *caller,           /* Routine that received the error.         */
error_status_t status)  /* Status we want to print the message for. */
{
    dce_error_string_t error_string;
    int print_status;

    dce_error_inq_text(status, error_string, &print_status);
    dce_svc_printf(SERVER_ERROR_MSG, caller, error_string);
}
.oE
.ps 12
.vs 14
.P
The \*Ldce_error_inq_text(\|)\*O routine looks up the status number
in a standard table and returns a string of text that describes the
error status.
The serviceability routine \*Ldce_svc_printf(\|)\*O then displays the
.iX "\*Ldce_svc_printf(\|)\*O"
message, logs it to one or more files, or both.
.P
The following code shows some typical tasks when setting up the server
for serviceability:
.iX "\*Ldce_svc_routing(\|)\*O"
.iX "\*Ldce_svc_register(\|)\*O"
.iX "\*Ldce_svc_debug_routing(\|)\*O"
.iX "\*Ldce_msg_define_msg_table(\|)\*O"
.nL
.ps 11
.vs 13
.oS
.ne 12
/* The following calls set up default routing of serviceability     */
/*  messages.                                                       */
for (i = 0, route_error = FALSE; (i < MAX_DEFAULT_ROUTES) 
					&& (!route_error); i++)
{
    printf("Setting default route %s ...\en", default_routes[i]);
    dce_svc_routing(default_routes[i], &status);
    if (status != svc_s_ok)
    {
        print_server_error("dce_svc_routing(default_routes[i])", status);
    }
}

/* Get serviceability handle...                                     */
smp_svc_handle = dce_svc_register(smp_svc_table, 
			(idl_char*)"smp", &status);
if (status != error_status_ok)
{
    print_server_error("dce_svc_register()", status);
    exit(1);
}

/* Set the default serviceability debug level and route...          */
dce_svc_debug_routing(default_debug_route, &status);

/* Set up in-memory serviceability message table...                 */
dce_msg_define_msg_table(smp__table,
	sizeof smp__table / sizeof smp__table[0],
	&status);
if (status != error_status_ok)
{
    print_server_error("dce_msg_define_msg_table()", status);
    exit(1);
}

dce_svc_printf(SIGN_ON_MSG);
    \&.
    \&.
    \&.
DCE_SVC_DEBUG((smp_svc_handle, 
	smp_s_server, 
	svc_c_debug4, 
	"Calling dce_server_sec_begin()");
.oE
.iX "\*LDCE_SVC_DEBUG(\|)\*O"
...\" ----------------------------------------------------------------------
.H 3 "Setting Up the Server's Objects"
...\" ----------------------------------------------------------------------
.P
The term \*Eobject\*O is a very general term that has meaning specific
.iX "object" "UUIDs"
.iX "object" "server objects"
to each application.  DCE uses object UUIDs to uniquely identify any object.  
The creation of object UUIDs, the determination of what (if anything)
constitutes an object for a server application, and the association of
these objects' UUIDs into collective types are all your application design
decisions.  
.P
Object UUIDs have a double use in the routing of RPCs, and you may at first
find this a bit confusing.
One use of object UUIDs is in the DCE RPC binding mechanism so that clients 
.iX "RPC" "binding mechanism"
can distinguish between specific resources, and another use of object
UUIDs in routing involves grouping objects into types so that 
a server can support different implementations of the same interface.
(DCE servers also use type UUIDs to associate objects for each ACL manager.)
.iX "object" "and ACL managers"
.P
If an application makes use of object UUIDs in bindings, 
.iX "object" "UUIDs" "in bindings"
.iX "object" "UUIDs" "exporting"
it makes them accessible to clients by exporting them with its
bindings when a server registers with DCE.
.P
The following shows sample code to create UUIDs for server objects and how
to store them using the backing store API:
.iX "backing store" "API"
.iX "\*Ldce_db_store_by_uuid(\|)\*O"
.iX "\*Ldce_db_store_by_name(\|)\*O"
.iX "\*Luuid_create(\|)\*O"
.nL
.ps 11
.vs 13
.oS
 \&.
 \&.
 \&.
/* A "well-known" residual name for the management "object":         */
#define MGMT_OBJ_NAME "server_mgmt"
/*                                                                   */
/* A residual name for a sample object:                              */
#define SAMPLE_OBJECT_NAME "sample_object"
 \&.
 \&.
 \&.
/* These are the backing store database handles:                     */
dce_db_handle_t db_acl, db_object, db_name;
 \&.
 \&.
 \&.
.ne 4
/* A UUID for a sample object:                                       */
uuid_t sample_object_uuid = {/* 00415371-f29a-1d3d-b8c8-0000c0d4de56 */
    0x00415371, 0xf29a, 0x1d3d, 0xb8, 0xc8, 0x00, 0x00, 0xc0, 0xd4, 
							0xde, 0x56 };
.ne 4
    \&.
    \&.
    \&.
    uuid_create(&server_uuid, &status);
    \&..
    \&..
    \&..
    dce_db_store_by_uuid(db_object, object_uuid, (void *)&sample_data, 
							status);
    if (*status != error_status_ok)
    {
	print_server_error("dce_db_store_by_uuid()", *status);
	return;
    }

    /* Finally, store the object UUID keyed by the object */
    /* ("residual") name...                               */

    dce_db_store_by_name(db_name, (char *)object_name, object_uuid, 
							status);
    \&.
    \&.
    \&.
.oE
.P
Names are established so that applications can refer to objects in a
way other than through the cumbersome UUID.  Object UUIDs are
generated in the following two ways:
.ML
.LI
The \*Luuidgen -s\*O command generates the C-structure form of a UUID
.iX "UUID"
.iX "\*Luuidgen\*O"
that can then be hard-coded into applications
.LI
The \*Luuid_create(\|)\*O routine generates a UUID ``on-the-fly.''
.iX "\*Luuid_create(\|)\*O"
.LE
.P
After creating backing store headers (if desired) and opening the
backing store databases, UUIDs are stored by calling the
\*Ldce_db_store_by_uuid(\|)\*O routine.
.iX "\*Ldce_db_store_by_uuid(\|)\*O"
To store names associated with the UUIDs, call the 
\*Ldce_\%db_\%store_\%by_\%name(\|)\*O routine.
.iX "\*Ldce_db_store_by_name(\|)\*O"
...\" ----------------------------------------------------------------------
.H 4 "Object UUIDs in Bindings"
...\" ----------------------------------------------------------------------
.iX "object" "UUIDs" "in bindings"
.iX "object" "UUIDs" "exporting"
.P
Object UUIDs are often used in the DCE RPC binding mechanism. 
The details of RPC binding are explained in Section 1.5.5,
and more thoroughly in Chapter 4.
It all comes down to this: 
clients import only \*Vpartial\*O bindings from the namespace. 
.iX "binding" "partial"
These will carry them only as far as the endpoint mapper service of the
.iX "\*Ldced\*O" "endpoint mapper service"
.iX "endpoint" "dynamic"
\*Ldced\*O on the destination server's host; 
it is \*Ldced\*O's job to resolve the binding with a dynamic endpoint.
.P
This means that some registration of bindings must be done by a server with
.iX "binding" "registration of"
the endpoint mapper.
The minimum two items that have to be registered are interface UUIDs and 
.iX "interface" "UUID"
.iX "UUID" "interface"
bindings (the latter of which contains the server's dynamically 
allocated endpoints).  With this information available,
.iX "endpoint" "dynamic"
the endpoint mapper can inspect the incoming RPCs interface UUIDs, 
select one of the endpoints that was registered under them, 
and resolve the partial bindings. 
In addition, a server can register its object UUIDs with its endpoint mapper. 
This allows lookups of endpoints by object UUID rather than interface UUID; 
the advantage is that object UUIDs are much more specific than interface UUIDs,
which may be registered by multiple servers at the same host.
.iX "server" "multiple servers on one host"
...\" ----------------------------------------------------------------------
.H 4 "Making Object-UUID/Type-UUID Associations"
...\" ----------------------------------------------------------------------
.P
To group together objects into types, the server makes an RPC library call
repeatedly to associate whatever objects it expects will appear in incoming
RPCs with a type UUID.  The association is made between each of the expected
.iX "type" "UUID"
incoming object UUIDs and the type UUID.  The following is an example:
.iX "\*Lrpc_object_set_type(\|)\*O"
.oS
rpc_object_set_type(\*Vobj_uuid\*C, \*Vtype_uuid\*C, &status);
.oE
.P
A type UUID is nothing but a special kind of object UUID.  \*EType\*O
in this context refers to a group of ordinary object UUIDs that have all been
associated with another specially generated common object UUID, which
can then be used to identify that group of objects collectively.
.iX "object"
.P
.ne 4
The type UUIDs in turn are associated with the entry points of 
manager modules in the server when the server registers with DCE. 
An incoming RPC with a \*Etyped\*O object UUID 
in its binding will be automatically
.iX "type" "manager"
.iX "manager" "type"
vectored by the server's runtime to the appropriate associated type
manager.
.P
Note that it is not necessary to call \*Lrpc_object_set_type(\|)\*O at
all if you intend to register only one set of manager routine
implementations per interface.
...\" ----------------------------------------------------------------------
.H 4 "Summary of Mechanisms that Rely on Object UUIDs"
...\" ----------------------------------------------------------------------
The type UUIDs and the type manager vectoring mechanism have nothing to do 
with the use of the object UUIDs themselves as lookups for the host
endpoint mapper.  The type manager vectoring occurs after 
object UUID binding happens, at the server.
Note also that object UUID binding happens only once in an uninterrupted
client/server session; after the partial binding is completed, communications
.iX "binding" "partial"
.iX "type" "manager"
proceed directly between the client and server.  Type manager vectoring, on
the other hand, occurs every time an incoming RPC contains
an object UUID.
.P
The very different nature of the two mechanisms just discussed is somewhat
obscured by the order in which they are initialized in the steps in 
this chapter.  The following list shows the relevant server steps, 
with an indication in each instance to which mechanism they are related:
.AL 1i
.LI 
When setting up the server's objects, 
groups of object UUIDs are associated under type UUIDs in the RPC runtime
related to the type vectoring mechanism.
.LI 
When defining the manager EPVs, 
.iX "manager" "entry point vectors"
.iX "EPV (entry point vector)"
each type UUID is associated with a manager EPV (in the RPC runtime)
related to the type vectoring mechanism.
.LI 
When registering the server,
object UUIDs and server endpoints are registered with the server's endpoint
mapper and the server bindings (containing the object UUIDs) are exported 
into the namespace.  These are related to the endpoint mapping mechanism.
.iX "endpoint" "mapping mechanism"
.LE
...\" ----------------------------------------------------------------------
.H 3 "Setting Up Security"
...\" ----------------------------------------------------------------------
.P
To set up the security environment, the server makes the following DCE
library call:
.iX "\*Ldce_server_sec_begin(\|)\*O"
.nL
.oS
dce_server_sec_begin(dce_server_c_login | dce_server_c_manage_key, \\
    &status);
.oE
.P
The flags in the first parameter represent the following security issues:
.ML
.LI
Establish the server principal identity
.P
.iX "server" "principal identity" "establishing"
.iX "login context"
When first invoked, a server process uses the login context of the user
who invoked it, until it assumes its own identity by accessing its
secret key, which is analogous to a user's password, and using it
.iX "keys" "secret key"
to get its own login context.   
Of course, it is possible for a server to simply continue using its inherited
login context.  In that case, all it needs to do is use the security login 
routines to obtain its principal name and explicitly get its login context.
.iX "keys" "managing server key"
.LI
Manage the server key
.P
When a server has its own identity, it takes on responsibility for
the upkeep of its password using the security key management routines.
.LE
.iX "authenticated RPC"
.P
The decision whether or not to use authenticated remote procedure calls
is something of a cooperative matter between the client and the server.
When the client calls \*Lrpc_binding_set_auth_info(\|)\*O,
it registers its preferences about the same things.
The client's and server's choices are not required to agree in order for the
client to successfully reach the server.  If the client's authentication and 
authorization choices do not agree with what the server expects, 
.iX "authorization"
it is up to the server to decide whether or not to go ahead with the
operations, and how far to cooperate with client requests.
.P
To control access to the server's objects, ACL
.iX "access control list (ACL)"
.iX "ACL" "manager"
managers are also set up.
...\" ----------------------------------------------------------------------
.H 3 "Defining the Manager Entry Point Vectors for Each Set of Operations"
...\" ----------------------------------------------------------------------
.P
\*EManager\*O is the DCE term for the part of a server that actually implements
a set of interface operations (the remote procedures), as distinguished 
from the more or less generic server initialization code described here.
(see \*Lsample_manager.c\*O for an example of manager code).
A manager EPV is the data structure in which
.iX "entry point vector" "manager"
.iX "manager" "entry point vectors"
.iX "entry point vector" "addresses in"
is recorded the entry addresses of the application routines that implement the
server's operations, as offered through an interface.  The server's stub code
uses the EPV to dispatch incoming RPCs to the requested operations. 
For each interface the server supports, a default manager EPV is generated
automatically by the IDL compiler.
In order for the RPC runtime to properly dispatch remote procedure calls
to the correct procedure, the server initialization code must declare 
the default EPVs and then register them with the runtime, as shown in
the following example:
.oS
extern rdaclif_v1_0_epv_t dce_acl_v1_0_epv;
extern sample_bind_v1_0_epv_t sample_bind_epv;
.oE
.P
We will later describe registering the EPVs with the RPC runtime.
.P
If more than one version of the same interface is to be supported by the same
server, another EPV is needed for each additional interface version. 
Interface version numbers are specified by the \*Lversion\*O attribute in the
.iX "interface" "version number"
\*L.idl\*O file. 
Additional EPVs are also required if the application implements the procedures
in more than one way.  For example, some applications invoke the same remote
procedure to operate on different types of objects.
.iX "entry point vector" "multiple"
Different objects would likely require different implementations, 
and thus more than one manager procedure would be coded.
The type manager RPC runtime mechanism, properly utilized,
allows a server to declare multiple EPVs under the same interface, 
and to have the RPC runtime vector (direct) the incoming remote calls to the
correct implementation code. 
...\" ----------------------------------------------------------------------
.H 3 "Registering the Server"
...\" ----------------------------------------------------------------------
.iX "server" "registering"
.iX "\*Ldce_server_register(\|)\*O"
.P
To register the server with DCE, the server calls the following:
.oS
dce_server_register(    
    dce_server_c_ns_export,   /* flag says register */
    server_conf,              /* server with CDS    */
    &register_data,
    &server_handle,
    &status
);
.oE
.P
The \*Ldce_server_register(\|)\*O routine affects a number of
components and services in DCE including the RPC runtime, 
the local endpoint mapper service, 
and if the \*Ldce_server_c_ns_export\*O flag is set, even the CDS namespace.
The \*Lserver_conf\*O structure is obtained with a call to the
\*Ldce_server_inq_server(\|)\*O routine and represents the
configuration \*Ldced\*O used to start the server.
This contains information needed to register the server too.
The \*Lregister_data\*O structure contains data about the server's 
.iX "\*Lregister_data\*O structure"
interfaces, entry point vectors, and type UUIDs.
.P
The following subsections describe the details about what happens when
you register a server.
...\" ----------------------------------------------------------------------
.H 4 "Registering the Interface, Type UUID, and EPV with RPC Runtime"
...\" ----------------------------------------------------------------------
.iX "UUID" "type" "registering"
.iX "UUID" "interface" "registering"
.iX "entry point vector" "registering"
.P
Earlier we described how to establish an EPV for
each set of operations provided by interfaces.
Remember that an EPV is a list of pointers to procedures.
The first affect of registering the server is to register the
services offered (represented by IDL interfaces) and the associated
EPVs with the RPC runtime.
Registering interfaces with their associated EPVs allow the RPC
runtime to use the EPVs to direct an incoming remote procedure call to
the correct procedure implemented in the server's manager code.
.P
.ne 6
We also described earlier the type manager mechanism which uses a type
UUID to group together object UUIDs.  With this mechanism,
a different EPV can be associated with each type UUID so that different 
manager code can be called, depending on an object's type UUID.
After these EPVs are registered with the runtime, 
incoming RPC binding that contain a typed object can be routed by the
runtime to the correct manager code.
.P
The data structure the server uses to establish its services is of
type \*Ldce_server_register_data_t\*O.
This data structure is initialized prior to the
\*Ldce_server_register(\|)\*O routine call as in the following example:
.iX "\*Ldce_server_register_data_t\*O structure"
.oS
dce_server_register_data_t  register_data[2];
\&.
\&.
\&. 
register_data.ifhandle[0]  = rdaclif_v1_0_s_ifspec;
register_data.epv[0]       = NULL;   /* use the default epv */
register_data[0].num_types = 0;         
register_data[0].types     = NULL;
register_data.ifhandle[1]  = sample_bind_v1_0_s_ifspec;
register_data.epv[1]       = NULL;   /* use the default epv */
register_data[1].num_types = 0;
register_data[1].types     = NULL;
.oE
.P
The \*Ldce_server_register(\|)\*O routine usually establishes all the services
for a server at once.  This is a reasonable approach for most
applications, but some interfaces for services may have dependencies
on the order in which they are enabled.  After the server calls
\*Ldce_server_register(\|)\*O, it can use a series of calls to
\*Ldce_server_disable_service(\|)\*O and 
\*Ldce_\%server_\%enable_\%service(\|)\*O
.iX "\*Ldce_server_disable_service(\|)\*O"
.iX "\*Ldce_server_enable_service(\|)\*O"
to disable and then later reenable any interface offered by the server.
...\" ----------------------------------------------------------------------
.H 4 "Telling RPC Runtime What Protocol Sequences to Use"
...\" ----------------------------------------------------------------------
.iX "protocol sequences" "RPC" "requesting"
.iX "endpoint" "dynamic"
.P
The second thing registering the server does is it obtains a set of
endpoints and associates them with the desired protocol sequences.  
Endpoints are the host's address
numbers on which the server can receive incoming calls.  
This begins the process of actually setting up the
information that the server's clients will need in order to bind to it. 
.P
.ne 3
The endpoints are usually dynamically generated each time the server starts.
However, some applications may use well-known endpoints that are the
.iX "endpoint" "well-known"
same every time the server starts.
If well-known endpoints are used, they are typically defined in the
interface definition with the \*Lendpoint\*O attribute.
.P
In the default case, all valid protocol sequences are used when the
\*Ldce_server_register(\|)\*O routine is called. 
The \*Ldce_server_c_no_protseq\*O flag can be passed in the first argument
to the routine in cases where dynamic assignment of endpoints is not
desired; for example, when well-known endpoints (specified in the
IDL definition) are being used.
...\" However, if you use
...\" the \*Ldce_server_c_no_protseq\*O flag in the first argument to the
...\" routine, you can later establish a specific protocol sequence with the
...\" \*Ldce_server_use_protseq(\|)\*O routine.
...\" .P
...\" \*L<<REVIEWERS: IS THIS RIGHT?>>\*O
...\" No-- protseq first -- Then register.  The no_protseq flag is for special cases
...\" like well-known ep's in the subset of available protseqs.
...\" ----------------------------------------------------------------------
.H 4 "Registering the Binding Information with the Endpoint Mapper Service"
...\" ----------------------------------------------------------------------
.iX "binding" "registration of"
.iX "endpoint" "mapper service"
.P
After server registration obtains the endpoints, the endpoints,
protocol sequences, and object UUIDs are
registered with the endpoint mapper service of the local host's \*Ldced\*O.
.P
Typically the server has received a certain number of
endpoints dynamically allocated on its host machine. 
However, when prospective clients import binding information from the
namespace, they get partial bindings.
.iX "binding" "partial"
When they first try to contact their server, 
the partial binding will get them only as far as the server's endpoint
mapper service.
.iX "endpoint" "registering"
The purpose of registering endpoints is to 
let the endpoint mapper know what endpoints belong to the server so that
it can fill in the partial bindings as they arrive and route the incoming
remote calls on their proper ways.  Subsequent remote calls executed with
the same bindings will go straight to the server, since the bindings are
now complete.
.P
The purpose of registering endpoints together with object UUIDs is to
account for all possible incoming object UUIDs (that is, object UUIDs that
could appear in incoming partial bindings arriving at the endpoint mapper),
and to associate with each of them one of the server's allocated endpoints.
Then the endpoint mapper can simply look up the object UUID, find an endpoint,
insert it into the binding, and send the RPC on to its destination.
.iX "interface" "UUID" "and incoming RPCs"
.iX "UUID" "object UUIDs" "and interface UUIDs"
.iX "interface" "generic"
.iX "server instances" "distinguishing"
.P
.ne 13
An incoming RPC \*Valways\*O has an interface UUID associated with it;
therefore, if a server registers all of its endpoints with the interface
it is offering, this will usually be sufficient for the endpoint mapper to
send the incoming requests to one of the servers that offer the desired
interface, even if there is more than one such server active on the machine.
However, if the application is designed in such a way that the binding
operation should not be generalized to the interface but must be made more
specific (in other words, this server's clients should always bind \*Vto
this server and no other\*O, even if some other server happens to offer
the same interface), then object UUIDs must be used to accomplish this.
\*EGeneric\*O interfaces offered by an application (such as the remote ACL
or the DCE serviceability interface) require an object UUID in order to
distinguish the application's \*Einstance\*O of them; unique interfaces,
however, do not require an object UUID.
.iX "UUID" "object UUIDs" "and endpoint mapping"
.P
Of course, the server's interface UUID must also be included in each
object UUID/endpoint mapping, since no RPC will pass the endpoint mapper
if it does not have a matching interface UUID for its destination server.
Therefore, the endpoint mapper takes either two or three types of item
to be registered, namely
.ML
.LI
Endpoints
.LI
Interface UUID
.LI
Object UUIDs (optionally)
.LE
.P
It then generates a cross-product table of all possible combinations of
all values of the items.  This allows it to find a valid endpoint for every
possible valid object UUID/interface UUID combination.
.P
The endpoint mapper is the first point of decision for an incoming RPC
with a partial binding.  The mapper makes its decision \*Vsolely\*O on the
basis of the contents of its endpoint map.  The object/type and manager EPV
registrations that were done earlier have no effect on the endpoint mapper. 
Only after a client request arrives at the server
does the server's runtime routines dispatch the request among multiple
managers, if type managers have been registered by the server. 
The endpoint mapper knows nothing about registered object types. 
.nL
.ne 12
...\" ----------------------------------------------------------------------
.H 4 "Exporting the Binding Information to the Namespace"
...\" ----------------------------------------------------------------------
.iX "binding" "exporting"
.P
The final task of server registration (if the
\*Ldce_server_c_ns_export\*O flag is set in the
\*Ldce_server_register(\|)\*O call) is
.iX "\*Ldce_server_register(\|)\*O"
to export the binding information to the namespace.  In the usual case,
where the server's endpoints have been dynamically allocated to it, the
endpoint information will not be included in the exported handles.  Instead,
this information will be filled in by the host's endpoint mapper as the
partially bound handles arrive at the host in incoming RPCs. 
.iX "binding" "partial"
However, if the endpoints are well-known, they will be
included in the exported binding handles, and clients will thus import fully
bound handles.
.P
If you wish, you can use the lower level RPC routine
\*Lrpc_\%ns_\%binding_\%export(\|)\*O to export individual services to the
.iX "\*Lrpc_ns_binding_export(\|)\*O"
namespace, but in this case you should first be sure the flag
\*Ldce_server_c_ns_export\*O is not set in the
\*Ldce_server_register(\|)\*O routine.
.iX "binding" "handle"
.P
As a final note, a client must have a binding handle in order to reach
a server, but it does not have to get the handle from the name service. 
However, the name service is the recommended way for clients and
servers to find each other because it is a convenient and easy to use
service built into DCE.
...\" ----------------------------------------------------------------------
.H 3 "Specifying Multithreadedness"
...\" ----------------------------------------------------------------------
.P
The application may also spawn an additional thread for a signal handler.
An example follows:
.iX "\*Lpthread_create(\|)\*O"
.iX "\*Ldce_svc_printf(\|)\*O"
.iX "threads" "RPC" "multiple"
.iX "multithreadedness" "in servers" "specifying"
.oS
if (pthread_create(&sigcatcher,
        pthread_attr_default,
        (pthread_startroutine_t)signal_handler,
        (void*)0))
{
    dce_svc_printf(NO_SIGNAL_CATCHER_MSG);
    exit(1);
}
.oE
.P
.ne 9
The \*Vmax_calls_exec\*O parameter to the \*Lrpc_server_listen(\|)\*O routine
.iX "\*Lrpc_server_listen(\|)\*O" "and \*Lmax_calls_exec\*O parameter"
specifies the number of operations that the server can perform concurrently
in response to client requests.  The \*Vmax_calls_exec\*O parameter is also used
to derive the size of a buffer (the call request buffer) for incoming client
.iX "buffer" "incoming RPC call request"
.iX "RPC" "incoming calls" "specifying concurrency of"
requests that cannot be immediately executed. \*Vmax_calls_exec\*O specifies
the upper limit for the number of RPC threads that will be spawned by the
RPC runtime to handle incoming remote procedure calls.  Thus, an important
side effect of \*Lrpc_server_listen(\|)\*O, when the specified concurrency
.iX "\*Lrpc_server_listen(\|)\*O"
is greater than 1, is to create multiple threads of execution in the server.
.P
The threads are automatically spawned to handle whatever operation is
requested by the client.  If the maximum number of manager threads is already
.iX "threads" "manager"
active and more incoming calls arrive, the RPC runtime buffers them in a call
request buffer.   The size of the call request buffer depends on the
\*Vmax_calls_exec\*O parameter; the larger the parameter, the bigger
the buffer.  Incoming calls beyond the call 
request buffer capacity are rejected (with an error code) by the RPC runtime.
.P
Although the execution threads are automatically managed by the
RPC runtime, the developer is responsible for coding the manager routines
according to thread-safe guidelines so that the threads will execute properly.
.iX "threadsafeness"
For further information on thread-safe programming practices, 
see Chapter 2.
...\" ----------------------------------------------------------------------
.H 3 "Listening for Incoming Service Requests"
...\" ----------------------------------------------------------------------
.P
In order to begin listening for incoming remote procedure calls,
the server calls the following RPC library routine:
.iX "\*Lrpc_server_listen(\|)\*O"
.oS
rpc_server_listen(\*Vmax_calls_exec\*C, &status);
.oE
.P
The \*Lmax_calls_exec\*O parameter specifies the number of concurrent
remote procedure calls the server can execute.
This call normally begins a ``semi-infinite'' loop, execution of which is
terminated only by one of the following events:
.ML
.ne 6
.LI
One of the server's manager routines calls
\*Lrpc_\%mgmt_\%stop_\%server_\%listening(\|)\*O
.LI
One of the server's clients makes a remote call using the routine
\*Lrpc_mgmt_stop_server_listening(\|)\*O. (Note that the server can intercept
.iX "\*Lrpc_mgmt_stop_server_listening(\|)\*O"
such a remote call and either allow or prevent it by installing a
function with \*Lrpc_mgmt_set_authorization_fn(\|)\*O).
.iX "\*Lrpc_mgmt_set_authorization_fn(\|)\*O"
.LI
A management application makes a remote procedure call using the
routine \*Ldced_server_stop(\|)\*O
.iX "\*Ldced_server_stop(\|)\*O"
.LI
An administrator (or administrative script) uses the \*Ldcecp server
.iX "\*Ldcecp\*O" "\*Lserver stop\*O"
stop\*O \*Eserver_name\*O operation
.LI
A signal or exception occurs
.LE
.P
From the point of view of the server, the call to \*Lrpc_server_listen(\|)\*O
blocks until the \*Lrpc_mgmt_stop_server_listening(\|)\*O routine is called.
When this happens, the RPC runtime stops accepting incoming
client requests to the server, and when all the currently executing operations
are completed, the call to \*Lrpc_server_listen(\|)\*O returns.
.P
Server operations can also be terminated by an exception or signal. DCE
Threads defines all exceptions as \*Eterminating\*O, which means that execution
.iX "exceptions" "terminating"
.iX "exceptions" "signals and"
must be caught by an exception handler (if one exists) and then be resumed
.iX "exception handlers"
there, or the process will be terminated.  Certain signals are defined by DCE
Threads as exceptions, which means that these signals have the same general
characteristics as exceptions.
For more information on the DCE Threads exception handling interface, see
.iX "exceptions" "handling interface"
Chapter 2.
...\" ----------------------------------------------------------------------
.H 3 "Cleaning Up Code When the Server Terminates"
...\" ----------------------------------------------------------------------
.P
If (or when) the server terminates execution, it should undo its initialization
that affected other facilities and services of DCE.  Facilities affected include
the CDS namespace, the endpoint mapper service, and backing store databases such
as those used for ACL managers.  For the most part, API routines that cause these
kinds of effects have a corresponding API routine to undo them.  The following
sections describe the series of routines typically used to clean up after an
application.
...\" ----------------------------------------------------------------------
.H 4 "Unregistering the Server"
...\" ----------------------------------------------------------------------
.P
Two important aspects of registering the server is that it registered
the interfaces and EPVs with the RPC runtime, and it established the
endpoints (or addresses) on which the server listened for requests.  
If the endpoint map contains \*Estale\*O data,
.iX "endpoint" "stale data in map"
it can create for a client a fully bound binding that is not valid.
Even though the endpoint mapper service does its own housecleaning
periodically, there is the possibility that these invalid bindings
could be created and used.  
Therefore, it is a good idea to call the following routine:
.iX "\*Ldce_server_unregister(\|)\*O"
.oS
dce_server_unregister(\*Vserver_handle\*C, &status);
.oE
.P
In addition to unregistering the server's address information from the local
.iX "unregistering server address information"
endpoint mapper's database, this routine unregisters all the services
(interfaces and EPVs) from the RPC runtime as well.  
.P
If your application requires a partial shutdown or a particular order
to the shutdown of services, you can use more specific routines such
as \*Lrpc_ep_unregister(\|)\*O and \*Ldce_server_disable_service(\|)\*O.
.iX "\*Lrpc_ep_unregister(\|)\*O"
.iX "\*Ldce_server_disable_service(\|)\*O"
...\" ----------------------------------------------------------------------
.H 4 "Unexporting from the Namespace"
...\" ----------------------------------------------------------------------
.P
If the server is going to be out of service for an extended period,
it should unexport any information it previously caused to be placed
.iX "unexporting server namespace information"
in the namespace.
This will prevent future prospective clients from being misled into
attempting to reach the server when it does not exist,
and also will help to conserve resources in the namespace.
.P
Unexporting is automatic when \*Ldce_server_unregister(\|)\*O is called
if the \*Ldce_server_c_ns_export\*O flag was set when the
corresponding \*Ldce_server_register(\|)\*O was called.
For more specific control, an individual service previously exported
is removed from the namespace with the following routine:
.iX "namespace" "unexporting information from"
.iX "\*Lrpc_ns_binding_unexport(\|)\*O"
.oS
rpc_ns_binding_unexport(\*Ventry_name_syntax\*C, \*Ventry_name\*C, \*Vif_handle\*C, \\
    \*Vobj_uuid_vector\*C, &status);
.oE
.P
The CDS namespace is designed to store location data for extended
periods of time.
...\" ----------------------------------------------------------------------
.H 4 "Cleaning Up Security Information"
...\" ----------------------------------------------------------------------
.P
A call to the \*Ldce_server_sec_begin(\|)\*O routine should have a
.iX "\*Ldce_server_sec_begin(\|)\*O"
corresponding call to the \*Ldce_server_sec_done(\|)\*O routine to
.iX "\*Ldce_server_sec_done(\|)\*O"
release resources allocated.  In addition, your code should close any
backing store databases used for ACL management.
...\" ----------------------------------------------------------------------
.H 2 "The Client Binding and RPC Invocation"
...\" ----------------------------------------------------------------------
.P
To use RPC, a client must first establish a binding to the server.
The following steps cover bindings and binding handles.  
.P
The programmer designing clients must decide whether or not to use
threads, and should have an understanding of multithreaded clients.
DCE provides a set of tools for multithreaded programming; 
these are described in Chapter 2.
...\" ----------------------------------------------------------------------
.H 3 "Importing the Binding Information from the Namespace"
...\" ----------------------------------------------------------------------
.iX "binding" "choices of"
.iX "binding" "methods"
.P
The first important thing that the client does is to acquire a binding to
the server it wants to request services from.  From the client's point of
view, there are several binding choices to be made.
.P
The first choice is in regard to the binding method to be used; however,
this is determined and implemented as part of
the development coding process (the \*L.acf\*O file).  The binding method
chosen has an effect both on what the client has to do in the present step
to acquire bindings, and subsequently on what it must do to maintain them.
.iX "binding" "explicit method"
.iX "binding" "implicit method"
.iX "binding" "automatic method"
In this step, it will be assumed that either the explicit or implicit method
was chosen.  If auto-binding were chosen, there would be no need for a
discussion, since the client would then have nothing to do.
...\" ----------------------------------------------------------------------
.H 4 "Getting a Handle"
...\" ----------------------------------------------------------------------
.iX "binding" "acquiring a handle"
.P
The second choice involves how to get a binding handle. Again, this is a
choice that is at least partially dependent on decisions already made.
The client can always generate a binding handle for itself; the problem is
where to get the information that belongs in it.  There are two general
solutions, as follows:
.iX "namespace" "importing binding handles from"
.iX "binding" "string" "converting binding information into"
.ML
.LI
The client imports from the namespace binding handles that already contain
the necessary information, or
.LI
The client receives the information in string form from user input, from a
file, from another server, or from any other source.  It then converts the
string into a binding by calling \*Lrpc_binding_from_string_binding(\|)\*O.
.iX "\*Lrpc_binding_from_string_binding(\|)\*O"
.LE
.P
The normal way for a server to make its location known to clients is to export
.iX "namespace" "exporting binding information into"
its binding information into the namespace.  The client can then call the 
following RPC name service library routines to import one or more bindings 
from the specified namespace entry: 
.iX "\*Lrpc_ns_binding_import_begin(\|)\*O"
.iX "\*Lrpc_ns_binding_import_next(\|)\*O"
.iX "\*Lrpc_ns_binding_import_done(\|)\*O"
.nL
.ps 11
.vs 12
.oS
rpc_ns_binding_import_begin(\*Ventry_name_syntax\*C, \*Ventry_name\*C, \*Vif_handle\*C, \\
    \*Vobj_uuid\*C, &import_context, &status);
 
rpc_ns_binding_import_next(\*Vimport_context\*C, &binding_handle, &status);
 
rpc_ns_binding_import_done(\*Vimport_context\*C, &status);
.oE
.ps 12
.vs 14
.P
The name service sees to it that only compatible bindings exported under the
.iX "binding" "importing compatible"
.iX "object" "UUIDs" "importing binding handles"
specified interface, with the optionally specified object UUID, will be
returned to the client. (Note that the interface specification is \*Enot\*O
contained in the binding, although it is exported to the namespace entry
where it is used by the name service for matching entries to prospective
importers.) The object UUID specified by \*Vobj_uuid\*O is contained in the
binding, if it is present.  This is the object UUID that was (optionally)
registered under a type UUID in an earlier step.  Even if \*Vobj_uuid\*O
is not specified in the import call, it will be returned in the 
binding handle(s) if it was exported by the server.
...\" ----------------------------------------------------------------------
.H 4 "Determing the Entry Name"
...\" ----------------------------------------------------------------------
.iX "namespace" "entry name in" "importing from"
.P
To determine how the client knows the entry name to import from, the
simplest method is to have the user type it in on the command line.
...\" ----------------------------------------------------------------------
.H 4 "Binding Compatibility"
...\" ----------------------------------------------------------------------
.iX "binding" "compatibility"
.iX "protocol sequences" "RPC runtime and"
.iX "protocol sequences" "and binding compatibility"
.P
The protocol sequence used must be supported by both the RPC
runtime and the operating system on the client's machine.  However, the
RPC runtime implicitly takes care of binding compatibility when it returns
bindings to importing clients; only compatible bindings are returned.
.P
The \*Lrpc_network_inq_protseqs(\|)\*O and
.iX "\*Lrpc_network_inq_protseqs(\|)\*O"
\*Lrpc_network_is_protseq_valid(\|)\*O routines
can be used to return all supported
.iX "\*Lrpc_network_is_protseq_valid(\|)\*O"
protocol sequences and to determine whether a specified protocol is supported,
respectively.
.P
To find out what protocol sequence is used in a binding handle, 
make the following series of calls:
.iX "\*Lrpc_binding_to_string_binding(\|)\*O"
.iX "\*Lrpc_string_binding_parse(\|)\*O"
.nL
.ps 11
.vs 12
.oS
rpc_binding_to_string_binding(\*Vbinding\*C, &string_binding, &status);

rpc_string_binding_parse(\*Vstring_binding\*C, NULL, &protseq, NULL, NULL, \\
    NULL, &status);
.oE
.ps 12
.vs 14
...\" ----------------------------------------------------------------------
.H 3 "Annotating the Binding Handle for Security"
...\" ----------------------------------------------------------------------
.P
Now that the client has a binding, it is almost ready to begin RPC operations.
One last preliminary task remains; namely, to specify various security-related
parameters to the RPC runtime, which will govern the (security) conduct of the
ensuing client/server relationship.  If the client does not require
authentication, it can skip this step completely.  The result will be that no
authentication will take place between the client and server.  It will then be
up to the server to decide how far to go with an unauthenticated client.
...\" ----------------------------------------------------------------------
.H 4 "Preparation"
...\" ----------------------------------------------------------------------
.P
What the client essentially wants to do now is call the routine
\*Lrpc_binding_set_auth_info(\|)\*O in order to specify all the necessary
.iX "\*Lrpc_binding_set_auth_info(\|)\*O"
security parameters.  However, when it does this, it should be able to specify
its server's principal name, so that the server it binds to can be
.iX "principal name" "server" "how a client determines"
authenticated \*Vto the client\*O. (The server's principal name is the name
by which the server is known to the DCE Security Service.)  The client must also
supply a handle to its own login context when it calls
.iX "login context" "handle"
\*Lrpc_binding_set_auth_info(\|)\*O.
.P
There are several ways to determine the server's principal name, as
follows:
.iX "binding" "annotating handle for security"
.ML
.LI
The server's principal name could be hardcoded in the client.  This
is not recommended practice for reasons of robustness and flexibility.
.LI
The client can be handed the name as input from the command line when
it is invoked.
...\" .LI
...\" The name can be stored in the namespace.  NOT SECURE
.LI
The principal name can be the same as the name entry (binding information)
name.
.LI
The client can query the server's principal name by calling
\*Lrpc_mgmt_inq_princ_name(\|)\*O.  It can then check group membership by calling
.iX "\*Lrpc_mgmt_inq_princ_name(\|)\*O"
\*Lsec_rgy_pgo_is_member(\|)\*O, using a known tested group.
.iX "\*Lsec_rgy_pgo_is_member(\|)\*O"
.LE
.P
The reason for checking group membership has to do with authorization-related
.iX "group membership" "reason for checking"
decisions that the client may need to consider.  It is not necessarily enough
to know that a server has a certain identity; it may also be necessary that
it belong to a certain group in order for it to be fully authorized, from the
client's point of view, to receive the data that the client will send.  In other
words, the client may need to make a decision about the server similar in nature
to that which the server makes about the client, when
it checks the client's authorization, via ACLs, to do the things it wants to do.
Security can be just as important for the client as for the server; this is the
justification for having to make the extra calls described here.
.P
The client retrieves its login context with the following security 
.iX "binding" "annotating handle for security"
.iX "login context" "client" "retrieving"
library routine:
.iX "\*Lsec_login_get_current_context(\|)\*O"
.oS
sec_login_get_current_context(&login_context, &status);
.oE
.P
However, this is not usually necessary. The client can, by passing a NULL
value to \*Lrpc_binding_set_auth_info(\|)\*O, simply
.iX "\*Lrpc_binding_set_auth_info(\|)\*O"
use its default login context.
.P
In any case, note that this login context already exists; the client merely
retrieves it. (The client inherited its login context from the user principal
who executed it.) The client can now set up for authenticated RPC.
...\" ----------------------------------------------------------------------
.H 4 "Setting Up for Authenticated RPC"
...\" ----------------------------------------------------------------------
.iX "authentication" "setting up for"
.P
The client makes the following call in order to set up the security
characteristics of the communications it is about to enter into with
the server:
.iX "\*Lrpc_binding_set_auth_info(\|)\*O"
.nL
.ps 11
.vs 12
.oS
rpc_binding_set_auth_info(\*Vbinding\*C, \*Vserver_princ_name\*C, \*Vprotect_level\*C, \\
    \*Vauthn_svc\*C, \*Vlogin_context\*C, \*Vauthz_svc\*C, &status);
.oE
.ps 12
.vs 14
.P
The security parameters specified here include \*Vprotect_level\*O for level
of protection performed (for example, authenticate only at the beginning of
each RPC, or authenticate everything received by the server), \*Vauthn_svc\*O
for the authentication service (including ``none''), and \*Vauthz_svc\*O for
the type of client authorization information that will be supplied to the server.
.P
The usual practice is to pass NULL for \*Vlogin_context\*O here, and thus
use the default context.
.P
.iX "authentication" "client's decision to use or not"
Note that it is the client who chooses whether or not to use authenticated RPC,
as well as the level of authentication, and how much authorization information
about itself to send.  It is then up to the server to accept this arrangement or
reject it, or to allow some limited operation with the client, or whatever else
it might decide.  The server decides which authentication to use.  The client also
specifies an authentication service (in \*Vauthn_svc\*O), but if this differs
.iX "authentication" "services"
from what the server specified, the call to \*Lrpc_binding_set_auth_info(\|)\*O 
will fail and an error will be returned to the client.
.P
There is an important difference between the rationales of authentication and
authorization.  Authentication is performed by the RPC runtime and is only
.iX "authentication" "and authorization"
indirectly felt by client and server; authorization, however, is for the most
part implemented explicitly in the server code if it is implemented at all.
This difference is the reason for the larger number of authentication-related
arguments that have to be specified in this step.
.P
For further information about authenticated RPC, see the \*(Dk.
...\" 
...\" Chapter 2 contains sections on server key management, which is part 
...\" of the authenticated RPC mechanism, and on the practical details
...\" involved in writing an ACL manager.
...\" ----------------------------------------------------------------------
.H 3 "Invoking Remote Procedure Calls"
...\" ----------------------------------------------------------------------
.P
This step is the culmination of all the foregoing steps; here the client
makes its first remote call to the server.  This call, which will obviously
be application specific (its definition was specified in the application's
\*L.idl\*O file, and possibly modified by the
\*L.acf\*O file), will look something like the following:
.oS
my_rpc_op(\*Vbinding_handle\*C, \*Varg1\*C, \*Varg2\*C, \*Varg3\*C);
.oE
.P
Note that the presence of the binding handle as a parameter means that
explicit binding handles are being used.
.P
Note also that after all the preceding talk about interfaces, no interface
.iX "interface" "ensuring compatibility of between server and client"
handle appears in the parameter list.  The RPC runtime takes care internally
of making sure that the interface offered by the server exactly matches what
the client expects.  The \*Lmy_rpc_op(\|)\*O routine was (or should have been)
defined as part of the application's interface.  When the
client calls \*Lmy_rpc_op(\|)\*O in the present step, the client stub code
(which was generated during the IDL compilation step) will include the
correct UUID for the interface the routine is associated with in the data
sent out on the network.  The RPC runtime uses the interface specification
.iX "interface" "specification in stubs"
included with each RPC as a ``fingerprint'' to ensure that the operation
being requested of a server is in fact implemented by that server.  This
ensures that interface compatibility is never dependent on the vagaries of
application code.
.nL
.ne 25
...\" ----------------------------------------------------------------------
.H 4 "The Possibility of Binding Failure"
...\" ----------------------------------------------------------------------
.iX "binding" "failure"
.P
Perhaps the most important thing to mention about this step
is that it may not at first succeed.  Remember that the client imported
a \*Vpartial\*O binding to the server.  Completion of the binding, and
therefore of the remote call, depends on the endpoint mapper's being
able to successfully complete the incoming binding with a good endpoint
for either the specified server (if one is specified) or for one of its
own choosing.  This in turn depends on the up-to-dateness of the host's
endpoint database, and that depends on such things as other servers'
being conscientious about unregistering themselves when terminating,
and so on.  Even the target host specified may not be valid when the call
is made because of any one of the various network problems that can
occur.
.P
In other words, the client should regard an unused binding not as a firm
promise that comes directly from the server, but rather as a well-meant
expression of intent passed on by the name service and based on
circumstances not entirely under anyone's control.  This is the reason
for the series of binding import calls described earlier.  The prudent
thing for a client to do after importing a binding is,
therefore, to assume that it will have to perform one or more times a 
series of steps something like the contents of the following loop:
.AL
.LI
Annotate the binding handle for security.
.LI
Try it out: attempt a remote call with it.
.LI
If the call succeeds, discard the binding import context and proceed to
.iX "binding" "discarding import context"
step 5 in this loop.
.LI
Otherwise, if the call fails, import the next binding and return to step 1
in this loop.
.LI
Proceed with remote operations until finished.
.LE
.P
If all imported bindings happen to fail, this could be because the client's
cache of bindings has become stale.  The client could then try calling
\*Lrpc_ns_mgmt_handle_set_exp_age(\|)\*O with a low timeout value, and
.iX "\*Lrpc_ns_mgmt_handle_set_exp_age(\|)\*O"
then retry the previous loop.  
A last resort could be to allow the user to type
in a string binding.
.iX "binding" "automatic method"
.P
Note that if you are using the auto-binding method and the binding becomes
unusable for some reason, the RPC runtime will rebind under most conditions.
...\" ----------------------------------------------------------------------
.H 4 "The Result of Successful Binding"
...\" ----------------------------------------------------------------------
.P
If \*Lmy_rpc_op(\|)\*O or its equivalent does succeed, the binding will
as a result be complete (even if it was partial before), and the
information in it can be regarded with much more assurance from then on.
Subsequent remote procedure calls by the client to the same server will
go straight to the bound-to server.
...\" ----------------------------------------------------------------------
.H 2 "The Server's Manager of RPC Requests"
...\" ----------------------------------------------------------------------
.P
As was explained, server threads are automatically
spawned by the RPC runtime in the server manager to handle incoming remote
procedure calls from clients.  The number of calls that can be concurrently
handled depends on the value of the \*Vmax_calls_exec\*O parameter specified
in the call to \*Lrpc_server_listen(\|)\*O.  The
thread is created by the RPC runtime and begins execution in the operation
requested.  When the operation is completed, the thread is automatically
terminated (by the RPC runtime).
...\" ..."Well, sort of-- they're cached" (Rich Salz).
.P
See also the \*(Dk and the \*(Dr
for a comprehensive discussion of DCE threads.
...\" ----------------------------------------------------------------------
.H 3 "Getting the Client's Credentials"
...\" ----------------------------------------------------------------------
.iX "credentials" "client's" "retrieval by server"
.P
As mentioned in the previous step, authentication, if it was specified by
the client, has already occurred if the client's request is received by
the server manager.  If the client fails to authenticate itself to the server
runtime, its remote procedure call fails before reaching the server's RPC
code.
.P
Authentication, if specified by the client and offered by the server, is
performed by the RPC runtime; it is not a responsibility of the application
code.  However, it is up to the application to formulate its own security
policy with regard to the client, based on the following:
.ML
.LI
The level at which the client has been authenticated.
.LI
The client's authorization; that is, whether the client should be allowed to
access resources it may request.
.LE
.iX "authentication" "determining client's information"
.iX "authorization" "determining client's information"
.iX "\*Lrpc_binding_inq_auth_caller(\|)\*O"
.P
In order to find out the client's authentication and authorization information,
the server calls the following RPC library routine:
.nL
.ps 11
.vs 12
.oS
rpc_binding_inq_auth_caller(\*Vbinding_handle\*C, \*Vprivs\*C, \*Vserver_princ_name\*C, \\
    \*Vprotect_level\*C, \*Vauthn_svc\*C, \*Vauthz_svc\*C, &status);
.oE
.ps 12
.vs 14
.P
The parameters in this call are analogous to the similarly named parameters in
the registration routines.  The server can
learn what level of authentication, what authentication service, and what
server principal name the client specified.  Of most interest, however, are
the \*Vprivs\*O and \*Vauthz_svc\*O parameters.  The \*Vprivs\*O
parameter is a pointer to whatever information the client is willing to let
the server know about its privilege attributes; \*Vauthz_svc\*O tells what
this information is.  It could be any one of the following:
.ML
.LI
The client's privilege attribute certificate (PAC), containing the client's
.iX "privilege attribute certificate"
principal and group UUIDs.  These can be used to look up the client's privilege
.iX "group UUID" "client's"
.iX "principal UUID" "client's"
attributes in ACLs, whose entries are keyed by principal and
group UUID.
.LI
The client's principal name (a string).  This also can be used to look
.iX "principal name" "client's" "used for authorization"
through ACLs, provided that the lists have been annotated
with such name strings.
.LI
Nothing.  The client chooses not to provide any authorization information.
.LE
.P
From now on, it is the server's decision, as implemented by the developer,
how to respond to the client's requests for services and resources, depending
on the security information the server has learned about it.  A non-ACL-based
strategy may be implemented using the client's principal name string for
lookups.  The ACL-based strategy, which is supported by a DCE interface,
is described further in the next step.
...\" ----------------------------------------------------------------------
.H 3 "Getting the Object's ACL"
...\" ----------------------------------------------------------------------
.iX "access control list (ACL)" "retrieving an object's"
.P
This step is reached if the client requests access to any object, resource,
or service that is managed by the server, to which ACLs are attached.  As
previously mentioned, the application must implement its own ACL manager
if it wants to use ACLs to control access to its resources.  For further
details on how to go about creating an ACL manager, see Chapter 3.
.P
In order to allow applications to as easily as possible offer an ACL interface
that is uniform with that used by the DCE components themselves, the remote
ACL interface has been built into the DCE library, and client applications
.iX "remote ACL (\*Lrdacl\*O) interface" "use of by DCE applications"
.iX "\*Lrdacl\*O interface" "use of by DCE applications"
can perform operations on ACLs through another interface, also part of the DCE
library, which calls through the remote interface to the appropriate manager.
The remote interface, consisting of \*Lrdacl_\*V*\*L(\|)\*O calls, must be
implemented by the server application; clients execute the local
\*Lsec_acl_\*V*\*L(\|)\*O routines, which are linked to every DCE application
as part of \*Llibdce\*O.
.P
For the client, all that is necessary is to possess a binding to the object
whose ACL is to be operated on.  As long as the application exposes the
resources it manages as accessible objects (via the namespace), then the
DCE ACL interface provides for a client's being able to bind to the object
by calling \*Lsec_acl_bind(\|)\*O.  (In fact, this kind of object-oriented
.iX "\*Lsec_acl_bind(\|)\*O"
binding model can be very useful, and is discussed in further detail in
.iX "object-oriented binding model"
.iX "ACL" "handles"
Chapter 4.) 
Note that the \*Lsec_acl_\*V*\*L(\|)\*O routines use an \*EACL handle\*O
to specify the object whose ACL is to be accessed, so \*Lsec_acl_bind(\|)\*O
must always be called to obtain this handle, even if the client is already
bound to the object's server.
.P
.iX "\*Lacl_edit\*O"
There is a user interface into the ACL operations, 
embodied in the \*Lacl_edit\*O command.  For further information, see the 
\*(Ar.
.P
Server applications can use the DCE ACL library routines to implement ACL
managers.  The DCE ACL library is an implementation of the remote ACL 
(\*Lrdacl\*O)
interface, designed in such a way as to allow any DCE application to 
use it instead
of having to implement the interface itself.  In DCE 1.0, 
applications that wished
to use the DCE ACL functionality had to implement the full remote interface
themselves; in DCE 1.1 this is no longer necessary.  For further information,
see Chapter 3.
...\" ----------------------------------------------------------------------
.H 3 "Making the Authorization Decision"
...\" ----------------------------------------------------------------------
.iX "authorization" "making decision"
.P
In this step, the server's ACL manager inspects the ACL of the resource
(object) under question, determines whether the client is authorized for the
requested access, and takes the appropriate action.
...\" A standard algorithm is used to accomplish this.
.iX "ACL" "types"
.iX "type" "managers" "ACL"
.P
The application may choose to implement more than one type of ACL (reflecting
the different kinds of objects and resources to be protected), thus resulting
in several ACL \*Etype managers\*O.
.P
Although it is up to the application to implement its own ACL storage, testing
algorithms and manager types, there are certain DCE-wide design conventions
that should be kept in mind and departed from only for good reason.  Among these
are the following:
.iX "ACL" "design guidelines"
.iX "ACL" "standard DCE entry types"
.iX "privileges" "standard DCE"
.iX "access algorithm" "standard DCE"
.ML
.LI
Standard DCE ACL entry types: the kinds of entry that can occur in an 
ACL (for example, \*Luser\*O, \*Lgroup\*O, and so on).
.LI
Standard privileges: the kinds of access that a principal can have
to a protected object (for example, read, write, and so on).
.LI
Standard inheritance rules: these rules govern the default characteristics of
ACLs created for newly created objects.
.LI
Standard access algorithm: the order in which a client's credentials are matched
against the various possible entry types.
.LE
.P
Information about these topics for application developers designing their own
ACL model can be found in the \*(Dk, in which all the DCE 
authorization conventions are described in detail.
...\" ----------------------------------------------------------------------
.H 3 "Servicing the RPC Request"
...\" ----------------------------------------------------------------------
.P
If the client's request is determined to be properly authorized, then the
requested operation can proceed.
.P
Note that this step and steps D3 and D4 (as discussed in Section 1.2) 
are somewhat intertwined.  Something like the following could occur:
.AL
.LI
The server wakes up in some routine defined in its manager code.  For example,
if the client executed the call \*Lmy_rpc_op(\|)\*O, then the server will
wake up in the routine that implements this remote call.
.LI
Execution of the \*Lmy_rpc_op(\|)\*O routine requires the \*Linsert\*O
privilege for the application's database \*Lmy_database\*O.  So
\*Lmy_rpc_op(\|)\*O begins by checking the client's relevant privilege
attribute by making an internal call to the application's ACL manager.
.LI
If the client is found to have the requisite privilege, \*Lmy_rpc_op(\|)\*O
proceeds.
.LE
.P
The remote procedure executed in this step is written by the application
developer.
...\" ----------------------------------------------------------------------
.H 3 "Returning the Results and Resuming Listening"
...\" ----------------------------------------------------------------------
.P
At the completion of the operation, the RPC thread that was automatically
spawned to execute it is terminated by the RPC runtime.  As far as the server
is concerned, it is still blocking on the call to \*Lrpc_server_listen(\|)\*O
which was made earlier.  If \*Vmax_calls_exec\*O was
.iX "\*Lrpc_server_listen(\|)\*O"
.iX "threads" "RPC" "multiple"
.iX "multithreadedness" "in servers" "behavior of"
.iX "\*Lrpc_server_listen(\|)\*O" "and \*Lmax_calls_exec\*O parameter"
.iX "buffer" "incoming RPC call request"
specified to be greater than 1 in that call, other threads may still be
executing at this time in response to other requests that have been received
from other clients.  In any case, the call to \*Lrpc_server_listen(\|)\*O will
not return until one of the server's own management routines, or a client,
makes a successful call to \*Lrpc_mgmt_stop_server_listening(\|)\*O.  If this
.iX "\*Lrpc_mgmt_stop_server_listening(\|)\*O"
happens, the RPC runtime will stop accepting incoming client requests to the
server.  When all the currently executing operations have been completed, the
call to \*Lrpc_server_listen(\|)\*O will return.
.P
The other way that execution can be thrown out of the \*Lrpc_server_listen(\|)\*O
call is as a result of a signal or exception.
.iX "signals" "and \*Lrpc_server_listen(\|)\*O"
.iX "exceptions" "and \*Lrpc_server_listen(\|)\*O"
...\" For more about this possibility,
...\" see Step B9.
...\" (Section 1.5.14).
.P
From the server's point of view, the result of completing the remotely called
routine is that it reenters the \*Elisten\*O loop, waiting for further remote
calls.  The server's runtime handles all the communications details of actually
sending any requested data to the client.
...\" ..."Implies serial, but it's parallel invocation" (Rich Salz).
.iX "remote call" "server's return from"
.P
From the client's point of view, the server's return at the end of its
remotely called routine results in the client's returning from a seemingly
locally executed routine.
...\" ----------------------------------------------------------------------
.H 4 "Continuing"
...\" ----------------------------------------------------------------------
.P
The client now goes on about its business, which may include performing
other remote procedure calls.
.P
Note that there is no housekeeping burden placed on the client with regard
to the termination of the relationship with a server.  However, a long-lived
client might want to make use of the \*Lrpc_binding_free(\|)\*O routine to
.iX "\*Lrpc_binding_free(\|)\*O"
.iX "binding" "freeing memory used by handle"
free memory that was allocated for no-longer-used handles.  The client should
also call \*Lrpc_ns_binding_import_done(\|)\*O to clean up the resources used
.iX "\*Lrpc_ns_binding_import_done(\|)\*O"
by the NSI routines.  If another binding handle will be needed later on, then
\*Lrpc_ns_binding_import_begin(\|)\*O will be recalled.
.iX "\*Lrpc_ns_binding_import_begin(\|)\*O"
...\" ----------------------------------------------------------------------
.H 2 "About DCE Programming Style"
...\" ----------------------------------------------------------------------
.iX "DCE programming style" "recommended"
...\" 
.P
The \*(Di (hereafter, the
\*EStyle Guide\*O) attempts to bridge a gap.  On one side stands
the tutorial and reference material provided by the rest of the \*(Dg
and by the \*(Dr.
In theory, this material provides complete
documentation of the \*Emechanisms\*O of DCE application programming.
In particular, it documents the syntax and semantics of every DCE API
interface and IDL construct and provides a service-by-service guide to
their use.
.P
On the other side stands the formal application portability
specification provided by the \*EAES/DC\*O.  This provides a
\*Epolicy\*O guide of a specific kind: if applications wish to be
portable among DCE implementations, they need to follow the AES
guidelines.
.P
Between these two poles of DCE documentation, there is still a great
deal of room to maneuver.  The DCE application programming facilities
provide such a large number of mechanisms, so many possible ways of
doing things, that it is often difficult for the programmer to decide
among them.  The guidelines provided by the \*EAES/DC\*O are limited
to only one (albeit an important one) policy issue: portability.
The DCE programmer is still left with many decisions about issues that
do not arise in the typical local programming environment: how to use the
name services, which security services to employ, how many threads to
use, and so on.
.P
The \*EStyle Guide\*O attempts to answer many of these questions or
at least to provide the grounds upon which an application programmer can
base decisions.  Of course, the coverage in these relatively few pages
in not exhaustive.  The number of implementation issues raised by the
available DCE application programming mechanisms is potentially
unlimited.  The \*EStyle Guide\*O attempts to cover the major
issues that are likely to confront most programmers at some stage in
DCE application design and development. 
.P
Aside from attempting to anticipate your questions, the \*EStyle
Guide\*O may also raise issues that you may not even have considered.
DCE covers a great deal of ground that is probably unfamiliar to
most application developers, such as multithreading and distributed
security.  When moving in such unfamiliar territory, it is easy to
overlook potential problems.  The \*EStyle Guide\*O attempts to alert
you to major stumbling blocks in each area.
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 3 "Mechanism, Policy, and Style"
...\" ----------------------------------------------------------------------
...\" 
.P
The \*EStyle Guide\*O is based on what is, to some degree, a fiction: that
application development issues can be nicely divided between
\*Emechanism\*O on one hand and \*Epolicy and style\*O on the other.
In theory, the \*Emechanisms\*O of DCE programming refer to the
syntax and semantics required by APIs, IDL constructs, services, and
the like.  These are the things about which the programmer has no
choice: they must either be done according to the documentation or not
done at all. \*EPolicy\*O and \*Estyle\*O, on the other hand, are supposed
to refer to the things about which the programmer can make a choice:
specifically, which mechanisms to use in given circumstances.
.P
In practice, the distinction between mechanism and policy/style is
often vague.  The other parts of the DCE application development
documentation set contain much that could be considered policy and
style guidance.  And, for reasons discussed in some detail in the next
section, the \*EStyle Guide\*O often contains descriptions of the
mechanisms of DCE programming.
.P
Nevertheless, the \*EStyle Guide\*O does attempt to keep to the ground
of policy and style issues.  It assumes that you already know what
mechanisms are available and attempts to provide guidance about the
choices you have in using those mechanisms.  One result is that the
\*EStyle Guide\*O is not a tutorial; it often assumes knowlege of
terms and concepts that are explained elsewhere in the programmer's
documentation.  
.P
.ne 5
On the other hand, the \*EStyle Guide\*O does in many
cases provide high-level discussions of the organization and
principals of DCE services, such as the security services.  The
assumption is that you may already know many of the details but may
lack an overall framework.  Often, such a general model is
just what you need to be able to make rational policy decisions.
.P
The distinction between policy and style is itself somewhat vague. In
general, \*Epolicy\*O refers to the things you \*Eshould\*O do in an
application program.  You can usually identify a policy recommendation
because the words ``should,'' ``must'' or ``recommended'' appear.
\*EStyle\*O is a more general term that includes policy (hence 
``\*EStyle Guide\*O''), but that also covers a variety of other
suggestions about how you might do things.  Much of the sample code
included in the \*EStyle Guide\*O embodies not only the recommended
policies, but also provides illustrations of possible styles of usage.
Such suggestions are intended to be helpful, but unless they are
couched in the language of policy, should be considered entirely
optional.
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 3 "Policy and Style Issues"
...\" ----------------------------------------------------------------------
...\" 
.P
Remote application programming, using DCE, imposes some special requirements on
applications that are not relevant to most local applications.  A DCE application
is a multicomponent system in which the various components interact dynamically
as the program operates.  Obviously, the application developer is concerned with
creating two major types of components, servers and clients, but these 
application specific components also enter into relationships with 
other DCE components.  For
example, most applications will be clients of naming and security services.  
Server applications that provide ACL managers may act, in turn, as 
servers to \*Ldcecp\*O
ACL commands.  Many similar client/server relationships may be 
created during the operation of a distributed application. 
.P
Furthermore, even components that do not communicate directly share 
common resources, such as directory and security services.  Components 
use these services to exchange specific kinds of data, such as bindings, 
and such exchanges can succeed only when they are made according to the 
correct protocols.  For example, a server needs to
organize the way it exports bindings to a name service so that clients can succeed
in finding them.  Similarly, clients and servers can only succeed at authenticated
communications if the correct registry and ACL data has been created and if each
follows the correct incantations to make use of this data.
.P
A particular constraint on DCE applications is that they must take into account the
administrative overhead of a distributed system.  Servers need to consider such issues
as the location and availability of the services they need, the structure of the
namespace into which they export their bindings, the DCE identity and privileges
under which the server must run, and many similar issues.  A successful server will be
one that interacts correctly with other components while imposing a minimal load on
the DCE environment and, most important, can be successfully and easily administered.
.P
To meet these requirements, application components must interact with each other
and with other DCE components in a consistent and well-behaved manner.  In this
context, one can think of DCE applications as having to meet application-level
and administrative interoperability requirements.  The \*VStyle Guide\*O is, in
part, a guide to such requirements.  Given the enormous variety of programming
and administrative mechanisms that DCE makes available to the programmer, the
\*VStyle Guide\*O provides a set of policy recommendations for the use of those
mechanisms that will maximize the application-level and administrative
interoperability of DCE applications.
.P
In addition to being complex, DCE application programming involves elements that
are likely to be unfamiliar to many programmers, such as remote parameter passing,
name services, and distributed security services.  Another goal of the \*VStyle
Guide\*O is to suggest wise uses for these tools, since many of the familiar local
programming models are inadequate.  These recommended policies are especially
important in the area of security: an application that fails to follow them is
likely to be insecure.  Recommended policies in some other areas, such as execution
semantics and locking, may also fundamentally affect the integrity of a distributed
application and should not be lightly ignored.  Other policies, such as those relating
to parameter passing affect mainly appliction performance.
.P
The simple unfamiliarity of many of the concepts can make the actual coding of an RPC
application a daunting task.  In traditional C programming you can usually begin with
familiar models\(emoften, with existing code\(embut with RPC you are unlikely to have
such starting points.  Therefore, this guide also provides extensive examples that
illustrate the basic uses of many important elements.  For example, in developing an
ACL manager, you may well be able to use the sample ACL manager as a starting point.
.P
The sample code is intended to suggest certain styles of usage that will probably prove
useful in many situations.  Obviously, these styles are only sugggestions: you will
certainly develop your own DCE programming style as you develop DCE applications.
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 3 "General Policies"
...\" ----------------------------------------------------------------------
...\" 
...\" 
.iX "server" "design guidelines"
...\" 
.P
The \*EStyle Guide\*O embodies a variety of basic assumptions. These
form the basis for a set of high-level policy recommendations that
cross the boundaries of the specific services discussed in later chapters.
These are as follows:
.ML
.LI
...\" 
.iX "server" "recommended design of interfaces"
...\" 
Servers are generalized providers of the services specified by their
published (IDL) interfaces.  That is, servers should encapsulate the
services they provide in such a way that naive clients, with no
knowledge of the specifics of server implementation, can successfully
make use of these services via the remote interfaces.  In this sense,
servers are much like libraries.  One should not assume that
clients will be written by someone with knowledge of server internals.
Where appropriate, define wrapper routines for the IDL operations to shield
developers from binding handles and other RPC peculiarities.
.LI
...\" 
.iX "server" "binding information recommendations" 
...\" 
Servers should make their resources known to clients using standard
mechanisms.  In particular, they should export their bindings
according to the recommended service models, use name and endpoint
services rather than fixed bindings and well-known endpoints, and
associate exported objects with UUIDs.
.LI
...\" 
.iX "clients" "portability of"
...\" 
...\" 
.iX "server" "portability of"
...\" 
Clients and servers should be portable, using DCE provided
mechanisms instead of operating system and transport-dependent
mechanisms.  For example, data streams should be communicated via the
RPC pipe mechanism rather than socket calls.  The AES/DC is
...\" 
.iX "pipe mechanism"
...\" 
the definitive guide to application portability using the
DCE mechanisms.
.LI
Distributed applications make greater administrative demands than
...\" 
.iX "distributed applications" "administrative demands of"
...\" 
nondistributed ones.  Clients and servers need to be written with an
eye to minimizing and simplifying administrative tasks.  This means,
for example, that
.ML  
.LI 
Applications need to be as configuration and location independent
as possible.  In particular, this means giving careful thought to
the use of name services for advertizing and finding resources.
.LI
Applications require both local and DCE identities and 
privileges.  They should follow the recommended models for  
acquiring and maintaining these privileges and identities.
.LI
.ne 5
Servers should be administratively interoperable; that is, they
should behave like the standard DCE servers, exporting the
recommended management interfaces,  exporting ACL managers, 
logging errors and messages, and providing for the standard 
startup and shutdown mechanisms.
.LE
.P
.LI
Distributed security is inherently more complex than local system
security (you can't just ``lock the door'').  Applications should follow
the recommended security policies rigorously.
...\" 
...\" They should avoid
...\" ad hoc security solutions which are as likely to compromise security
...\" as to enhance it.
...\" 
.LI
Clients and servers should follow the recommended
internationalization guidelines to ensure character set
interoperability.
.LE 
...\" 
...\" 
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------

...\"
...\" @OSF_COPYRIGHT@
...\" COPYRIGHT NOTICE
...\" Copyright (c) 1990, 1991, 1992, 1993 Open Software Foundation, Inc.
...\" ALL RIGHTS RESERVED (DCE).  See the file named COPYRIGHT.DCE in the
...\" src directory for the full copyright text.
...\"
...\"
...\" HISTORY
...\" $Log: 2_concepts.gpsml,v $
...\" Revision 1.1.6.16  1995/06/07  14:42:55  rcb
...\" 	PRENTICE HALL reformat; final edits and changes
...\" 	[1995/06/05  19:57:45  rcb]
...\"
...\" 	PRENTICE HALL reformat
...\" 	[1995/04/13  16:06:54  rcb]
...\"
...\" 	PRENTICE HALL reformat
...\" 	[1995/04/13  15:33:15  rcb]
...\"
...\" 	incorporated 1.1 edits
...\" 	[1995/04/13  14:57:50  rcb]
...\"
...\" Revision 1.1.6.15  1994/11/03  23:35:43  neilson
...\" 	Substituted macros for book names in cross refs.
...\" 	[1994/11/03  01:39:14  neilson]
...\" 
...\" 	Substituted macros for book names in cross refs.
...\" 
...\" Revision 1.1.6.14  1994/10/20  22:07:07  jshirley
...\" 	Fixed cross references.
...\" 	[1994/10/20  22:06:45  jshirley]
...\" 	Revision 1.1.6.13  1994/10/19  20:15:22  neilson
...\" 	CR 10326 - Automatic fix to name of intro ref page
...\" 	[1994/10/19  20:09:03  neilson]
...\" 	Revision 1.1.6.12  1994/10/19  19:34:04  weir
...\" 	Removed register set request
...\" 	[1994/10/19  19:33:42  weir]
...\" 	Revision 1.1.6.11  1994/10/18  15:16:01  weir
...\" 	{def,9772,R1.1}
...\" 	Fixed various inaccuracies
...\" 	[1994/10/18  15:15:07  weir]
...\" 	Revision 1.1.6.10  1994/09/30  18:51:42  weir
...\" 	Fixing internal cross-references
...\" 	[1994/09/30  18:51:05  weir]
...\" 	Revision 1.1.6.9  1994/03/14  22:00:59  rom
...\" 	{enh, 10129, R1.1}
...\" 	Fix pathnames of included files for new three-book organization.
...\" 	[1994/03/14  21:20:37  rom]
...\" 	Revision 1.1.6.8  1993/02/22  21:25:49  weir
...\" 	Fixed CR7104
...\" 	[1993/02/22  21:25:01  weir]
...\" 	Revision 1.1.6.7  1993/02/19  19:50:35  johnson
...\" 	No changes made.
...\" 	[1993/02/19  19:49:41  johnson]
...\" 	Revision 1.1.6.6  1993/02/03  20:04:21  buckler
...\" 	Changed .P! to .pI and added Postscript boundary boxes
...\" 	[1993/02/03  20:03:44  buckler]
...\" 	Revision 1.1.6.5  1993/01/28  18:46:40  cjd
...\" 	Embedded copyright notice
...\" 	[1993/01/28  18:07:44  cjd]
...\" 	Revision 1.1.6.4  1993/01/14  18:55:17  buckler
...\" 	Corrected bug number in change marker codes (4909 became 4908).
...\" 	[1993/01/14  18:54:36  buckler]
...\" 	Revision 1.1.6.3  1993/01/08  19:22:25  johnson
...\" 	CR#:     4908
...\" 	File:    /src/app_gd/threads/2_concepts.gpsml
...\" 	Change:  Added types of errors that can cause thread termination
...\" 	[1993/01/08  19:13:28  johnson]
...\" 	Revision 1.1.6.2  1992/11/20  21:00:24  weir
...\" 	Moved into 1.0.2doc tree
...\" 	[1992/11/20  20:57:46  weir]
...\" 	Revision 1.1.4.6  1992/11/11  23:54:18  buckler
...\" 	Corrected index entries
...\" 	[1992/11/11  22:59:19  buckler]
...\" 	Revision 1.1.4.5  1992/11/06  16:36:30  lmk
...\" 	Prentice-Hall index edits only
...\" 	[1992/11/06  16:33:40  lmk]
...\" 	Revision 1.1.4.4  1992/10/12  22:19:39  casey
...\" 	Index corrections for PH
...\" 	[1992/10/12  22:16:20  casey]
...\" 	Revision 1.1.4.3  1992/10/08  17:45:34  lmk
...\" 	Prentice-Hall edits only
...\" 	[1992/10/08  17:43:56  lmk]
...\" 	Revision 1.1.4.2  1992/09/10  20:43:01  buckler
...\" 	Second editorial review
...\" 	[1992/09/10  20:39:11  buckler]
...\" 	Revision 1.1.2.2  1992/06/17  18:50:47  buckler
...\" 	Incorporated editorial review
...\" 	[1992/06/17  18:50:02  buckler]
...\" 	Revision 1.1  1992/01/29  16:07:27  damon
...\" 	Initial revision
...\" 
...\" $EndLog$
...\"
...\" (c) Copyright 1991, Open Software Foundation, Inc.  ALL RIGHTS RESERVED
...\" ********************************************************************
...\"                                                                    *
...\" COPYRIGHT (c) 1991 BY DIGITAL EQUIPMENT CORPORATION,               *
...\" Maynard, Massachusetts                                             *
...\" All Rights Reserved.                                               *
...\"                                                                    *
...\" This document is furnished under a license and may be used and     *
...\" copied only in accordance with the terms of such license and with  *
...\" the inclusion of the above copyright notice.  No title to or        *
...\" ownership of the document is hereby transferred.                   *
...\"                                                                    *
...\" The information in this document is subject to change without      *
...\" notice and should not be construed as a commitment by Digital      *
...\" Equipment Corporation.                                             *
...\"                                                                    *
...\" ********************************************************************
.H 1 "Thread Concepts and Operations"
.PP
This chapter discusses concepts and techniques related to DCE Threads.
The following topics are covered:
.ML
.LI
Thread operations
.LI
New primitives
.LI
Attributes objects
.LI
Synchronization objects
.LI
One-time initialization code
.LI
Thread-specific data
.LI
Thread cancellation
.LI
Thread scheduling
.LE
.PP
For detailed information on the multithreading routines referred to in this
chapter, see the reference page for that routine in the \*(Dr.
.H 2 "Thread Operations"
.PP
.iX "thread" "states"
A thread changes states as it runs, waits to synchronize, or is ready 
to be run.  A thread is in one of the following states:
.ML
.LI
Waiting
.P
The thread is not eligible to execute because it is
synchronizing with another thread or with an external event.
.LI
Ready
.P
The thread is eligible to be executed by a processor.
.LI
Running
.P
The thread is currently being executed by a processor.
.LI
Terminated
.P
The thread has completed all of its work.
.LE
.PP
Figure 7-1 shows the transitions between states for a
typical thread implementation.
.P
.iX "thread" "state transitions"
.iX "state transitions, threads"
.FG "Thread State Transitions"
.pI ../threads/figures/1_intro_10.ps 0 0 1
.PP
The operations that you can perform include starting, 
waiting for, terminating, and deleting threads.
.H 3 "Starting a Thread"
.PP
.iX "starting" "threads"
.iX "creating" "threads"
.iX "thread" "starting"
.iX "thread" "creating"
To start a thread, create it using the \*Lpthread_create(\|)\*O routine.
This routine creates the thread, assigns specified or default
attributes, and starts execution of the function you specified as the
thread's start routine.  A unique identifier (handle) for that thread 
is returned from the \*Lpthread_create(\|)\*O routine.
.H 3 "Terminating a Thread"
.PP
.iX "thread" "terminating"
.iX "terminating" "threads"
A thread exists until it terminates and the \*Lpthread_detach(\|)\*O
.iX "-[" "pthread functions"
routine is called for the thread.  The \*Lpthread_detach(\|)\*O routine can be
called for a thread before or after it terminates.  If the thread 
terminates before \*Lpthread_detach(\|)\*O is called for it, then the 
thread continues to exist and can be 
synchronized (joined) until it is detached. 
Thus, the object (thread) can be detached by any thread that has access 
to a handle to the object.
.PP
Note that \*Lpthread_detach(\|)\*O 
must be called to release the memory allocated
for the thread objects so that this storage does not build up and cause the
process to run out of memory.  For example, after a thread returns from a call
to join, it detaches the joined-to thread if no other threads 
join with it.  Similarly, if a thread has no other threads joining with
it, it detaches itself so that its thread object is deallocated as
soon as it terminates.
.PP
A thread terminates for any of the following reasons:
.ML
.LI
The thread returns from its start routine; this is the usual case.
.LI
The thread calls the \*Lpthread_exit(\|)\*O routine.
.PP
The \*Lpthread_exit(\|)\*O routine terminates the calling thread and
returns a status value, indicating the thread's exit status to any 
potential joiners.
.LI
The thread is canceled by a call to the \*Lpthread_cancel(\|)\*O
routine.
.PP
The \*Lpthread_cancel(\|)\*O routine requests termination of a specified
thread if cancellation is permitted. (See Section 7.7 for more
information on canceling threads and controlling whether or not cancellation
is permitted.)
.LI
An error occurs in the thread.
.PP
Examples of errors that cause thread termination are programming errors,
segmentation faults, or unhandled exceptions.
.LE
.H 3 "Waiting for a Thread to Terminate"
.PP
.iX "waiting" "for a thread to terminate"
.iX "thread" "waiting for another to terminate"
A thread waits for the termination of another thread by calling the
\*Lpthread_join(\|)\*O routine. 
Execution in the current thread is
suspended until the specified thread terminates.  If multiple threads call
this routine and specify the same thread, all threads resume execution when
the specified
thread terminates.
.PP
If you specify the current thread with the \*Lpthread_join(\|)\*O routine,
a deadlock results.
.PP
Do not confuse \*Lpthread_join(\|)\*O with other routines that cause waits
and that are related to the use of a particular multithreading feature.  For
example, use \*Lpthread_cond_wait(\|)\*O or 
\*Lpthread_cond_timedwait(\|)\*O 
to wait
for a condition variable to be signaled or broadcast.
.H 3 "Deleting a Thread"
.PP
.iX "deleting" "threads"
.iX "thread" "deleting"
A thread is automatically deleted after it terminates; that is, no explicit
deletion operation is required.  Use 
\*Lpthread_detach(\|)\*O to free the storage of a terminated thread. 
Use \*Lpthread_cancel(\|)\*O to request that a running thread terminate 
itself.
.PP
If the thread has not yet terminated, the
\*Lpthread_detach(\|)\*O routine marks the thread for deletion, and its
storage is reclaimed immediately when the thread terminates.  A thread cannot
be joined or canceled after the \*Lpthread_detach(\|)\*O routine is called for
the thread, even if the thread has not yet terminated.
.PP
If a thread that is not detached terminates, its storage remains so
that other threads can join with it.  Storage is reclaimed when the thread is
eventually detached.
.PP
.H 2 "New Primitives"
.PP
Routines implemented by DCE Threads that are not specified
by Draft 4 of the POSIX 1003.4a standard are indicated by an \*L_np\*O
suffix to the name.  These routines have not been incorporated into the
POSIX standard, and as such are extensions to that document.  The routines
are fully portable.
.H 2 "Attributes Objects"
.PP
.iX "attributes" "object" "definition of"
An attributes object 
.gL "attributes object"
is used to describe the behavior of threads, mutexes, and
condition variables.  This description consists of the individual attribute
values that are used to create an attributes object.  Whether an 
attribute is valid depends on whether it describes threads, mutexes, or 
condition variables.
.PP
When you create an object, you can accept the default attributes for 
that object, or you can specify an attributes object 
that contains individual attributes that you
have set.  For a thread, you can also change one or more attributes after
thread execution starts; for example, calling the 
\*Lpthread_setprio(\|)\*O 
routine to change the priority that you 
specified with the \*Lpthread_attr_setprio(\|)\*O routine.
.PP
The following subsections describe how to create and delete attributes objects
and describe the individual attributes that you can specify for different
objects.
.H 3 "Creating an Attributes Object"
.PP
.iX "attributes" "object" "creating"
.iX "creating" "attributes object"
To create an attributes object, use one of the following routines, depending
on the type of object to which the attributes apply:
.ML
.LI
The \*Lpthread_attr_create(\|)\*O routine for thread attributes objects
.LI
The \*Lpthread_condattr_create(\|)\*O routine for condition variable attributes
objects
.LI
The \*Lpthread_mutexattr_create(\|)\*O routine for mutex attributes objects
.LE
.PP
These routines create an attributes object containing default values for the
individual attributes.  To modify any attribute values in an attributes
object, use one of the set routines described in the following subsections.
.PP
Creating an attributes object or changing the values in an attributes object
does not affect the attributes of objects previously created.
.H 3 "Deleting an Attributes Object"
.PP
.iX "attributes" "object" "deleting"
.iX "deleting" "attributes object"
To delete an attributes object, use one of the following routines:
.ML
.LI
The \*Lpthread_attr_delete(\|)\*O routine for thread attributes objects
.LI
The \*Lpthread_condattr_delete(\|)\*O routine for condition variable attributes
objects
.LI
The \*Lpthread_mutexattr_delete(\|)\*O routine for mutex attributes objects
.LE
.PP
Deleting an attributes object does not affect the attributes of objects
previously created.
.H 3 "Thread Attributes"
.PP
.iX "attributes" "thread"
.iX "thread" "attributes"
A thread attributes object allows you to specify values for thread
attributes other than the defaults when you create a thread with the
\*Lpthread_create(\|)\*O routine. 
To use a thread attributes object,
perform the following steps:
.iX "using a thread attributes object"
.AL
.LI
Create a thread attributes object by calling the routine
\*Lpthread_attr_create(\|)\*O.
.LI
Call the routines discussed in the following subsections to set the
individual attributes of the thread attributes object.
.LI
Create a new thread by calling the \*Lpthread_create(\|)\*O 
routine and specifying the identifier of the thread attributes object.
.LE
.PP
.ne 8
You have control over the following attributes of a new thread:
.ML
.LI
Scheduling policy attribute
.LI
Scheduling priority attribute
.LI
Inherit scheduling attribute
.LI
Stacksize attribute
.LE
.H 4 "Scheduling Policy Attribute"
.iX "attributes" "scheduling policy"
.iX "FIFO (First in, First out) scheduling"
.iX "RR (Round Robin) scheduling"
.iX "scheduling" "policy attribute"
.iX "-[" "threads" "scheduling"
.PP
The scheduling policy attribute describes the overall scheduling
policy of the threads in your application.  A thread has one of the
following scheduling policies:
.ML
.LI
\*LSCHED_FIFO\*O (First In, First Out)
.P
The highest-priority thread runs
until it blocks.  If there is more than one thread with the same priority,
and that priority is the highest among other threads, the first thread to
begin running continues until it blocks.
.LI
\*LSCHED_RR\*O (Round Robin)
.P
The highest-priority thread runs until
it blocks; however, threads of equal priority, if that priority is the
highest among other threads, are timesliced. 
.gL "timesliced."
.iX "timeslice"
(Timeslicing is a mechanism that ensures that every thread is allowed time
to execute by preempting running threads at fixed intervals.)
.LI
\*LSCHED_OTHER, SCHED_FG_NP\*O (Default)
.P
All threads are timesliced.
\*LSCHED_OTHER\*O and \*LSCHED_FG_NP\*O do the same thing; however, \*LSCHED_FG_NP\*O
is simply more precise terminology.  The \*LFG\*O stands for \*Vforeground\*O 
and the \*LNP\*O for \*Vnew primitive\*O.  All threads running under
the \*LSCHED_OTHER\*O and \*LSCHED_FG_NP\*O policy, regardless of priority,
receive some scheduling.  Therefore, no thread is completely denied
execution time.  However, \*LSCHED_OTHER\*O and \*LSCHED_FG_NP\*O threads
can be denied execution time by \*LSCHED_FIFO\*O or \*LSCHED_RR\*O threads.
.LI
.ne 7
\*LSCHED_BG_NP\*O (Background)
.P
Like \*LSCHED_OTHER\*O and 
\*LSCHED_FG_NP\*O, \*LSCHED_BG_NP\*O  ensures that all threads, 
regardless of priority, 
receive some scheduling.  However, \*LSCHED_BG_NP\*O can be denied 
execution by the \*LSCHED_FIFO\*O or \*LSCHED_RR\*O policies.
The \*LBG\*O stands for \*Vbackground\*O.
.LE
.PP
The following two methods are used to set the scheduling policy attribute:
.ML
.LI
Set the scheduling policy attribute in the attributes object, which
establishes the scheduling policy of a new thread when it is created.  To do
this, call the \*Lpthread_attr_setsched(\|)\*O routine.
.LI
.ne 4
Change the scheduling policy of an existing thread (and, at the same
time, the scheduling priority) by calling the 
\*Lpthread_setscheduler(\|)\*O routine.
.LE
.PP
Section 7.8 describes and shows the effect of scheduling policy 
on thread scheduling.
.H 4 "Scheduling Priority Attribute"
.iX "attributes" "scheduling priority"
.iX "scheduling"
.iX "thread" "scheduling" "priority attribute"
.PP
The scheduling priority attribute specifies the execution of a 
thread.  This attribute is expressed relative to other threads on a continuum
of minimum to maximum for each scheduling policy.  A thread's priority falls
within one of the following ranges, which are implementation defined:
.ML
.LI
\*LPRI_FIFO_MIN\*O to \*LPRI_FIFO_MAX\*O
.LI
\*LPRI_RR_MIN\*O to \*LPRI_RR_MAX\*O
.LI
\*LPRI_OTHER_MIN\*O to \*LPRI_OTHER_MAX\*O
.LI
\*LPRI_FG_MIN_NP\*O to \*LPRI_FG_MAX_NP\*O
.LI
\*LPRI_BG_MIN_NP\*O to \*LPRI_BG_MAX_NP\*O
.LE
.PP
The following two methods are used to set the scheduling priority
attribute:
.ML
.LI
Set the scheduling priority attribute in the attributes object, which
establishes the execution priority of a new thread when it is created.  To do
this, call the \*Lpthread_attr_setprio(\|)\*O routine.
.LI
Change the scheduling priority attribute of an existing thread by
calling the \*Lpthread_setprio(\|)\*O routine. (Call the 
\*Lpthread_setscheduler(\|)\*O routine to change both the scheduling
priority and scheduling policy of an existing thread.)
.LE
.H 4 "Inherit Scheduling Attribute"
.iX "attributes" "inherit scheduling"
.iX "inherit scheduling attribute"
.iX "-]" "threads" "scheduling"
.iX "scheduling"
.PP
The inherit scheduling attribute specifies whether a newly created thread
inherits the scheduling attributes (scheduling priority and policy) of the
creating thread (the default), or uses the scheduling attributes stored in
the attributes object.  Set this attribute by calling the routine
\*Lpthread_attr_setinheritsched(\|)\*O.
.H 4 "Stacksize Attribute"
.iX "attributes" "stacksize"
.iX "stacksize attribute"
.iX "memory" "setting for thread stack"
.PP
The stacksize attribute is the minimum size (in bytes) of the memory
required for a thread's stack.  The default value is machine dependent.
Set this attribute by calling the \*Lpthread_attr_setstacksize(\|)\*O routine.
.H 3 "Mutex Attributes"
.iX "attributes" "mutex type"
.iX "mutex" "type attribute"
.PP
A mutex attributes object allows you to specify values for mutex
attributes other than the defaults when you create a mutex with the
routine \*Lpthread_mutex_init(\|)\*O.
.PP
The mutex type attribute specifies whether a mutex is fast, 
recursive, or nonrecursive.  Set 
the mutex type attribute by calling the routine
\*Lpthread_mutexattr_setkind_np(\|)\*O.  (Any routine with the 
\*L_np\*O suffix is a new primitive; see Section 7.2.)
If you do not use a mutex attributes object to select a mutex type, calling
the \*Lpthread_mutex_init(\|)\*O routine creates a fast mutex by default.
.H 3 "Condition Variable Attributes"
.iX "attributes" "condition variable"
.iX "condition variable" "attributes"
.PP
Currently, attributes affecting condition variables are not defined.
You cannot change any attributes in the condition variable attributes
object.
.PP
Section 7.4.2 describes the purpose and uses of condition
variables.
.H 2 "Synchronization Objects"
.PP
In a multithreaded program, you must use synchronization objects whenever
there is a possibility of corruption of shared data or conflicting
scheduling of threads that have mutual scheduling dependencies.  The
following subsections discuss two kinds of 
synchronization objects: mutexes and condition variables.
.H 3 "Mutexes"
.PP
.iX "synchronization objects" "mutex"
.iX "-[" "mutex"
A mutex 
.gL "mutex"
(\*Emut\*Oual \*Eex\*Oclusion) is an object
that multiple threads use
to ensure the integrity of a shared resource that they access, most commonly
shared data.
A mutex has two states: locked and unlocked.  For each piece of shared data,
all threads accessing that data must use the same mutex; each thread locks the
mutex before it accesses the shared data and unlocks the mutex when it is
finished accessing that data.  If the mutex is locked by another
thread, the thread requesting the lock is blocked when it tries to 
lock the mutex if you call \*Lpthread_mutex_lock(\|)\*O (see Figure 7-2).  
The blocked thread continues and is not blocked if you call 
\*Lpthread_mutex_trylock(\|)\*O.
.P
.ne 2.5i
.FG "Only One Thread Can Lock a Mutex"
.pI ../threads/figures/2_concepts_04.ps 2.3i 1i
.sp .5
.PP
Each mutex must be initialized. (To initialize mutexes as part of the program's
one-time initialization code, see Section 7.5.) To initialize a mutex,
use the \*Lpthread_mutex_init(\|)\*O routine. 
This routine allows you to
specify an attributes object, which allows you to specify the mutex type.
The following are types of mutexes:
.ML
.LI
A fast mutex 
.gL "fast mutex"
(the default) is locked only once by a thread.
If the thread tries to lock the mutex again without first unlocking it, the
thread waits for itself to release the first lock and deadlocks on itself.
.PP
This type of mutex is called \*Efast\*O because it
can be locked and unlocked more rapidly than a recursive mutex.  It is the
most efficient form of mutex.
.LI
A recursive mutex 
.gL "recursive mutex"
can be locked more than once by a given
thread without causing a deadlock.  The thread must call the 
\*Lpthread_mutex_unlock(\|)\*O routine 
the same number of times that it
called the \*Lpthread_mutex_lock(\|)\*O 
routine before another thread can
lock the mutex.  Recursive mutexes have the notion of a mutex owner.  
When a thread successfully locks a recursive mutex, it owns that mutex 
and the lock count is set to 1. Any other thread attempting to lock 
the mutex blocks until the mutex becomes unlocked.  If the owner 
of the mutex attempts to lock the mutex again, the lock count is 
incremented, and the thread continues running.  When an owner unlocks a 
recursive mutex, the lock count is decremented.  The mutex remains 
locked and owned until the count reaches 0 (zero).  It is an error for any 
thread other than the owner to  attempt to unlock the mutex.
.PP
.ne 4
A recursive mutex is useful if a thread needs exclusive
access to a piece of data, and it needs to call another routine (or itself)
that needs exclusive access to the data.  A recursive mutex allows nested
attempts to lock the mutex to succeed rather than deadlock.
.PP
This type of mutex requires more careful programming.
Never use a recursive mutex with condition variables because the
implicit unlock performed for a \*Lpthread_cond_wait(\|)\*O 
or 
\*Lpthread_cond_timedwait(\|)\*O 
may not actually release the mutex.  In
that case, no other thread can satisfy the condition of the predicate.
.LI
.gL "nonrecursive mutex"
A nonrecursive mutex is locked only once by a thread, like a
fast mutex.  If the thread tries to lock the mutex again without first
unlocking it, the thread receives an error.  Thus, nonrecursive
mutexes are more informative than fast mutexes because fast mutexes
block in such a case, leaving it up to you to determine why the
thread no longer executes.  Also, if someone other than the owner tries
to unlock a nonrecursive mutex, an error is returned.
.LE
.PP
To lock a mutex, use one of the following routines, depending on what you
want to happen if the mutex is locked:
.ML
.LI
The \*Lpthread_mutex_lock(\|)\*O routine
.PP
If the mutex is locked, the thread waits for the mutex to become
available.
.LI
The \*Lpthread_mutex_trylock(\|)\*O routine
.PP
If the mutex is locked, the thread continues without waiting for the
mutex to become available.  The thread immediately checks the return status
to see if the lock was successful, and then takes whatever action is
appropriate if it was not.
.LE
.PP
When a thread is finished accessing a piece of shared data, it unlocks the
associated mutex by calling the \*Lpthread_mutex_unlock(\|)\*O routine.
.PP 
If another thread is waiting on the mutex, its execution is unblocked.  If more
than one thread is waiting on the mutex, the scheduling policy 
and the thread scheduling priority determine which thread acquires the mutex.
.PP
You can delete a mutex and reclaim its storage by calling the 
\*Lpthread_mutex_destroy(\|)\*O routine. 
Use this routine only after the
mutex is no longer needed by any thread.  Mutexes are automatically
deleted when the program terminates.
.iX "-]" "mutex"
.H 3 "Condition Variables"
.PP
.iX "synchronization objects"
.iX "-[" "condition variable"
A condition variable
.gL "condition variable"
allows a thread to block its own execution
until some shared data reaches a particular state.  Cooperating threads check
the shared data and wait on the condition variable.  For example, one thread
in a program produces work-to-do packets and another thread consumes these
packets (does the work).  If the work queue is empty when the consumer thread
checks it, that thread waits on a work-to-do condition variable.  When the
producer thread puts a packet on the queue, it signals the work-to-do
condition variable.
.PP
A condition variable is used to wait for a shared resource to assume 
some specific state (a predicate).  A mutex, on the other hand, is used 
to reserve some shared resource while the resource is being 
manipulated.
For example, a thread A may need to wait for a thread B to finish a 
task X before thread A proceeds to execute a task Y. Thread B can 
tell thread A that it has finished task X by using a variable they 
both have access to, a condition variable.  When thread A is ready to 
execute task Y, it looks at the condition variable to see if thread B 
is finished (see Figure 7-3).
.P
.FG "Thread A Waits on Condition Ready, Then Wakes Up and Proceeds"
...\" .pI ../threads/figures/2_concepts_02.ps 0 0 1
.sp .2
.PS
.in +.5i
scale = 100
"\fR\s8wait\s8\fR"  at 248, 220
"\fR\s8thread)\s8\fR"  at 40, 204
"\fR\s8(transparent to\s8\fR"  at 40, 220
"\fR\s8System activity\s8\fR"  at 40, 236
circle radius 40 at 144, 212
ellipse wid 56 ht 32 at 332, 212
line ->  from 144, 172 \
	to 144, 148 \
	to 328, 148 
"\fR\s8YES\s8\fR"  at 328, 236
"\fR\s8NO\s8\fR"  at 288, 212
line ->  from 272, 212 \
	to 208, 212 
"\fR\s8(unlock)\s8\fR"  at 144, 236
"\fR\s8(lock)\s8\fR"  at 144, 204
"\fR\s8proceed\s8\fR"  at 56, 340
"\fR\s8and unlock\s8\fR"  at 56, 308
line ->  from 88, 324 \
	to 8, 324 
line ->  from 328, 252 \
	to 328, 324 \
	to 208, 324 
ellipse wid 112 ht 40 at 328, 32
line ->  from 232, 12 \
	to 232, 36 \
	to 264, 36 
"\fR\s8lock\s8\fR"  at 240, 44
"\fR\s8Thread A\s8\fR"  at 232, 4
line ->  from 328, 52 \
	to 328, 196 
"\fR\s8predicate\s8\fR"  at 360, 76
"\fR\s8read\s8\fR"  at 344, 84
ellipse wid 112 ht 40 at 152, 320
"\fB\s8wait\s8\fR"  at 144, 220
"\fB\s8mutex_ready\s8\fR"  at 152, 324
"\fB\s8ready\s8\fR"  at 328, 212
"\fB\s8mutex_ready\s8\fR"  at 328, 36
box dashed wid 0 ht 0 at 64, 268
box dashed wid 112 ht 112 at 144, 212
.in
.PE
.sp .5
.PP
.ne 9
.iX "condition variable" "diagram of"
First, thread A locks the mutex named \*Lmutex_ready\*O that is associated 
with the condition variable.  Then it reads the predicate associated 
with the condition variable 
named \*Lready\*O.  If the predicate indicates that thread B has 
finished task X, then thread A can unlock the mutex and proceed with 
task Y.  If the condition variable predicate indicated 
that thread B has not yet finished task X, 
however, then thread A waits for the condition variable to change.  Thread A 
calls the \*Lwait\*O primitive.  Waiting on the condition variable 
automatically unlocks the mutex, 
allowing thread B to lock the mutex when it has finished task X 
(see Figure 7-4).
.P
.FG "Thread B Signals Condition Ready"
.pI ../threads/figures/2_concepts_03.ps 0 0 1
.sp .5
.PP
.ne 3
.iX "condition variable" "figure of"
Thread B updates the predicate named 
\*Lready\*O associated with the condition variable to the state thread 
A is waiting for.  It also executes a signal on the condition variable 
while holding the mutex \*Lmutex_ready\*O.
.P
.ne 2.5i
.FG "Thread A Wakes Up and Proceeds"
.pI ../threads/figures/2_concepts_04.ps 2.3i 1i
.sp .5
.PP
Thread A wakes up, verifies that the condition variable is in the 
correct state, and proceeds to execute task Y (see Figure 7-3).
.PP
Note that, although the condition variable is used for explicit 
communications among threads, the communications are anonymous.  Thread B 
does not necessarily know that thread A is waiting on the condition 
variable that thread B signals.  And thread A does not know that it 
was thread B that woke it up from its wait on the condition variable.
...\" You must associate a condition variable with a mutex.  A thread locks a mutex
...\" for some shared data and then checks whether or
...\" not the shared data is in the proper state.  If it is not in the proper
...\" state, the thread waits on the appropriate condition variable.  Waiting on
...\" the condition variable unlocks the
...\" mutex.  It is essential that the mutex be unlocked because another thread
...\" needs to acquire the mutex in order to put the data in the appropriate state
...\" for the waiting thread.  When the thread that acquires the mutex puts the
...\" data in the appropriate state, it wakes
...\" a waiting thread by signaling the condition variable.  One thread comes out
...\" of its wait state with the mutex locked (the thread relocks the mutex before
...\" returning from the wait); other threads waiting on the condition variable
...\" remain blocked.
.PP
Use the \*Lpthread_cond_init(\|)\*O routine 
to create a condition variable.
To create condition variables as part of the program's one-time
initialization code, see Section 7.5.
.PP
Use the \*Lpthread_cond_wait(\|)\*O routine to cause a thread to wait
until the condition is signaled or broadcast.
This routine specifies a condition variable and a mutex that you have
locked. (If you have not locked the mutex, the results of 
\*Lpthread_cond_wait(\|)\*O 
are unpredictable.) This routine unlocks the
mutex and causes the calling thread to wait on the condition variable until
another thread calls one of the following routines:
.ML
.LI
The \*Lpthread_cond_signal(\|)\*O 
routine to wake one thread that is waiting on the
condition variable
.LI
The \*Lpthread_cond_broadcast(\|)\*O 
routine to wake all threads that are waiting
on a condition variable
.LE
.PP
If you want to limit the time that a thread waits for a condition to be
signaled or broadcast, use the \*Lpthread_cond_timedwait(\|)\*O routine.
This routine specifies the condition variable, mutex, and absolute time at
which the wait should expire if the condition variable is not signaled
or broadcast.
.PP
You can delete a condition variable and reclaim its storage by calling the
\*Lpthread_cond_destroy(\|)\*O routine. 
Use this routine only after the
condition variable is no longer needed by any thread.  Condition variables
are automatically deleted when the program terminates.
.iX "-]" "condition variable"
.H 3 "Other Synchronization Methods"
.PP
.iX "join primitive"
.iX "synchronization methods"
There is another synchronization method that is not anonymous: the 
\*Ljoin\*O primitive.  This allows a thread to wait for another 
specific thread to complete its execution.  When the second thread is
finished, the first thread unblocks and continues its execution.  
Unlike mutexes and condition variables, the \*Ljoin\*O primitive is not 
associated with any particular shared data.
.H 2 "One-Time Initialization Routines"
.PP
.iX "initialization routines, one-time"
.iX "one-time initialization routines"
You probably have one or more routines that must be executed \*Ebefore\*O
any thread executes code in your application, but must be executed 
\*Eonly once\*O
regardless of the sequence in which threads start executing.  For example,
you may want to create mutexes and condition variables (each of which must
be created only once) in an initialization routine.
Multiple threads can call the \*Lpthread_once(\|)\*O 
routine, or 
the \*Lpthread_once(\|)\*O 
routine can be called multiple times in the same thread,
resulting in only one call to the specified routine.
.PP
Use the \*Lpthread_once(\|)\*O routine to ensure that your application 
initialization routine is executed only a single time; that is, by the 
first thread that tries to initialize the application.  
This routine is the only way to guarantee that one-time 
initialization is performed in a multithreaded environment 
on a given platform.  The \*Lpthread_once(\|)\*O
routine is of particular use for runtime libraries, which are often 
called for the first time after multiple threads are created.
.PP
Refer to the \*Lthr_intro(3thr)\*O reference page for a list of the
DCE Threads routines which, when called, implicitly perform any necessary
initialization of the threads package.  Any application that uses DCE Threads
must call one of these routines before calling any other threads routines.
.H 2 "Thread-Specific Data"
.PP
.iX "thread-specific data"
.iX "data" "thread-specific"
...\" Each thread has an area in which thread-specific context information is
...\" kept.
...\" You can also associate arbitrary data with a thread's context.  That is, you
...\" can think of this as the ability to add one or more user-specified fields to
...\" the current thread's context.
The thread-specific data interfaces allow each thread to associate an 
arbitrary value with a shared key value created by the program.
.PP
Thread-specific data is like a global variable in which each thread can keep
its own value, but is accessible to the thread anywhere in the program.
.PP
Use the following routines to create and access thread-specific data:
.ML
.LI
The \*Lpthread_keycreate(\|)\*O routine to create a unique key value
.LI
The \*Lpthread_setspecific(\|)\*O routine to associate data with a key
.LI
The \*Lpthread_getspecific(\|)\*O 
routine to obtain the data associated with a key
.LE
.PP
The \*Lpthread_keycreate(\|)\*O routine generates a unique key value
that is shared by all threads in the process. 
This key is the identifier of a piece of thread-specific data.  
Each thread uses the 
same key value to assign or retrieve a thread-specific value.
This keeps your data separate
from other thread-specific data.  One call to the \*Lpthread_keycreate(\|)\*O 
routine creates a cell in all threads.
Call this routine to specify a routine to be called to destroy the context
value associated with this key when the thread terminates.
.PP
The \*Lpthread_setspecific(\|)\*O routine associates the address of some
data with a specific key. 
Multiple threads associate different data (by
specifying different addresses) with the same key.  For example, each thread
points to a different block of dynamically allocated memory that it has
reserved.
.PP
The \*Lpthread_getspecific(\|)\*O routine obtains the address of the
thread-specific data value associated with a specified key.  Use this routine
to locate the data associated with the current thread's context.
.H 2 "Thread Cancellation"
.PP
.iX "canceling a thread" 
.iX "thread" "canceling"
.gL "Canceling"
Canceling is a mechanism by which one thread terminates another
thread (or itself).  When you request that a thread be canceled, you are
requesting that it terminate as soon as possible.  However,
the target thread
can control how quickly it terminates by controlling its general
cancelability and its asynchronous cancelability.
.PP
The following is a list of the pthread calls that are cancellation 
points:
.ML
.LI
The \*Lpthread_setasynccancel(\|)\*O routine
.LI
The \*Lpthread_testcancel(\|)\*O routine
.LI
The \*Lpthread_delay_np(\|)\*O routine
.LI
The \*Lpthread_join(\|)\*O routine
.LI
The \*Lpthread_cond_wait(\|)\*O routine
.LI
The \*Lpthread_cond_timedwait(\|)\*O routine
.LE
.PP
.iX "thread" "canceling"
.iX "general cancelability"
.gL "General cancelability"
General cancelability is enabled by default.  A thread is canceled
only at specific places in the program; for example, when a call to the
\*Lpthread_cond_wait(\|)\*O 
routine is made.  If general cancelability is
enabled, request the delivery of any pending cancel request by using the
\*Lpthread_testcancel(\|)\*O 
routine.  This routine allows you to permit
cancellation to occur at places where it may not otherwise be permitted
under general cancelability, and it is especially useful within very long
loops to ensure that cancel requests are noticed within a reasonable time.
.PP
If you disable general cancelability, the thread cannot be terminated by any
cancel request.  Disabling general cancelability means that a thread could
wait indefinitely if it does not come to a normal conclusion; therefore, be
careful about disabling general cancelability.
.PP
.iX "thread" "canceling"
.iX "asynchronous cancelability"
.gL "Asynchronous cancelability"
Asynchronous cancelability, when it is enabled, allows cancels to be 
delivered to the enabling thread at any time, not only at those times 
that are permitted when just general cancelability is enabled.
Thus, use asynchronous cancellation primarily during long processes 
that do not have specific places for cancel requests.
Asynchronous cancelability is disabled by default.  Disable asynchronous 
cancelability when calling threads routines or any other runtime library 
routines that are not explicitly documented as cancel-safe.
.nS note
If general cancelability is disabled, the thread cannot be canceled,
regardless of whether asynchronous cancelability is enabled or disabled.  The
setting of asynchronous cancelability is relevant only when general
cancelability is enabled.
.nE
.PP
Use the following routines to control the canceling of threads:
.ML
.LI
The \*Lpthread_setcancel(\|)\*O 
routine to enable and disable general cancelability
.LI
The \*Lpthread_testcancel(\|)\*O 
routine to request delivery of a pending cancel to
the current thread
.LI
The \*Lpthread_setasynccancel(\|)\*O 
routine to enable and disable asynchronous cancelability
.LI
The \*Lpthread_cancel(\|)\*O routine to request that a thread be canceled
.LE
.iX "-]" "pthread functions"
.H 2 "Thread Scheduling"
.PP
.iX "-: threads, scheduling" "scheduling" "threads"
.iX "-[" "threads" "scheduling"
Threads are scheduled according to their scheduling priority and how the
scheduling policy treats those priorities.  To understand the discussion in
this section, you must understand the concepts in the following sections 
of this chapter:
.ML
.LI
Section (7.3.3.1) discusses scheduling policies, including the way in
which each policy handles thread scheduling priority.
.LI
Section (7.3.3.2) discusses thread scheduling priorities.
.LI
Section (7.3.3.3) discusses inheritance of scheduling
attributes by created threads.
.LE
.PP
To specify the minimum or maximum priority, use the appropriate symbol;
for example, \*LPRI_OTHER_MIN\*O or \*LPRI_OTHER_MAX\*O.  To
specify a value between the minimum and maximum priority, use an
appropriate arithmetic expression.  
.P
.ne 5
For example, to specify a priority
midway between the minimum and maximum for the default scheduling
policy, specify the following concept using your programming
language's syntax:
.oS
pri_other_mid = (PRI_OTHER_MIN + PRI_OTHER_MAX)/2
.oE
.PP
If your expression results in a value outside the range of minimum to
maximum, an error results when you use it.
Priority values are integers.
.PP
To show results of the different scheduling policies, consider the following
example: a program has four threads, called threads A, B, C, and D. For each
scheduling policy, three scheduling priorities have been defined: minimum,
middle, and maximum.  The threads have the priorities shown in Table 7-1.
.iX "thread" "priorities"
.iX "priority" "of scheduling routines"
.iX "scheduling"
.P
.TB "Sample Thread Proprities"
.TS
center,box,tab(%);
lb | lb
c | l.
Thread%Priority
=
A%Minimum
B%Middle
C%Middle
D%Maximum
.TE
.PP
Figures 7-6 through 7-8 show execution flows, depending on whether the 
threads use the 
\*LSCHED_FIFO\*O, \*LSCHED_RR\*O, or \*LSCHED_OTHER\*O (default)
scheduling policy.  Assume that all waiting threads are
ready to execute when the current thread waits or terminates and that
no higher-priority thread is awakened while a thread is executing
(during the flow shown in each figure).
.PP
Figure 7-6 shows a flow with  
\*LSCHED_FIFO\*O (First In, First Out) scheduling.
.P
.FG "Flow with SCHED_FIFO Scheduling"
.pI ../threads/figures/2_concepts_10.ps 0 0 1
.PP
Thread D executes until it waits or terminates, then Thread B starts because
it has been waiting longer than Thread C and it executes until it waits or
terminates, then Thread C executes until it waits or terminates, then Thread
A executes.
.PP
.ne 2i
Figure 7-7 shows a flow with \*LSCHED_RR\*O (Round Robin)
scheduling.
.P
.FG "Flow with SCHED_RR Scheduling"
.pI ../threads/figures/2_concepts_20.ps 0 0 1
.PP
All four threads are timesliced.  Threads with higher priority are 
generally scheduled when more than one thread is ready to run; 
however, to ensure fairness, all threads are given some time.  The 
effective priority of threads may be modified over time by the 
scheduler, depending on the use of processor resources.
.PP
Thread D executes until it waits or terminates, then threads B and C are
timesliced because they both have middle priority, then thread A executes.
.PP
Figure 7-8 shows a flow with \*LSCHED_OTHER\*O (default)
scheduling. 
.iX "-]" "threads" "scheduling"
.P
.FG "Flow with SCHED_OTHER Scheduling"
.pI ../threads/figures/2_concepts_30.ps .25i 3.8i
.PP
Thread D executes until it waits or terminates; then threads B, C, and A are
timesliced, even though thread A has a lower priority than the other two.
Thread A receives less execution time than thread B or C if either is ready
to execute as often as thread A is.  However, the default scheduling policy
protects thread A against being blocked from executing indefinitely.
.PP
Because low-priority threads eventually run, the default scheduling policy
protects against the problem of priority inversion discussed in 
Chapter 8.

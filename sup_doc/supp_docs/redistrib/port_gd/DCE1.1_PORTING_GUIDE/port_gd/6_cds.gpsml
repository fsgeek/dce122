...\" @OSF_COPYRIGHT@
...\" COPYRIGHT NOTICE
...\" Copyright (c) 1990, 1991, 1992, 1993, 1994 Open Software Foundation, Inc.
...\" ALL RIGHTS RESERVED (DCE).  See the file named COPYRIGHT.DCE for
...\" the full copyright text.
...\" 
...\" HISTORY
...\" $Log: 6_cds.gpsml,v $
...\" Revision 1.1.2.15  1994/10/30  22:47:42  weir
...\" 	Last updates
...\" 	[1994/10/30  22:46:42  weir]
...\"
...\" Revision 1.1.2.14  1994/10/30  16:25:45  weir
...\" 	Updates
...\" 	[1994/10/30  16:24:26  weir]
...\" 
...\" Revision 1.1.2.13  1994/10/29  23:26:06  weir
...\" 	More Updates
...\" 	[1994/10/29  23:24:51  weir]
...\" 
...\" Revision 1.1.2.12  1994/10/28  20:50:25  weir
...\" 	DCE 1.1 updates
...\" 	[1994/10/28  20:49:06  weir]
...\" 
...\" Revision 1.1.2.11  1994/10/26  20:40:58  weir
...\" 	DCE 1.1 Updates
...\" 	[1994/10/26  20:39:37  weir]
...\" 
...\" Revision 1.1.2.10  1994/10/14  18:39:03  weir
...\" 	Minor edit changes
...\" 	[1994/10/14  18:38:03  weir]
...\" 
...\" Revision 1.1.2.9  1994/06/20  21:39:50  weir
...\" 	Beta Update
...\" 	[1994/06/20  21:38:49  weir]
...\" 
...\" Revision 1.1.2.8  1994/06/20  20:28:54  weir
...\" 	Beta Update
...\" 	[1994/06/20  20:27:38  weir]
...\" 
...\" Revision 1.1.2.7  1994/06/19  20:54:04  weir
...\" 	Beta Update
...\" 	[1994/06/19  20:53:01  weir]
...\" 
...\" Revision 1.1.2.6  1994/06/17  13:50:31  weir
...\" 	Beta Update
...\" 	[1994/06/17  13:49:06  weir]
...\" 
...\" Revision 1.1.2.5  1994/06/13  19:25:38  devobj
...\" 	cr10872 - fix copyright
...\" 	[1994/06/13  19:24:44  devobj]
...\" 
...\" Revision 1.1.2.4  1994/06/12  17:32:09  weir
...\" 	No change-- for copyright insertion
...\" 	[1994/06/12  17:30:48  weir]
...\" 
...\" Revision 1.1.2.3  1994/06/08  18:47:29  weir
...\" 	Beta Update
...\" 	[1994/06/08  18:46:29  weir]
...\" 
...\" Revision 1.1.2.2  1994/06/02  21:12:49  weir
...\" 	Beta Updates
...\" 	[1994/06/02  21:11:08  weir]
...\" 
...\" Revision 1.1.2.1  1994/05/03  19:00:30  weir
...\" 	Reorganization
...\" 	[1994/05/03  18:59:17  weir]
...\" 
...\" $EndLog$
...\" 
...\" 
...\" 
...\"
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 1 "DCE Cell Directory Service"
...\" ----------------------------------------------------------------------
...\" 
...\" 
...\" 
...\" 
...\" 
...\" 
...\" 
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 2 "Overview"
...\" ----------------------------------------------------------------------
...\" 
...\" 
...\" 
.iX "-: CDS" "Cell Directory Service"
.iX "overview" "of CDS"
.iX "CDS" "overview of"
...\" 
.P
The DCE Cell Directory Service (CDS) provides the directory (naming) services
for use within a cell in a DCE environment. CDS allows users to assign names
to resources and then use those resources, without needing to know their
physical locations in the network. CDS uses the client/server model, and
provides both command line and programming interfaces for configuring services.
CDS services can be accessed through two Application Programming Interfaces
(APIs), provided as part of \*Llibdce.a\*O. The first is the X/Open Directory
Service (XDS) API, and the second is the Name Service Interface (NSI) of the
RPC component, which accesses CDS in an RPC-specific way.
.P
CDS allows clients to register named objects with the server and to bind a set
of attributes, including an object's network addresses, to these objects. An
object's attributes are stored in a distributed database, which is partitioned
and partially replicated. CDS is composed of three programs:
...\" 
.BL
.LI
\*Lcdsd\*O
.P
The CDS server. This program stores and maintains CDS names and handles requests
to create, modify, or look up data in the CDS database.
...\" 
.LI
\*Lcdsclerk\*O
.P
The CDS clerk. This is the interface between client applications and servers, and
it must exist on every node. Several of these may be running on each node since
one is spawned for each user.
...\" 
.LI
\*Lcdsadv\*O
.P
The CDS advertiser, the program which makes distributed CDS servers aware of each
other and known to clients. There must be one of these on every node.
...\" 
.LE
...\" 
.P
In addition to these, there is also the \*Lcdsbrowser\*O utility and the
\*Lcdscp\*O administration program (``CDS control program'').
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 3 "Considerations and Dependencies"
...\" ----------------------------------------------------------------------
...\" 
.iX "dependencies" "of CDS"
.iX "CDS" "dependencies"
...\" 
.P
Note the following:
.BL
.LI
CDS uses DCE Remote Procedure Call (RPC) for communications between clerks
and servers and for concurrency with DCE Threads. All supported protocol
sequences are enabled in DCE 1.0.2, with one exception: The CDS advertiser
(\*Lcdsadv\*O) uses RPC broadcast to find other CDS advertisers, and
RPC broadcast is only supported for datagram (connectionless) protocols.
Broadcast is supported only by some RPC protocols; in particular, it is
not supported by the connection-oriented protocol. If you do not have a
protocol available that supports broadcasts, the \*Lcdscp define cached
server\*O command can help your CDS clerk locate remote CDS servers.
(See the subsection ``Setting Up CDS Communications'' in Chapter 3 of this
guide.)
.LI
The CDS control program (\*Lcdscp\*O) manages the namespace and shows
the namespace structure and contents (attributes).
.LI
The CDS Browser (\*Lcdsbrowser\*O), an OSF/Motif application, allows
workstation users to view the cell namespace structure.
.LI
CDS uses support routines from other DCE components' libraries;
therefore, it is necessary to build the libraries from DCE Threads,
RPC, DTS, and Security before CDS can be built.
.LE
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 3 "CDS File Locations"
...\" ----------------------------------------------------------------------
...\" 
.iX "file locations" "CDS"
.iX "CDS" "file locations"
...\" 
.de ZY
\v'-3p'\\$1\v'3p'\s0
..
.P
The following table lists the locations of libraries and programs
built in CDS.
.P
All paths given for the location of source files
are relative from
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds\*O
.DE
.P
unless otherwise noted. The path indicates the directory in which the \*LMakefile\*O
attempts to build the component. A subcomponent can consist of multiple source files.
Complete source may not reside in this directory.
.P
All paths given for the location of installation are relative from
.DS
    \*Vdce-root-dir\*L/dce/install/\*Vmachine\*L/opt/dce1.1\*O
.DE
.P
unless otherwise noted by ``N/A.'' The path indicates the directory in which the
subcomponent is installed.
...\" 
.nP
...\" 
.TB "Locations of CDS Subcomponent Files"
.nL
.TS H
expand center tab (@) box;
lB | lB | lB | lB
lB | lB | lB | lB
lB | l | lB | lB.
CDS@@Location of@Location of
Subcomponent@Function@Source Files@Installation
_
.TH
_
\*Llibcdscache.a\*O@T{
CDS cache library used by \*Lcdsadv\*O and \*Lcdsclerk\*O
T}@cache@N/A\v'-3p'\\1\v'3p'\s0
_
\*Llibcds.a\*O@T{
CDS runtime library
T}@library@in libdce
_
\*Lcadump\*O@T{
Dumps contents of cache to a file.
T}@cache@N/A\v'-3p'\\2\v'3p'\s0
_
\*Lcatraverse\*O@T{
Dumps contents of cache to a file in data structure format.
T}@cache@N/A\v'-3p'\\2\v'3p'\s0
_
\*Lcdsclerk\*O@CDS clerk@child@bin
_
\*Lcdsd_diag\*O@T{
Server diagnostics interface
T}@server@N/A\v'-3p'\\2\v'3p'\s0
_
\*Lcds_dbdump\*O@T{
Dumps server database to a file.
T}@server@N/A\v'-3p'\\2\v'3p'\s0
_
\*Lcdsd\*O@CDS server@server@bin
_
\*Lparser_aid\*O@T{
Generates parse tables for \*Lcdscp\*O.
T}@control@N/A\v'-3p'\\1\v'3p'\s0
_
msg@T{
Message file converter for \*Lcdscp\*O
T}@control@N/A\v'-3p'\\1\v'3p'\s0
_
prs@T{
Parse table file converter for \*Lcdscp\*O
T}@control@N/A\v'-3p'\\1\v'3p'\s0
_
\*Lcdscp\*O@CDS control program@control@bin
_
\*Lcdscp.bpt\*O@Parses tables for \*Lcdscp\*O@control@etc
_
\*Lcdscp.mbf\*O@Parses tables for \*Lcdscp\*O@control@etc
_
\*Lcdsadv\*O@CDS advertiser@adver@bin
_
\*Lcdsbrowser\*O@CDS browser@cdsbrowser@bin
_
\*Lcds_attributes\*O@T{
Stores OIDs and types for CDS attributes.
T}@includes@etc
_
\*Lgds_attributes\*O@T{
Stores OIDs and types for GDS attributes.
T}@includes@etc
_
\*Lgdad\*O@GDA daemon@gda@bin
_
\*Lgda_clerk\*O@GDA test program@gda\*O@N/A\v'-3p'\\2\v'3p'\s0
_
.TE
...\" 
...\" 
.nL
.na
.ZY "1"
This item is not installed but is needed to build CDS.
.nL
.na
.ZY "2"
This item is not installed but is used for testing or debugging.
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 2 "Porting"
...\" ----------------------------------------------------------------------
...\" 
.iX "porting" "CDS"
.iX "CDS" "porting"
...\" 
.P
OSF\*(Tm DCE Version 1.1 contains CDS code ported to the reference
platforms listed in the section on ``Reference Platforms'' in Chapter
1 of this guide. When porting to a different platform, you may need to
modify the following files:
...\" 
.BL
.LI
\*Vdce-root-dir\*L/dce/src/directory/cds/includes/decnet_types.h\*O
.P
This file contains macros for accessing 8-bit, 16-bit, and 32-bit
fields within messages. You will need to define macros applicable to
your platform.
.LI
\*Vdce-root-dir\*L/dce/src/directory/cds/includes/dns_cdefs.h\*O
.P
This file determines if the compiler for a particular platform permits
ANSI prototypes, and if the compiler supports \*Lvoid *\*O pointers.
Add these definitions if your platform needs them.
.LI
\*Vdce-root-dir\*L/dce/src/directory/cds/includes/dns_record.h\*O
.P
Make sure the \*L#define\*O statements, especially the \*LMOVE.bytes\*O
statement to handle overlapping bytes, are correct for your system.
...\" 
...\" 
.LI
\*Vdce-root-dir\*L/dce/src/directory/cds/includes/triggers.h\*O
.P
If you need to include \*Lsys/select.h\*O, modify the following
\*L#ifdef\*O statement for your system:
...\" 
.oS
    #ifdef _\*Voperating_system\*C	
    #include <sys/select.h>
    #endif
.oE
...\" 
where \*Voperating_system\*O is your operating system.
.LE
...\" 
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 3 "Preprocessor Variables"
...\" ----------------------------------------------------------------------
...\" 
...\" 
...\" N.B.:
...\" While I don't have a description of CDS data structures I 
...\" can offer a header as a good starting point - dns_record.h which
...\" does describe many of them.
...\" 
...\" 
...\" .zA "Added conditional symbols"
...\" 
.P
The following C preprocessor variables are used in building DCE Threads.
...\" 
.VL .5i
...\" 
.LI
\*LARCH_BIG_ENDIAN\*O
.P
Defined in:
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds/includes/decnet_types.h\*O
.DE
.P
Machine has big-endian architecture.
...\" 
...\" 
.LI
\*LARCH_LITTLE_ENDIAN\*O
.P
Defined in:
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds/includes/decnet_types.h\*O
.DE
.P
Machine has little-endian architecture.
...\" 
...\" 
.LI
\*LDCE_SEC\*O
.P
Enable DCE Security code during compilation.
...\" 
...\" 
...\" 
.LI
\*LDEBUG\*O
.P
Used to turn on debugging for \*Lcdscp\*O, \*Lcdsd\*O, \*Lcdsclerk\*O,
\*Lcdsadv\*O, \*Lcdsd_diag\*O, and \*Lcdsbrowser\*O.
...\" 
...\" 
.LI
\*LDNS_CDS\*O
.P
Defined in:
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds/includes/cdsclerk.h\*O
.DE
.P
Compiles CDS instead of DNS.
...\" 
...\" 
...\" 
.LI
\*LDNS_CMA\*O
.P
Compiles code to use DCE Threads.
...\" 
...\" 
...\" 
...\" 
.LI
\*LDNS_V3API\*O
.P
Defined in:
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds/includes/cdsclerk.h\*O
.DE
.P
Turns on the CDS API.
...\" 
...\" 
...\" 
.LI
\*LNBPG\*O
.P
Defined in:
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds/cache/cadump.c\*O
    \*Vdce-root-dir\*L/dce/src/directory/cds/cache/casys.c\*O
    \*Vdce-root-dir\*L/dce/src/directory/cds/cache/catraverse.c\*O
    \*Vdce-root-dir\*L/dce/src/directory/cds/includes/dns_record.h\*O
.DE
.P
Number of bytes per page.
...\" 
...\" 
...\" 
.LI
\*LNSEC_PER_SEC\*O
.P
Defined in:
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds/library/unix_time.c\*O
.DE
.P
Nanoseconds per second.
...\" 
...\" 
...\" 
.LI
\*L_USER_THREADS_\*O
.P
User mode threads.
...\" 
...\" 
...\" 
.LE
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 4 "Other Variables"
...\" ----------------------------------------------------------------------
...\" 
.P
The following three symbols depend on what system clock interface is being used:
.VL .5i
.LI
\*LTL_TIMEQUAD\*O
.P
Defined in:
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds/includes/sys_time.h\*O
.DE
.P
\*Ltime_local_t\*O uses \*Ltimequad\*O.
...\" 
...\" 
.LI
\*LTL_TIMESPEC\*O
.P
Defined in:
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds/includes/sys_time.h\*O
.DE
.P
\*Ltime_local_t\*O uses \*Ltimespec\*O structure.
...\" 
...\" 
.LI
\*LTL_TIMEVAL\*O
.P
Defined in:
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds/includes/sys_time.h\*O
.DE
.P
\*Ltime_local_t\*O uses \*Ltimeval\*O structure.
.LE
...\" 
...\" 
...\" 
...\" 
...\" .LE
...\" 
...\" 
...\" 
...\" 
...\" 
...\" .zZ "Added conditional symbols"
...\" 
...\" 
...\" 
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 3 "Machine-Dependent Modules"
...\" ----------------------------------------------------------------------
...\" 
.P
When porting, you may need to modify or create the following C
language routines:
...\" 
.BL
...\" 
...\" 
.LI
\*Lgda_main.c\*O
.P
The
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds/gda/gda_main.c\*O
.DE
.P
file currently calls the \*Lsigsetmask(\|)\*O system call.
If your operating system calls \*Lsigprocmask(\|)\*O or another system
call in place of \*Lsigsetmask(\|)\*O, you can use an \*L#ifdef\*O
statement to determine what system call \*Lgda_main.c\*O calls.
These system calls take the same arguments.
The \*L#ifdef\*O statement appears as follows:
...\" 
.oS
    #ifdef _\*Voperating_system\*C
       (void) sigsetmask(SIG_SETMASK,int sig_set,(sigset_t *)NULL);
    #else
       (void) sigprocmask(SIG_SETMASK,int sig_set,(sigset_t *)NULL);
    #endif
.oE
...\" 
where \*Voperating_system\*O is your operating system.
...\" 
...\" 
...\" 
.LI
\*Lthreads_lib.c\*O
.P
The
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds/library/threads_lib.c\*O
.DE
.P
file has an include statement to pick up \*Lsys/select.h\*O.
.P
You may need to add an include of \*L/usr/include/sys/time.h\*O for
your operating system.
...\" 
...\" 
...\" 
.LI
\*Lunix_getaddr.c\*O
.P
Since some systems do not provide a system call to obtain the network
adapter address, the
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds/library/\*Vmachine/\*Lunix_getaddr.c\*O
.DE
.P
module obtains the hardware address of the network adapter (used as the
system identifier of a node on which a name is created).
There is no machine-independent way to obtain this address, so you must
create a \*Lunix_getaddr.c\*O module for your platform.
Use the code in the following files as algorithms when creating this module:
...\" 
.BL
.LI
\*Vdce-root-dir\*L/dce/src/directory/cds/library/RIOS/unix_getaddr.c\*O
.LI
\*Vdce-root-dir\*L/dce/src/directory/cds/library/MIPS/unix_getaddr.c\*O
.P
See also the following file:
.LI
\*Vdce-root-dir\*L/dce/src/rpc/runtime/\*Vmachine\*L/uuidsys.c\*O
.LE
...\" 
...\" 
...\" 
.LI
\*Lunix_qarith.c\*O
.P
The
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds/library/\*Vmachine\*L/unix_qarith.c\*O
.DE
.P
file contains several machine-dependent routines for manipulation of timestamps.
.LI
\*Lcasysinfo.c\*O
.P
The
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds/cache/\*Vmachine\*L/casysinfo.c\*O
.DE
.P
file contains machine-dependent code to calculate total machine memory size.
Use this code to check that the clerk cache is 0.5% of memory.
...\" 
...\" 
.LE
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 3 "Porting CDS to Other Kernel Pthreads Implementations"
...\" ----------------------------------------------------------------------
...\" 
.P
CDS is currently designed to use DCE Threads, the user space threads software
supplied with DCE. This section describes porting issues involved when porting
CDS to another kernel Pthreads environment. It is based on experience in porting
CDS to Pthreads on an OSF/1 platform. Several of the issues, especially the
Runtime Issues, may also be applicable to other DCE components that use DCE
Threads.
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 4 "Threads Porting Issues"
...\" ----------------------------------------------------------------------
...\" 
.AL
.LI
When porting CDS to kernel-based Pthreads, \*LDNS_CMA\*O must still be defined, even
though DCE Threads (referred to in the code as CMA) is not actually being used.
If DNS_CMA is not defined, CDS attempts to use internal threads software contained
in the file \*Lthreads_lib.c\*O. If \*LDNS_CMA\*O is defined, CDS assumes that
external threads software is being used. This can be DCE Threads, kernel-based
Pthreads, or some other threads environment.
.LI
Several files in the library directory define the following macros:
...\" 
.oS
    #ifndef DNS_CMA
    #  define DNS_LOCK
    #  define DNS_END_LOCK
    #else
    #  define DNS_LOCK	{ cma_init(\|); cma_lock_global(\|); }
    #  define DNS_END_LOCK	{ cma_unlock_global(\|); }
    #endif 
.oE
...\" 
.P
When using kernel-based Pthreads, the routines \*Lcma_init(\|)\*O, \*Lcma_lock_global(\|)\*O,
and \*Lcma_unlock_global(\|)\*O do not exist. These macros are used to protect system calls
such as \*Lfprintf(\|)\*O. Since it is assumed that thread-safe system calls exist, special
global locking and unlocking macros are not needed when using kernel-based Pthreads.
\*LDNS_LOCK\*O and \*LDNS_END_LOCK\*O should be defined to null when using kernel-based
Pthreads.
.P
The files containing these macros are:
...\" 
.BL
.LI
\*Ldeb_event_mgr.c\*O
.LI
\*Ldns_record.c\*O
.LI
\*Lgda_main.c \*O
.LI
\*Ltriggers_lib.c \*O
.LE
...\" 
.LI
The header file \*Ldnsclerk.h\*O defines the structure \*LdnsFlagStat\*O.
Within this structure is the element \*LfsOpqDNS\*O, which is a 5-element
array of \*Lunsigned long\*O. This element is intended to be an opaque
element used by the library code.
.P
The last two elements of this \*LfsOpqDNS\*O array are used as a Pthread
condition variable by the library file \*Ldnsread.c\*O. Unfortunately, using
the last two elements of the opaque array as a condition variable assumes 
knowledge of the size of \*Lpthread_cond_t\*O. Since the DCE Threads
\*Lpthread_cond_t\*O is not the same size as the \*Lpthread_cond_t\*O
defined for kernel-based Pthreads, this does not work. 
.P
To resolve the issue, modify the \*LfsOpqDNS\*O in the structure
\*LdnsFlagStat\*O to be a 3-element array rather than 5 and add the
element immediately after \*LfsOpqDNS\*O:
...\" 
.oS
    pthread_cond_t      fsOpqCND; 
.oE
...\" 
.P
Then modify the file \*Ldnsread.c\*O to change  all references to
\*LFlags_p->fsOpqDNS[OPQCND0]\*O to be \*LFlags_p->fsOpqCND\*O instead.
This causes the condition variable \*LfsOpqCND\*O to be used rather than
elements of the array.
.P
Also modify the routine \*LdnsInitFlagStat(\|)\*O in the file
\*Ldnsinitflagstat.c\*O to change the initialization of the
\*LdnsFlagStat\*O structure. 
.LI
Several files reference the type \*Lpthread_startroutine_t\*O
when calling \*Lpthread_create(\|)\*O. \*Lpthread_startroutine_t\*O
is specific to the DCE Threads version of \*Lpthread.h\*O. The \*Lpthread.h\*O
used with kernel-based Pthreads defines the \*Vstart_routine\*O parameter of
\*Lpthread_create(\|)\*O to be of type \*Lpthread_func_t\*O. The two versions
of \*Lpthread.h\*O need to be made consistent.
.LI
Several files reference the type \*Lpthread_destructor_t\*O when calling
\*Lpthread_keycreate(\|)\*O. \*Lpthread_destructor_t\*O is specific to the
DCE Threads version of \*Lpthread.h\*O. The \*Lpthread.h\*O used with
kernel-based Pthreads defines the \*Vdestructor\*O parameter of
\*Lpthread_keycreate(\|)\*O to be of type \*Lvoid *\*O. The two versions
of \*Lpthread.h\*O need to be made consistent. 
.LI
Several files reference the type \*Lpthread_addr_t\*O. This type is specific
to the DCE Threads version of \*Lpthread.h\*O. The \*Lpthread.h\*O for
kernel-based Pthreads uses \*Lany_t\*O instead. Again, the two versions of
\*Lpthread.h\*O need to be made consistent. 
.LI
The routine \*Ldthread_import_fd(\|)\*O in the file \*Lthreads_lib.c\*O
contains the following code:
...\" 
.oS
    #ifndef DNS_CMA
    fcntl(fd, F_SETFL, fcntl(fd, F_GETFL, 0) | FNDELAY);
    #else /* DNS_CMA */
    cma_import_fd(fd);
    #endif	/* !DNS_CMA */ 
.oE
...\" 
.P
When using kernel-based Pthreads, the call to \*Lcma_import_fd(\|)\*O does not
need to be made. This call should be taken out. Note, however, that you do \*Vnot\*O
want to make the call to \*Lfcntl(\|)\*O. Doing so will make the clerk/library socket
non-blocking, causing problems with the \*Lcdsclerk\*O.
.LI
Two \*Lsprintf(\|)\*O statements inside of the file \*Lgda_main.c\*O reference the
elements \*Lfield1\*O and \*Lfield2\*O of the \*Lpthread_t\*O structure. These two
fields are specific to the DCE Threads version of \*Lpthread.h\*O and thus should
not be referenced.       
.LE
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 4 "Threads and Runtime Issues"
...\" ----------------------------------------------------------------------
...\" 
.P
Once CDS is built and linked with kernel-based Pthreads, it is possible to
bring up CDS. However, at this point you will have to resolve the following
issues.
...\" 
.AL
.LI
The main routines for the advertiser, clerk, server, and GDA daemon have to be
modified so that the \*Lfork(\|)\*O to create the daemon process is done prior
to issuing any Pthreads calls.   
.P
This problem was found as a result of \*Ldthread_init(\|)\*O being called prior
to the \*Lfork(\|)\*O. \*Ldthread_init(\|)\*O calls \*Lpthread_keycreate(\|)\*O
to create a thread-specific data key. However, in kernel-based Pthreads, this
thread-specific information does not survive a \*Lfork(\|)\*O. Thus, the
thread-specific information was being lost after the \*Lfork(\|)\*O was
executed to create the daemon process. This caused problems later when calls
to \*Lpthread_setspecific(\|)\*O were made.
.P
Another reason for issuing the \*Lfork(\|)\*O earlier in the main routine is
that when using kernel-based Pthreads, only the thread issuing the
\*Lfork(\|)\*O call actually survives the \*Lfork(\|)\*O. In the advertiser,
a thread was being created for the \*Lsignal_catcher(\|)\*O routine before
the forking of the daemon was done. As a result, the \*Lsignal_catcher(\|)\*O
thread was not surviving the \*Lfork(\|)\*O.
.P
.LI
CDS was designed based on the knowledge that in DCE Threads, blocking system
calls such as \*Laccept(\|)\*O and \*Lread(\|)\*O are thread cancellation points.
Draft 4 of the Pthreads document (P1003.4a/D4) states that it is
implementation-defined whether a blocking system call is a cancellation point.
OSF/1 kernel-based Pthreads are designed to Draft 4 and so chose the option to
not consider such system calls as cancellation points.
.P
This causes problems if a thread is cancelled while it is blocked in one of these
calls. The result can be a hang of the thread because the thread being cancelled
does not honor the cancel while it is blocked.
.P
To resolve this problem, asynchronous cancellability must be enabled prior to
issuing the blocking system call and disabled after returning from the blocking
system call. Turning on asynchronous cancellability allows a thread to be cancelled
at any point, including during a blocking system call. Due to the danger of enabling
asynchronous cancellability, it is important disable it after returning from the
blocking call.
.P
This problem occurred at two locations in the \*Lcdsclerk\*O:
...\" 
.BL
.LI
The routine \*Lclerk_listener(\|)\*O in the file \*Lclerk_listener.c\*O should be
modified to issue a call to:
...\" 
.oS
    pthread_setasynccancel(CANCEL_ON);
.oE
...\" 
prior to issuing the call to \*Ldthread_accept(\|)\*O and issue a call to:
...\" 
.oS
    pthread_setasynccancel(CANCEL_OFF);
.oE
...\" 
after returning from \*Ldthread_accept(\|)\*O. \*Ldthread_accept(\|)\*O is a
blocking call. 
.LI
The routine \*Lclerk_client(\|)\*O in the file \*Lclerk_client.c\*O should be
modified to place a call to: 
...\" 
.oS
    pthread_setasynccancel(CANCEL_ON);
.oE
...\" 
prior to calling \*Lread_request(\|)\*O and issue a call to:
...\" 
.oS
    pthread_setasynccancel(CANCEL_OFF);
.oE
...\" 
after returning from \*Lread_request(\|)\*O. The routine \*Lread_request(\|)\*O
issues a call to \*Ldthread_read(\|)\*O, which is another blocking system call.
.LE
...\" 
.P
If asynchronous cancellability is not enabled prior to issuing these calls, the
\*Lcdsclerk\*O hangs when it attempts to terminate itself after a period of
non-activity. The two threads issuing the blocking calls do not honor the
cancellation and the \*Lcdsclerk\*O is unable to terminate. However, other
threads in the clerk have already terminated, resulting in an  unusable
\*Lcdsclerk\*O that will not die.
.LI
The file \*Lserver_globals.c\*O defines several \*Ldthread\*O attribute
structures for the different server threads. In an effort to save memory,
specific stack sizes are associated with several of these attribute structures.
In some cases, the specified stack size is as low as 5500 bytes.
.P
The minimum allowed stack size in the current OSF Pthreads implementation is
2 pages, which was 8K for the target platform of this port. Any stack sizes
specified less than 8K were automatically set to 8K. However, sometimes 8K
was not enough due to runtime conventions and the requirement to allocate
stack frames in muliples of 64 bytes. For example, with the
\*Lbackground_activator(\|)\*O thread, the stack was being overrun, causing
a Bus Error.
.P
To resolve the issue, increase the stack size on the server threads in order
to avoid the possibility of running out of stack space. For example, a minimum
stack size of 32000 can be chosen. Change any stack size specified in a \*Ldthread\*O
attribute structure greater than 0 but less than 32000 to 32000. Change all specified
stack sizes that are greater than 32000 to 0. Setting the stack size to 0 in a
\*Ldthread\*O attribute causes the routine  \*Lth_birth(\|)\*O in \*Lthreads_lib.c\*O
to use \*Lpthread_attr_default\*O when calling \*Lpthread_create(\|)\*O. This causes a
default stack size to be used. This default stack size could be used for all server
threads, but the default size is very large and you may decide to avoid using a great
deal of virtual memory for threads with very small stack sizes.
.P
Although this issue may not apply to many platforms, if you are porting to a
kernel-based Pthreads platform and you start having problems with the CDS server,
you should look into it.
.LE
...\" 
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 2 "Building and Linking"
...\" ----------------------------------------------------------------------
...\" 
.iX "building component code" "CDS"
.iX "CDS" "building component code"
...\" 
.P
The
.DS
    \*Vdce-root-dir\*L/dce/src/cds\*O
.DE
.P
directory contains the source code for building CDS.
.P
The
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds/cds.mk\*O
.DE
.P
file contains the compiler flags for building CDS.
Machine-specific compiler flags that affect the compilation of the
whole component or flags for individual subdirectories should be set
in this file.
Also, any machine libraries that need to be used to link binaries
should be set in this file.
.P
The flags for the CDS testcases in the
.DS
    \*Vdce-root-dir\*L/dce/src/test/directory/cds\*O
.DE
.P
directory are set in:
.DS
    \*Vdce-root-subdir\*L/dce/src/test/directory/cds/Makefile\*O
.DE
.P
CDS uses the \*Llibdce.a\*O global library to resolve subroutines from
other components.
.P
For a listing of directories where libraries and executables are built,
see the table in the ``CDS File Locations'' section of this chapter.
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 2 "Installing CDS"
...\" ----------------------------------------------------------------------
...\" 
.P
Before you attempt to set up a component for testing, you need to install
the component code.
The component code or component tests may look for certain files and executables
at the path \*Vdcelocal\*O on a DCE machine, where \*Vdcelocal\*O usually stands
for
.DS
    \*L/opt/dcelocal\*O
.DE
.P
as set up by default by \*Ldce_config\*O during cell configuration. You will
not be able to start up a component for testing until the \*Vdcelocal\*O tree
is populated with certain files that the component uses.
.P
For more information about the \*Vdcelocal\*O tree and its contents, see the
``Location of Installed DCE Files'' chapter of the \*VOSF DCE Administration
Guide\(emIntroduction\*O. For information on how to populate the \*Vdcelocal\*O
tree using \*Ldce_config\*O, see the ``Overview of the DCE Configuration Script''
chapter of the \*VOSF DCE Administration Guide\(emIntroduction\*O.
...\" 
...\" 
...\" 
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 2 "Setup, Testing, and Verification"
...\" ----------------------------------------------------------------------
...\" 
.P
Eight types of CDS tests are shipped with DCE. Two ways to test CDS are provided:
\*Lcdstest\*O and the CDS test scripts. These tests are described in more detail
in the following sections.
.P
The \*Lcdsd_diag\*O, \*Lcadump\*O, and \*Lcatraverse\*O programs, and the \*Ldcesx\*O
test, are also useful in debugging CDS.
.P
Before executing the test cases, you must configure CDS for testing using either
the DCE Configuration script
.DS
    \*Vdce-root-dir\*L/dce/src/config/dce_config\*O
.DE
.P
or the instructions found in the next subsection. You can run tests on the
configurations described in that section.
...\" 
...\" 
...\" ----------------------------------------------------------------------
...\" .zA "dcetest_config information added"
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 3 "Installing CDS Functional Tests with dcetest_config"
...\" ----------------------------------------------------------------------
...\" 
.P
You can install the functional tests described in the following sections
by running the menu-driven \*Ldcetest_config\*O script described in Chapter
13 of this guide. \*Ldcetest_config\*O will install the tests you select at
the path you specify, and will create a softlink (called \*L/dcetest/dcelocal\*O)
to that location. The functional tests for a given component will thus be
installed under a:
.DS
    \*L/dcetest/dcelocal/test/\*Vcomponent_name\*L/\*O
.DE
...\" 
.P
directory, where the \*Ltest/\*Vcomponent_name\*O elements of this path are
equivalent to the \*Ltest/\*Vcomponent_name\*O elements in the pathnames given
in the ``CDS Test Scripts'' and following sections below, which refer to the
tests' source or build locations.
.P
Note that \*Ldcetest_config\*O will prompt you for the location \*Vfrom which\*O
the tests should be installed (in other words, the final location of the built
test tree). For the CDS functional tests, this path should be the location, on
your machine, of:
.DS
    \*Vdce-root-dir\*L/dce/install\*O
.DE
...\" 
...\" 
.P
\(emwhich is the DCE \*Linstall\*O tree (for more information on the structure
of the DCE tree, see Chapter 12 of this guide).
.P
Thus, \*Ldcetest_config\*O will install the CDS functional tests at:
.DS
    \*L/dcetest/dcelocal/test/directory/cds/\*O
.DE
...\" 
.P
where \*L/dcetest/dcelocal\*O is the link to whatever path you supplied as
the install destination. 
.P
The advantage in using \*Ldcetest_config\*O to install the functional tests
is that it will install \*Vall\*O that is needed and \*Vonly\*O what is needed
out of the DCE build, thus avoiding the mistakes that can occur with manual
installation.
.P
Note that you can only \*Vinstall\*O (if you choose) functional tests with
\*Ldcetest_config\*O; for test configuration and execution you must follow
the instructions in the sections below.
.P
Refer to Chapter 13 of this guide for further information on using
\*Ldcetest_config\*O.
...\" 
...\" 
...\" .zZ "dcetest_config information added"
...\" 
...\" ----------------------------------------------------------------------
...\" 
...\" ----------------------------------------------------------------------
.H 3 "CDS Setup"
...\" ----------------------------------------------------------------------
...\" 
.iX "setup for testing" "of CDS"
.iX "CDS" "setup for testing"
...\" 
.P
You can set up CDS for testing purposes in two ways: with or without the CDS
advertiser, \*Lcdsadv\*O. The \*Lcdsadv\*O program automatically starts up a
clerk-only system; you must start the clerk manually when running CDS without
\*Lcdsadv\*O for testing. You can specify the \*L-a\*O switch with \*Lcdsd\*O
to create a namespace, a clearinghouse, and the root directory. This process
is called auto-initialization.
...\" 
.P
To debug the CDS commands \*Lcdscp\*O, \*Lcdsd\*O, \*Lcdsclerk\*O, \*Lcdsadv\*O,
\*Lcdsd_diag\*O, or \*Lcdsbrowser\*O, you need to have built the code with the
\*LDEBUG\*O macro defined. The debug output will go to a log file in:
.DS
    \*Vdcelocal\*L/var/adm/directory/cds/cdsd\*O
.DE
...\" 
.P
(for server daemons) and:
.DS
    \*Vdcelocal\*L/var/adm/directory/cds/cdsclerk\*O
.DE
...\" 
.P
(for clerk daemons) directories, if there exists a file with the command name
and a file extension \*L.events\*O (with an asterisk as the only character
in the file) in the respective directory. This file is checked only at
startup.
...\" 
...\" .zA "def,4404,R1.0.2,cdsclerk.events limit"
...\" 
.nS "Note"
The CDS clerk will stop working if the contents of its events file:
.DS
    \*Vdcelocal\*L/var/adm/directory/cds/cdsclerk/cdsclerk.events\*O
.DE
.P
exceeds 100 entries.
.nE
...\" 
...\" .zZ "def,4404,R1.0.2,cdsclerk.events limit"
...\" 
...\" 
...\" 
.P
Both \*Lcdsd\*O and \*Lcdsadv\*O take \*L-d\*O and \*L-e\*O switches.
The \*L-d\*O switch specifies debugging mode (that is, it does not
fork) and if specified with the \*L-e\*O switch, routes event output
to the standard output. The \*L-e\e*\*O switch requests debug event
logging for all events to go to standard output. (The backslash is a
shell escape character so that the asterisk is passed through the shell.
The asterisk indicates that all events should be reported.)
...\" 
...\" 
...\" 
...\" 
...\" 
.P
See the section ``Setting Up CDS Communications'' in Chapter 3 of this guide
for information about setting up CDS on a network where RPC broadcast messages
(on which the CDS advertiser mechanism normally relies) are unavailable.
.P
See the ``CDS Questions and Answers'' at the end of this chapter for some
general information on the CDS advertiser mechanism.
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 4 "CDS Setup without cdsadv"
...\" ----------------------------------------------------------------------
...\" 
.P
To configure CDS for testing without \*Lcdsadv\*O, you need to be
logged in as root and do the following:
...\" 
.AL
.LI
Change directory to \*Vdcelocal\*L/bin\*O.
.LI
The \*Ldced\*O (DCE host daemon) process must be running before you start
any CDS processes. See the \*Ldced(8dce)\*O reference page for information
on starting \*Ldced\*O.
...\" 
...\" The \*Lrpcd\*O process must be running before you start any CDS processes.
...\" Enter:
...\" .iS
...\"     \&./rpcd
...\" .iE
...\" 
...\" .P
...\" to start \*Lrpcd\*O.
...\" You can use the \*L-d\*O flag to print out debugging information for
...\" \*Lrpcd\*O.
...\" 
.LI
To start the \*Lcdsd\*O daemon, enter:
.iS
    \&./cdsd -a
.iE
...\" 
.P
where \*L-a\*O specifies auto-initialization. The auto-initialization
information is stored in the
.DS
    \*Vdcelocal\*L/etc/cds_config\*O
.DE
.P
file, which is created by \*Lcdsd\*O, and which can be used to configure
clerks and servers manually.
.PP
You may also use the following optional switches:
...\" 
.VL 1.4i
.LI "\*L-d\*O"
Debug mode, events to \*Lstdout\*O, does not fork, turns on tracing to
your terminal.
.LI "\*L-e\*O"
Prints error messages.  Use the \*L\\\*O character to escape the 
shell.  Use the \*L*\*O character to indicate full error messages (-e\\*) 
or use a fully qualified filename.
.LI "\*L-v\*O"
Prints initialization progress messages; these verify that initialization 
sucessfully completed.
.LE
...\" 
...\" 
...\" 
...\" 
...\" .P
...\" You can stop the server by entering:
...\" .iS
...\"     kill \*Vcdsd_pid\*O
...\" .iE
...\" where \*Vcdsd_pid\*O is the process ID of \*Lcdsd\*O.
.LI
On the server machine (the machine on which you started the server),
enter:
.iS
    \&./cdsclerk -d -F
.iE
...\" 
.P
to start the \*Lcdsclerk\*O process, since this configuration does not
use \*Lcdsadv\*O to start \*Lcdsclerk\*O.
The \*L-d\*O flag prohibits forking, and the \*L-F\*O flag deletes the
old socket on startup.
.P
You may also use the following optional switches with \*Lcdsclerk\*O:
...\" 
.VL 1.5i
.LI "\*L-e\*O"
Prints error messages.  Use the \*L\\\*O character to escape the 
shell.  Use the \*L*\*O character to indicate full error messages (-e\\*) 
or use a fully qualified filename.
.LI "\*L-m\ \*Vnumber\*O"
Uses shared memory ID \*Vnumber\*O.  The shared memory ID can 
be found in:
.DS
    \*Vdcelocal\*L/etc/cdscache.shmid\*O
.DE
.LE
...\" 
...\" 
...\" 
...\" 
.LI
If the machine on which you want to run the client is not the server machine,
you need to run \*Lcdsclerk\*O. Copy the
.DS
    \*Vdcelocal\*L/etc/cds_config\*O
.DE
...\" 
.P
from the server machine to the client machine. Enter:
.iS
    \&./cdsclerk -d -F
.iE
...\" 
.P
to start the \*Lcdsclerk\*O process on the client machine, since this
configuration does not use \*Lcdsadv\*O to start \*Lcdsclerk\*O.
The \*L-d\*O flag prohibits forking, and the \*L-F\*O flag deletes the
old socket on startup.
.LE
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 4 "CDS Setup with cdsadv"
...\" ----------------------------------------------------------------------
...\" 
.P
To configure CDS for testing with \*Lcdsadv\*O, you must be logged in as root
and do the following:
...\" 
.AL
...\" 
...\" 
.LI
The \*Ldced\*O (DCE host daemon) process must be running before you start
any CDS processes. See the \*Ldced(8dce)\*O reference page for information
on starting \*Ldced\*O.
...\" 
...\" 
...\" The \*Lrpcd\*O process must be running before you start any CDS processes.
...\" Enter:
...\" .iS
...\"     \&./rpcd
...\" .iE
...\" 
...\" .P
...\" to start \*Lrpcd\*O.
...\" 
...\" 
.LI
To start the CDS advertiser, enter:
.iS
    \&./cdsadv
.iE
...\" 
.P
You may also use the following optional switches:
...\" 
.VL 1i
...\" 
.LI "\*L-c\*O"
Specifies cache size in kilobytes.
...\" 
.LI "\*L-e\*O"
Prints error messages. Use the \*L\\\*O character to escape the shell. Use
the \*L*\*O character to indicate full error messages (-e\\*), or use a fully
qualified filename.
...\" 
.LI "\*L-s\*O"
Prohibits the sending or receiving of advertisements. This setting is useful
for debugging and for setting up multiple cells on one LAN.
...\" 
.LI "\*L-v\*O"
Prints initialization progress messages; these verify that initialization
completed successfully.
...\" 
.LE
...\" 
...\" 
.P
The \*Lcdsadv\*O program solicits responses from CDS Servers on the same LAN
by broadcast RPC. The first response it receives becomes the default CDS Server
used by that clerk.
...\" 
...\" 
.P
To promote some other server to default, edit
.DS
    \*Vdcelocal\*L/etc/cds_config\*O
.DE
.P
and change the desired defaults. You must then stop any clerks that are
running, and restart \*Lcdsadv\*O.
...\" 
...\" .P
...\" You can stop the advertiser by entering:
...\" .iS
...\"     kill \*Vcdsadv_pid
...\" .iE
...\" 
...\" .P
...\" where \*Vcdsadv_pid\*O is the process ID of \*Lcdsadv\*O.
...\" 
...\" .nS "note"
...\" If the process does not terminate, enter:
...\" .iS
...\"     kill -9 \*Vcdsadv_pid
...\" .iE
...\" 
...\" .P
...\" and remove the shared memory segments manually.
...\" See the next subsection for more information.
...\" .nE
...\" 
.LI
In the same directory, start the \*Lcdsd\*O daemon by entering:
.iS
    \&./cdsd -a
.iE
...\" 
.P
where the \*L-a\*O flag specifies auto-initialization.
The auto-initialization information is stored in the
.DS
    \*Vdcelocal\*L/etc/cds_config\*O
.DE
...\" 
.P
file, which can be used to configure clerks and servers manually.
You can also use the optional switches described for \*Lcdsd\*O in
the section on ``CDS Setup Without cdsadv'' in this chapter.
...\" 
...\" .P
...\" You can stop the server by entering:
...\" .iS
...\"     kill \*Vcdsd_pid
...\" .iE
...\" 
...\" .P
...\" where \*Vcdsd_pid\*O is the process ID of \*Lcdsd\*O.
...\" .LI
...\" Enter:
...\" .iS
...\"     ps
...\" .iE
...\" 
...\" .P
...\" to make sure that the \*Lcdsadv\*O, \*Lcdsd\*O, and \*Lcdsclerk\*O
...\" processes are running.
...\" Since \*Lcdsadv\*O starts \*Lcdsclerk\*O automatically, you
...\" do not need to start the \*Lcdsclerk\*O process for this
...\" configuration.
...\" 
.LE
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 4 "Using gdad"
...\" ----------------------------------------------------------------------
...\" 
.P
The \*Lgdad\*O command starts the GDA daemon. The Global Directory Agent (GDA)
enables intercell communication, serving as a connection to other cells through
the global naming environment.
.P
You may use the following optional switches:
...\" 
.VL 1i
.LI "\*L-d\*O"
For debugging use only. Ranges from d0 through d12, with d0 being the simplest level
and d12 the most complex. The most useful level of debug output is d7 for diagnosing
operational problems. Higher levels are useful when debugging coding errors.
.LI "\*L-f\*O"
Does not fork the child process.
.LI "\*L-F\*O"
Deletes old socket on startup.
.LI "\*L-r\*O"
Alternate pathname of \*L/etc/resolv.conf\*O.
.LI "\*L-s\*O"
Alternate pathname of \*Lnamed.ca\*O file.
.LI "\*L-u\*O"
Does not update GDA information in CDS server.
.LI "\*L-v\*O"
Prints initialization progress messages; these verify that
initialization completed successfully.
.LE
...\" 
...\" 
...\" .cS
...\" ----------------------------------------------------------------------
...\" .H 4 "Starting a CDS Server"
...\" ----------------------------------------------------------------------
...\" To start a CDS server, first make sure the following directory exists:
...\" .in +0.5i
...\" \*L/usr/var/dss/dns\*O
...\" .in -0.5i
...\" Then use the following command:
...\" .in +0.5i
...\" \*Lcdsd\*O
...\" .in -0.5i
...\" .P
...\" If the server fails to start, remove the following files and attempt
...\" the command again:
...\" .in +0.5i
...\" \*L/usr/var/dss/dns/*
...\" .br
...\" /usr/tmp/DNS*\*O
...\" .in -0.5i
...\" .P
...\" Then, you must start the CDS clerk on the server machine (see
...\" instructions below).
...\" When the clerk daemon is started on the server, it creates
...\" \*L/usr/var/dss/dns/dce_config\*O.
...\" This file is required by the other clerks that uses this server.
...\" ----------------------------------------------------------------------
...\" .H 4 "Starting a CDS Clerk"
...\" ----------------------------------------------------------------------
...\" Before a CDS clerk can be started, there must be a CDS server running.
...\" Copy \*L/usr/var/dss/dns/dce_config\*O from the server machine into
...\" the same directory on the clerk.
...\" .P
...\" Then use the following command to start the CDS clerk daemon:
...\" .in +0.5i
...\" \*Lcdsclerk -d\*O
...\" .in -0.5i
...\" .P
...\" If the clerk fails to start, remove the following file and reissue the
...\" command:
...\" .in +0.5i
...\" \*L/tmp/dce_clerk\*O
...\" .in -0.5i
...\" .cE
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 4 "Resetting the CDS Environment"
...\" ----------------------------------------------------------------------
...\" 
.P
If it is necessary to reset the CDS environment to a ``clean'' state, there are
several files that need to be removed and shared memory segments and semaphores
to be deleted.
...\" 
...\" .zA "def,5310,R1.0.2,Fixed shmem removal instructions"
...\" 
.P
The shared memory segment(s) can be removed by performing the following steps:
...\" 
.AL
.LI
Get the SHMID (shared memory ID) from the first line of the file:
.DS
    \*Vdcelocal\*L/etc/cdscache.shmid\*O
.DE
...\" 
...\" 
.LI
Use \*Lipcs\*O to find the \*Lshm_key\*O for the SHMID. The semaphore used
by CDS uses the same key as the shared memory:
.DS
    \*Lipcs | awk '/\*VSHMID_from_step_1\*L/ {print $3}'
.DE
...\" 
...\" 
.LI
Remove the semaphore:
.DS
    \*Lipcrm -S \*Vshm_key_from_step_2\*O
.DE
...\" 
...\" 
.LI
Remove the shared memory:
.DS
    \*Lipcrm -m \*VSHMID_from_step_1\*O
.DE
...\" 
...\" 
.LE
...\" 
...\" .zZ "def,5310,R1.0.2,Fixed shmem removal instructions"
...\" 
...\" 
...\" 
.P
The CDS files can be removed with the following script:
...\" 
...\" 
.iS
    rm -rf \*Vdcelocal\*L/var/adm/directory/cds/*

    rm -rf \*Vdcelocal\*L/var/directory/cds*

    rm -rf \*Vdcelocal\*L/var/directory/cds/adm/cdsd/*

    rm -rf \*Vdcelocal\*L/var/directory/cds/adm/gdad/*

    rm -rf \*Vdcelocal\*L/etc/cds_config

    rm -rf \*Vdcelocal\*L/etc/cds_defaults

    rm -rf \*Vdcelocal\*L/etc/gda_id

    rm -rf \*Vdcelocal\*L/etc/cdsadv.pid

    rm -rf \*Vdcelocal\*L/etc/cdscache.shmid

    rm -rf \*Vdcelocal\*L/etc/cdsd.pid\*O
.iE
...\" 
.P
See also the \*Ldce.rm\*O script.
...\" 
...\" .zA "Moved from Chapter 10"
...\" 
...\" Following section MOVED FROM libdce CHAPTER...
...\" ----------------------------------------------------------------------
...\" .H 3 "Removing the CDS On-Disk Cache"
...\" ----------------------------------------------------------------------
...\" 
.P
It is sometimes useful to purge the CDS cache between runs. To remove the CDS
on-disk cache (e.g., before starting up a new CDS server), execute the following
commands:
...\" 
...\" 
.iS
    kill -9 \*Vcdsclerk PID\*L
    /etc/dce.clean
    cd /opt/dcelocal/var/adm/directory/cds
    mv cds_cache.\*Vnumber\*L cds_cache.\*Vnumber\*L.BAD
    /etc/rc.dce
.iE

.P
If the CDS server and client cannot broadcast, you must also do the following:
...\" 
.iS
    cdscp define cached server \*VCDS_Server_Hostname\*L tower \\
        ncadg_ip_udp:\*VCDS_Server_IP_Address\*O
.iE
...\" 
.P
For example:
...\" 
.iS
    cdscp define cached server west tower ncadg_ip_udp:130.105.201.10
.iE
...\" 
...\" 
...\" .iS
...\"     rm \*Vdcelocal\*L/etc/cdscache.shmid
...\"     rm \*Vdcelocal\*L/var/adm/directory/cds/cds_cache.*
...\" .iE
...\" 
...\" 
...\" 
...\" .zZ "Moved from Chapter 10"
...\" 
...\" ----------------------------------------------------------------------
...\"	.H 3 "CDS Test Scripts"
...\" ----------------------------------------------------------------------
...\" 
.iX "testing" "CDS"
.iX "CDS" "testing"
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 4 "CDS Configuration Files"
...\" ----------------------------------------------------------------------
...\" 
...\" .zA "Added config file info"
.P
The following files are used in CDS configuration:
...\" 
...\" 
.VL 2.25i
...\" 
.LI "\*Vdcelocal\*L/etc/cds.conf\*O"
This file contains security information for CDS, such as the principal names
of the \*Lcdsd\*O and \*Lgdad\*O, as well as the names of the \*Lcds-server\*O
and \*Lcds-admin\*O groups.
...\" 
.LI "\*Vdcelocal\*L/etc/cds_config\*O"
This file contains configuration information about namespaces and clearinghouses,
including the name and UUID of each. In each case it also contains the internet
address of the server that supports the clearinghouse.
...\" 
...\" .LI "\*L/opt/dcelocal/etc/cds_defaults\*O"
...\" Not sure.  I believe it is created when a cdsd is initialized.
...\" 
...\" 
.LI "\*Vdcelocal\*L/etc/cds_attributes\*O"
This text file contains a list of the DCE attributes and their OIDs. It maps OID,
SYNTAX, and the label used by CDS to identify the displayed attribute. For
example:
...\" 
.oS
  OID             LABEL            SYNTAX
  1.3.22.1.3.42   CDS_LastSkulk    Timestamp
.oE
...\" 
...\" 
.LI "\*Vdcelocal\*L/etc/cds_globalnames\*O"
This file is a database of DCE-supported X.500 attribute types. Some of these
are ``naming attributes'' (meaning that they occur in the names of objects, as
specified by the schema), but most are not. The file maps the following for each
Attribute Type:
...\" 
.BL
.LI
OID
.LI
LABEL
.LI
ASN.1-IDENTIFIER
.LI
SYNTAX
.LI
MATCHING RULE
.LE
...\" 
...\" full pathname?????
.LI "\*Lcdscp.bpt\*O"
Used by the \*Lcdscp\*O parser.
...\" 
...\" full pathname?????
.LI "\*Lcdscp.mbf\*O"
Used by the \*Lcdscp\*O parser.
...\" 
.LE
...\" 
...\" 
...\" .zZ "Added config file info"
...\" 
...\" ----------------------------------------------------------------------
.H 3 "CDS Test Scripts"
...\" ----------------------------------------------------------------------
...\" 
.iX "testing" "CDS"
.iX "CDS" "testing"
...\" 
.P
The test scripts for CDS are in the
.DS
    \*Vdce-root-dir\*L/dce/src/test/directory/cds\*O
.DE
.P
directory. To run a test, enter:
.iS
    cp_test.sh\*O [\*V-switch ...\*O] \*Vtestname
.iE
...\" 
.P
where
...\" 
...\" 
...\" 
.zA "def,10739,1.1beta,new info"
...\" 
...\" 
.VL 1.4i
.LI "\*V-switch\*O"
This optional parameter specifies a certain testing option.
The following values are valid for \*Vswitch\*O:
...\" 
...\" .zA "Added four parms at end"
...\" 
.VL 1.4i
...\" 
...\" 
.LI "\*L-cdscpdir\ \*Vpathname\*O"
Specifies an alternative pathname for \*Lcdscp\*O.
...\" 
...\" 
.LI "\*L-cell\ \*Vname1\*O"
Specifies \*Vname1\*O as the cell name to perform local tests on.
...\" 
...\" 
.LI "\*L-ch1\ \*Vname2\*O"
Specifies \*Vname2\*O as the primary clearinghouse (Clearinghouse 1).
...\" 
...\" 
.LI "\*L-ch2\ \*Vname3\*O"
Specifies \*Vname3\*O as the secondary clearinghouse (Clearinghouse 2 - an
existing clearinghouse).
...\" 
...\" 
.LI "\*L-ch3\ \*Vname4\*O"
Specifies \*Vnam4\*O as Clearinghouse 3 - a clearinghouse to create.
...\" 
...\" 
.LI "\*L-dir\ \*Vdirname\*O"
Specifies \*Vdirname\*O as the top level test directory.
...\" 
...\" 
.LI "\*L-disable\*O"
Do not strip \*Ldisable\*O commands from scripts.
...\" 
...\" 
.LI "\*L-inet\ \*Vaddress\*O"
Specifies Internet address.
...\" 
...\" 
.LI "\*L-keeplines\*O"
Do not delete the test script when done.
...\" 
...\" 
.LI "\*L-nodeldir\*O"
Strips \*Ldeldir\*O commands from scripts.
...\" 
...\" 
.LI "\*L-noch\*O"
Strips all clearinghouse information.
...\" 
...\" 
.LI "\*L-noch1\*O"
Strips primary clearinghouse (Clearinghouse 1) information.
...\" 
...\" 
.LI "\*L-noch2\*O"
Strips secondary clearinghouse (Clearinghouse 2) information.
...\" 
...\" 
.LI "\*L-noch3\*O"
Strips create clearinghouse (Clearinghouse 3) information.
...\" 
...\" 
.LI "\*L-nopipe\*O"
Specifies that commands not be piped into \*Lcdscp\*O.
...\" 
...\" 
.LI "\*L-noshow\*O"
Strips \*Lshow\*O commands from scripts.
...\" 
...\" 
.LI "\*L-noskulk\*O"
Strip \*Lskulk\*O commands from scripts.
...\" 
...\" 
.LI "\*L-pid\*O"
Uses the process ID of \*Lcp_test.sh\*O to generate unique log filenames.
You can run multiple simultaneous tests using this option.
...\" 
...\" 
.LI "\*L-remcell\ \*Vcellname\*O"
Specifies Remote cell name to reference for intercell testing.
...\" 
...\" 
.LI "\*L-restart\*O"
Specifies that the DCE servers be restarted before starting the test.
...\" 
...\" 
.LI "\*L-use_alias\*O"
Use \*L/.:\*O in tests to refer to the cellname.
...\" 
...\" 
.LI "\*L-v\*O"
Specifies verbose mode.
...\" 
...\" 
...\" 
...\" 
...\" 
...\" 
.LE
...\" 
...\" .zZ "Added four parms at end"
...\" 
...\" 
...\" 
.LI "\*Vtestname\*O"
Specifies the CDS test to run. The following tests are provided:
...\" 
.VL 1.5i
...\" 
.LI "\*Lcp_abuse.tests\*O"
Stress tests.
...\"   abuse *+	Stress tests
...\" 
.LI "\*Lcp_childpointer.tests\*O"
Tests childpointer operations.
...\" 	childpointer	Childpointer operations
...\" 
.LI "\*Lcp_clearinghouse.tests\*O"
Tests clearinghouse operations.
...\" 	clearinghouse	Clearinghouse operations
...\" 
.LI "\*Lcp_clerk.tests\*O"
Tests clerks.
...\" 	clerk		Clerks
...\" 
.LI "\*Lcp_credir.tests\*O"
Tests directory operations and is a subset of \*Lcp_directory.tests\*O.
...\" 	credir*		Directory creation (subset of directory)
...\" 
.LI "\*Lcp_directory.tests\*O"
Tests directory operations.
...\" 	directory	Directory operations
...\" 
.LI "\*Lcp_foreign.tests\*O"
Tests merges of foreign cell subtree dump files.
...\" 
...\" 
.LI "\*Lcp_intercell.tests\*O"
Tests references to foreign cell data (requires \*L-remcell\*O to be
specified).
...\" 
...\" 
...\" 
.LI "\*Lcp_misc.tests\*O"
Tests confidence, preferred clearinghouse.
...\" 	misc*		Confidence, preferred clearinghouse
...\" 
...\" 
.LI "\*Lcp_negative.tests\*O"
Tests multiple creates/deletes, and non-extant references.
...\" 
...\" 
.LI "\*Lcp_object.tests\*O"
Tests object operations.
...\" 	object		Object operations
...\" 
.LI "\*Lcp_replica.tests\*O"
Tests replica operations.
...\" 	replica		Replica operations
...\" 
.LI "\*Lcp_server.tests\*O"
Tests servers.
...\" 	server		Servers
...\" 
.LI "\*Lcp_softlink.tests\*O"
Tests softlink operations.
...\" 	softlink	Softlink operations
...\" 
.LI "\*Lcp_subtree.tests\*O"
Tests subtree operations.
...\" 
...\" 
.LE
...\" 
.LE
...\" 
...\" 
.P
The
...\" 
.DS
    \*Vdce-root-dir\*L/dce/src/test/directory/cds/cp_killer.sh\*O
.DE
...\" 
.P
script runs all the tests listed above except:
...\" 
.BL
.LI
\*Lcp_misc.tests\*O
...\" 
.LI
\*Lcp_abuse.tests\*O
...\" 
.LI
\*Lcp_intercell.tests\*O
...\" 
.LI
\*Lcp_credir.tests\*O
...\" 
.LE
...\" 
...\" 
.P
To run \*Lcp_killer.sh\*O, enter:
...\" 
.iS
    cp_killer.sh
.iE
...\" 
.P
Any of the \*Lcp_test.sh\*O switches may be used when running \*Lcp_killer.sh\*O.
The \*Lcp_killer.sh\*O script uses \*Lcp_test.sh\*O.
...\" 
...\" 
...\" To run \*Lcp_killer.sh\*O and observe the results of the script as it executes,
...\" enter:
...\" 
...\" .iS
...\"     cp_killer.sh -ns \*Vservername\*L_ns -ch1\\
...\"        clearinghousename\*L_ch -noch2&> killer.log;\\
...\"        tail -f killer.log
...\" .iE
...\" 
...\" .P
...\" where \*Vservername\*O is the name of your server machine, and \*Vclearinghousename\*O
...\" is the name of your clearinghouse.
...\" .P
...\" Save \*Lkiller.log\*O to see what a successful run looks like.
...\" 
...\" 
.zZ "def,10739,1.1beta,new info"
...\" 
...\" .zA "Added ACL test info"
...\" 
...\" ----------------------------------------------------------------------
.H 3 "Distributed ACL Tests"
...\" ----------------------------------------------------------------------
...\" 
.P
The driver script
.DS
    \*Vdce-root-dir\*L/dce/src/test/directory/cds/dacl_testing.sh\*O
.DE
...\" 
.P
runs the distributed ACL tests:
...\" 
.BL
.LI
\*Ldacl_creates.sh\*O
.LI
\*Ldacl_deletes.sh\*O
.LI
\*Ldacl_modifies.sh\*O
.LI
\*Ldacl_reads.sh\*O
.LI
\*Ldacl_replicas.sh\*O
.LE
...\" 
.P
It is invoked as follows:
.iS
    dacl_testing.sh -ch1 \*Vclearinghouse1 \*L-ch2 \*Vclearinghouse2\*O
.iE
...\" 
.P
where \*Vclearinghouse1\*O and \*Vclearinghouse2\*O are the names of two
clearinghouses, both of which must already have been created when the test
is run, and neither of which should be the cell default clearinghouse.
.P
Note that the clearinghouse arguments must \*Vnot\*O be specified with a
leading ``\*L/.:/\*O'' or ``\*L/.../\*O''.
.P
The following things must be true in order for the ACL tests to be run
successfully:
...\" 
.BL
.LI
The driver script is running as the principal \*Lnotroot\*O.
.LI
The CDS server is called
.DS
    \*V/.../hosts/\*Vhostname\*L/cds-server\*O
.DE
...\" 
.P
This is the default name as set up by \*Ldce_config\*O.
...\" 
.LI
The \*Lnotroot\*O principal has write permission for the default clearinghouse.
...\" 
.LI
The \*Lnotroot\*O principal has insert and read permission for the root
directory.
...\" 
.LE
...\" 
...\" 
.P
Because of these prerequisites for running the test, it is advisable to run
\*Ldacl_testing.sh\*O in a newly-configured DCE cell which has been specially
set up for this purpose. The \*Ldacl_setup.sh\*O script can be run to set
up such a newly-configured cell so that it meets the above requirements.
.P
\*Ldacl_setup.sh\*O, which should be run as the \*Lcell_admin\*O principal,
is invoked as follows:
...\" 
.iS
    dacl_setup.sh -ch1 \*Vclearinghouse1 \*L-ch2 \*Vclearinghouse2 \*L-ch3 \*Vdefault_clearinghouse\*O
.iE
...\" 
.P
where \*Vdefault_clearinghouse\*O is the default clearinghouse for the cell;
this usually has a name of the form \*Vhostname\*L_ch\*O, where \*Vhostname\*O
is the name of the host machine.
.P
Note that the clearinghouse arguments must \*Vnot\*O be specified with a
leading ``\*L/.:/\*O'' or ``\*L/.../\*O''.
...\" 
.P
The output of the tests is written to the following logfiles:
...\" 
.BL
.LI
\*Ldacl_creates.log\*O
.LI
\*Ldacl_deletes.log\*O
.LI
\*Ldacl_modifies.log\*O
.LI
\*Ldacl_reads.log\*O
.LI
\*Ldacl_replicas.log\*O
.LE
...\" 
...\" 
...\" 
...\" .zZ "Added ACL test info"
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 3 "NSI Test"
...\" ----------------------------------------------------------------------
...\" 
...\" .P
...\" The following commands are used in testing.
...\" 
...\" .BL
...\" .LI
...\" \*Lprs\*O
...\" .P
...\" This command is used to create the \*L.bpt\*O files used by the control
...\" programs \*Lcdscp\*O and \*Ldtscp\*O.
...\" Its source is in the directory \*Lsrc/directory/cds/control\*O.
...\" A \*L.cdt\*O file is fed as input and a \*L.bin\*O file is produced
...\" that is renamed to \*L.bpt\*O.
...\" This is used by the control program to aid in parsing commands.
...\" The use of \*Lparser_aid\*O requires the use of a \*L.bpt\*O file
...\" generated by \*Lprs\*O.
...\" .LI
...\" \*Lmsg\*O
...\" .P
...\" This command is used to create the \*L.mbf\*O files used by the
...\" control program \*Lcdscp\*O.
...\" Its source is in the directory \*Lsrc/directory/cds/control\*O.
...\" A \*L.txt\*O file is
...\" input and a \*L.bin\*O file is produced that is renamed to \*L.dat\*O.
...\" .LE
...\" 
...\" 
.P
\*Ldcesx\*O is a test of the CDS NSI (Name Service Interface). It is invoked
as follows:
...\" 
.oS
    dcesx -K -M -R -V -i 10 -m 10 -p 99 -t 30
.oE
...\" 
.P
The flags have the following meanings:
.ne 4i
...\" 
.TS H
center tab (@) box;
lB | lB
l | l.
Flag@Meaning
_
.TH
\*L-K\*O@T{
Skulk whenever the namespace is changed.
T}
\*L-M\*O@T{
Use multiple threads.
T}
\*L-R\*O@T{
Re-randomize search context
(only used if a directory search fails).
T}
\*L-V\*O@T{
Set maximum verbosity.
T}
\*L-i 10\*O@T{
Number of interfaces to enable (10 is the maximum).
T}
\*L-m 10\*O@T{
Number of call threads to configure (for RPC).
T}
\*L-p 99\*O@T{
Number of passes (\*L-p 0\*O means go forever).
T}
\*L-t 30\*O@T{
Number of seconds to delay after failure to import
an interface.
T}
.TE
...\" 
...\" .zA "def,7381,R1.0.2,dce_login necessary for dcesx"
...\" 
.P
Note that you should \*Ldce_login\*O as \*Lcell_admin\*O before running
the \*Ldcesx\*O test, so that the test will have the permissions necessary
to perform the operations it will attempt on specific directories and
objects.
...\" 
...\" .zZ "def,7381,R1.0.2,dce_login necessary for dcesx"
...\" 
...\" 
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 3 "Testing Intercell Lookup"
...\" ----------------------------------------------------------------------
...\" 
...\" .zA "Added gda_clerk info"
.P
The GDA clerk, unlike the CDS clerk which is an integral part of CDS, exists
for test purposes only. Its source is located at:
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds/gda/gda_clerk.c\*O
.DE
.P
The \*Lgda_clerk\*O test program performs the same GDA lookup that the CDS clerk
performs; by running it you can eliminate all of the logic of the CDS clerk when
testing the GDA. \*Lgda_clerk\*O uses the same interfaces and the same progress
records as the CDS clerk.
.P
Its interactive inputs are:
...\" 
.BL
.LI
A string binding to the GDA. You can get this from the output of running
the command:
.iS
    rpccp show mapping
.iE
...\" 
...\" 
.LI
A \*L/.../\*Vcellname\*O for the GDA to look up.
...\" 
.LE
.P
You should make sure that \*Lgda_clerk\*O returns good results before you try
remote cell access through CDS.
...\" 
...\" 
...\" 
...\" 
...\" 
...\" .zZ "Added gda_clerk info"
...\" 
...\" 
...\" 
...\" 
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
...\" .H 2 "Debugging Hints"
...\" ----------------------------------------------------------------------
...\" 
...\" .P
...\" This section gives miscellaneous hints for debugging CDS.
...\" 
...\" 
...\" ----------------------------------------------------------------------
...\" .H 3 "Debugging a CDS Clerk"
...\" ----------------------------------------------------------------------
...\" 
...\" .P
...\" The following technique is most useful when you want to start the CDS clerk
...\" in a debugger.
...\" .P
...\" Normally, the \*Lcdsclerk\*O daemons are forked from the advertiser and they
...\" cannot easily be debugged. Follow these steps to start them manually, which
...\" will enable you to debug them:
...\" 
...\" .AL
...\" .LI
...\" Become root.
...\" .LI
...\" Start \*Lrpcd\*O, \*Lsecd\*O, and \*Lsec_clientd\*O.
...\" .LI
...\" \*Ldce_login\*O
...\" .P
...\" (This will take a long time\*(EMfirst it has to fail to
...\" find the Security registry through the nonexistent namespace.)
...\" .LI
...\" Start up \*Lcdsadv\*O.
...\" .LI
...\" \*Lcd \*Vdcelocal\*L/var/adm/directory/cds\*O
...\" .LI
...\" Rename the socket \*LcdsLib\*O to \*LcdsLib.old\*O.
...\" .LI
...\" Look in the
...\" .DS
...\"     \*Vdcelocal\*L/etc/cdscache.shmid\*O
...\" .DE
...\" 
...\" .P
...\" file to get the UNIX IPC ID of CDS's shared memory segment. The first number
...\" in the file is the ID:
...\" 
...\" .oS
...\"     300
...\"     711294522
...\" .oE
...\" 
...\" .P
...\" Alternatively, you can see the ID by entering:
...\" 
...\" .oS
...\"     # \*Lipcs -m\*C
...\"     Shared Memory:
...\"     T    ID      KEY      MODE            OWNER    GROUP
...\"     m    300     6732     --rw-------     root     daemon
...\" .oE
...\" 
...\" .LI
...\" Start up the clerk (through the shell or a debugger):
...\" 
...\" .iS
...\"     cdsclerk -dFm \*Vshmid\*L
...\" .iE
...\" 
...\" .P
...\" The \*Vshmid\*O is the shared memory ID from the \*Lipcs\*O above. In this
...\" example, the ID is 300. There is also an option \*L-e\e*\*O which enables all
...\" debug output.
...\" .LI
...\" Wait a moment and start up \*Lcdsd\*O (also from a process that has already
...\" executed \*Ldce_login\*O).
...\" .LI
...\" Wait until the Security Service has exported itself to the namespace.
...\" .LE
...\" 
...\" .P
...\" You now have a cell running. One difference from the generic CDS model is
...\" that the \*Lcdsclerk\*O you started is the clerk for \*Vall\*O principals.
...\" The advertiser will not fork off any others.
...\" 
...\" .nP
...\" 
...\" .zA "Added CDS utilities info"
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 2 "CDS Runtime Output and Debugging Output"
...\" ----------------------------------------------------------------------
...\" 
.P
The CDS component outputs server information of all kinds via the DCE serviceability
component. The following sections describe how to control the various kinds of
information (including debugging output) available from CDS via serviceability.
...\" 
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 3 "Normal CDS Server Message Routing"
...\" ----------------------------------------------------------------------
...\" 
.P
There are basically two ways to control normal CDS server message routing:
...\" 
.BL
.LI
At startup, through the contents of a routing file (which are applied to
all components that use serviceability messaging).
.LI
Dynamically, through the \*Ldcecp log\*O object.
.LE
...\" 
...\" 
.P
The following sections describe each of these methods.
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 4 "Routing File"
...\" ----------------------------------------------------------------------
...\" 
.P
If a file called
...\" 
.DS
    \*Vdce-local-path\*L/svc/routing\*O
.DE
...\" 
.P
exists when CDS is brought up (i.e., when the CDS daemons are executed or when
the cell is started through \*Ldce_config\*O), the contents of the file (if in
the proper format) will be used as to determine the routing of CDS serviceability
messages.
.P
The value of \*Vdce-local-path\*O depends on the values of two \*Lmake\*O
variables when DCE is built:
...\" 
...\" 
...\" 
.VL 1i
.LI "\*LDCEROOT\*O"
its default value is: \*L/opt\*O
...\" 
.LI "\*LDCELOCAL\*O"
its default value is: \*L$DCEROOT/dcelocal\*O
...\" 
.LE
...\" 
.P
Thus, the default location of the serviceability routing file is normally:
...\" 
.DS
    \*L/opt/dcelocal/svc/routing\*O
.DE
...\" 
.P
However, a different location for the file can be specified by setting the
value of the environment variable \*LDCE_SVC_ROUTING_FILE\*O to the complete
desired pathname.
...\" 
.P
The contents of the routing file consist of formatted strings specifying
the routing desired for the various kinds of messages (based on message
severity). Each string consists of three fields as follows:
...\" 
.DS
    \*Vseverity\*L:\*Voutput_form\*L:\*Vdestination\*O\ [\*Voutput_form\*L:\*Vdestination\*O .\ .\ .\ ]
.DE
...\" 
.P
Where:
...\" 
.VL 1i
.LI "\*Vseverity\*O"
specifies the severity level of the message, and must be one of the following:
.BL
.LI
\*LFATAL\*O
...\" Fatal error, about to exit
.LI
\*LERROR\*O
...\" Normal exit
.LI
\*LWARNING\*O
...\" Error detected, program proceeding
.LI
\*LNOTICE\*O
...\" Informational notice
.LI
\*LNOTICE_VERBOSE\*O
...\" Verbose informational notice
.LE
...\" 
.P
(The meanings of these severity levels are explained in detail in Chapter 4 of
the \*VOSF DCE Application Development Guide \(em Core Components\*O volume,
in the section entitled ``Specifying Message Severity''.)
...\" 
...\" 
...\" 
.LI "\*Voutput_form\*O
specifies how the messages of a given severity level should be processed, and
must be one of the following:
.BL
.LI
\*LBINFILE\*O
.P
Write these messages as binary log entries
.LI
\*LTEXTFILE\*O
.P
Write these messages as human-readable text
.LI
\*LFILE\*O
.P
Equivalent to \*LTEXTFILE\*O
.LI
\*LDISCARD\*O
.P
Do not record messages of this severity level
.LI
\*LSTDOUT\*O
.P
Write these messages as human-readable text to standard output
.LI
\*LSTDERR\*O
.P
Write these messages as human-readable text to standard error
.LE
...\" 
.P
Files written as \*LBINFILE\*Os can be read and manipulated with a set of
logfile functions. See Chapter 4 of the \*VOSF DCE Application Development
Guide \(em Core Components\*O volume, mentioned above, for further information.
.P
The \*Voutput_form\*O specifier may be followed by a two-number specifier of the form:
...\" 
.DS
    \*L.\*Vgens\*L.\*Vcount\*O
.DE
...\" 
.P
Where:
...\" 
.VL .5i
.LI "\*Vgens\*O"
is an integer that specifies the number of files (i.e., generations) that
should be kept
.LI "\*Vcount\*O"
is an integer specifying how many entries (i.e., messages) should be
written to each file
.LE
...\" 
.P
The multiple files are named by appending a dot to the simple specified
name, followed by the current generation number. When the number of entries
in a file reaches the maximum specified by \*Vcount\*O, the file is closed,
the generation number is incremented, and the next file is opened. When the
maximum generation number files have been created and filled, the generation
number is reset to 1, and a new file with that number is created and written
to (thus overwriting the already-existing file with the same name), and so
on, as long as messages are being written. Thus the files wrap around to their
beginning, and the total number of log files never exceeds \*Vgens\*O, although
messages continue to be written as long as the program continues writing them.
...\" 
...\" 
...\" 
...\" 
.LI "\*Vdestination\*O
specifies where the message should be sent, and is a pathname. The field
can be left blank if the \*Voutput_form\*O specified is \*LDISCARD\*O,
\*LSTDOUT\*O, or \*LSTDERR\*O. The field can also contain a \*L%ld\*O
string in the filename which, when the file is written, will be replaced
by the process ID of the program that wrote the message(s). Filenames may
\*Vnot\*O contain colons or periods.
...\" 
...\" 
.LE
...\" 
...\" 
.P
Multiple routings for the same severity level can be specified by simply
adding the additional desired routings as space-separated
...\" 
.DS
    \*Voutput_form\*L:\*Vdestination\*O
.DE
...\" 
.P
strings.
...\" 
.P
For example, 
...\" 
.oS
    FATAL:TEXTFILE:/dev/console
    WARNING:DISCARD:--
    NOTICE:BINFILE.50.100:/tmp/log%ld STDERR:-
.oE
...\" 
.P
Specifies that:
...\" 
.BL
.LI
Fatal error messages should be sent to the console.
.LI
Warnings should be discarded.
.LI
Notices should be written both to standard error and as binary entries in files
located in the \*L/tmp\*O directory. No more than 50 files should be written, and
there should be no more than 100 messages written to each file. The files will have
names of the form:
...\" 
.DS
    \*L/tmp/log\*Vprocess_id\*L.\*Vnn\*O
.DE
...\" 
.P
where \*Vprocess_id\*O is the process ID of the program originating the messages,
and \*Vnn\*O is the generation number of the file.
...\" 
...\" 
.LE
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 4 "Routing by the dcecp log Object"
...\" ----------------------------------------------------------------------
...\" 
.P
Routing of CDS server messages can be controlled in an already-started cell
through the \*Ldcecp log\*O object. See the \*Llog.8dce\*O reference page
in the \*VOSF DCE Command Reference\*O for further information.
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 3 "Debugging Output"
...\" ----------------------------------------------------------------------
...\" 
.P
Debugging output from CDS can be enabled (provided that CDS has been built with
\*LDCE_DEBUG\*O defined) by specifying the desired debug messaging level and route(s)
in the
...\" 
.DS
    \*Vdce-local-path\*L/svc/routing\*O
.DE
...\" 
.P
routing file (described above), or by specifying the same information in the
\*LSVC_CDS_DBG\*O environment variable, before bringing up CDS (i.e., prior to
starting the cell). Debugging output can also be enabled and controlled through
the \*Ldcecp log\*O object.
.P
Note that, unlike normal message routing, debugging output is always specified
on the basis of DCE component/sub-component (the meaning of ``sub-component''
will be explained below) and desired level.
.P
The debug routing and level instructions for a component are specified by the
contents of a specially-formatted string that is either included in the value
of the environment variable or is part of the contents of the routing file.
.P
The general format for the debug routing specifier string is:
...\" 
.DS
\s-1
    "\*Vcomponent\*L:\*Vsub_comp\*L.\*Vlevel\*L,\*V.\ .\ .\*L:\*Voutput_form\*L:\*Vdestination\*O \\
    [\*Voutput_form\*L:\*Vdestination\*O .\ .\ .\ ] "
\s+1
.DE
...\" 
.P
where the fields have the same meanings as in the normal routing specifiers
described above, with the addition of the following:
...\" 
...\" 
...\" 
.VL 1i
.LI "\*Vcomponent\*O"
specifies the component name
...\" 
.LI "\*Vsub_comp\*L.\*Vlevel\*O"
specifies a subcomponent name, followed (after a dot) by a debug level
(expressed as a single digit from 1 to 9). Note that multiple
subcomponent/level pairs can be specified in the string.
.P
A star (``\*L*\*O'') can be used to specify all sub-components. The sub-component
list is parsed in order, with later entries supplementing earlier ones; so the
global specifier can be used to set the basic level for all sub-components, and
specific sub-component exceptions with different levels can follow (see the example
below).
...\" 
.LE
...\" 
...\" 
.P
``Sub-components'' denote the various functional modules into which a component has
been divided for serviceability messaging purposes. For CDS, the sub-components are
as follows:
...\" 
...\" 
.VL 2.5i
.LI "\*Ladver\*O"
CDS Advertiser sub-component
...\" 
.LI "\*Lchild\*O"
CDS Clerk/Child/Client sub-component
...\" 
.LI "\*Lgda\*O"
CDS GDA sub-component
...\" 
.LI "\*Lserver\*O"
CDS Server sub-component
...\" 
.LI "\*Lcache\*O"
CDS Cache sub-component
...\" 
.LI "\*Llibrary\*O"
CDS Library sub-component
...\" 
.LI "\*Lgeneral\*O"
CDS General sub-component
...\" 
.LI "\*Ldthread\*O"
CDS dthreads sub-component
...\" 
.LI "\*Lcdscp\*O"
CDS Control Program sub-component
...\" 
.LE
...\" 
...\" 
.P
For example, the string
...\" 
.DS
    "cds:*.1,server.3:TEXTFILE.50.200:/tmp/CDS_LOG
.DE
...\" 
.P
sets the debugging level for all CDS sub-components (\*Vexcept\*O
\*Lserver\*O) at 1; \*Lserver\*O's level is set
at 3. All messages are routed to \*L/tmp/CDS_LOG\*O. No more than
50 log files are to be written, and no more than 200 messages are
to be written to each file.
.P
The texts of all the CDS serviceability messages, and the sub-component list,
can be found in the CDS sams file, at:
...\" 
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds/includes/cds.sams\*O
.DE
...\" 
.P
For further information about the serviceability mechanism and API, see Chapter 4
of the \*VOSF DCE Application Development Guide \(em Core Components\*O volume,
``Using the DCE Serviceability Application Interface''.
...\" 
...\" 
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 2 "CDS Utilities"
...\" ----------------------------------------------------------------------
...\" 
.P
The following sections contain information about various CDS debugging and
diagnostic utilities.
...\" 
...\"
...\"
...\" ----------------------------------------------------------------------
.H 3 "cadump"
...\" ----------------------------------------------------------------------
...\" 
.P
The \*Lcadump\*O command dumps the clerk cache data. It is useful for
debugging and for clerk cache sanity checking.
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.sp 2
.in -0.25i
\s+1\*L
Synopsis
\*O\s-1
.in +0.25i
.sp 1
...\" ----------------------------------------------------------------------
...\" 
.P
\*Lcadump\*O is invoked as follows:
...\" 
.iS
    cadump \*V[\*L -m \*Vcacheid ] | [ \*L-n \*Vfilename ]\*O
.iE
...\" 
.P
or:
.iS
    cadump -m \*Vcacheid\*O
.iE
...\" 
.P
or:
.iS
    cadump -n \*Vfilename\*O
.iE
...\" 
.P
Where:
...\" 
...\" 
.VL 1i
.LI "\*Vcacheid\*O"
specifies the shared memory id (obtain with \*Lipcs\*O)
.LI "\*Vfilename\*O"
specifies the clerk cache filename
.LE
...\"
...\"
...\"
...\"
...\"
...\"
...\" ----------------------------------------------------------------------
.H 3 "catraverse"
...\" ----------------------------------------------------------------------
...\" 
.P
The \*Lcatraverse\*O command traverses the clerk cache data. It is useful for
debugging and for clerk cache sanity checking.
...\" 
...\" 
...\" 
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.sp 2
.in -0.25i
\s+1\*L
Synopsis
\*O\s-1
.in +0.25i
.sp 1
...\" ----------------------------------------------------------------------
...\" 
...\" 
.P
\*Lcatraverse\*O is invoked as follows:
...\" 
...\" 
.iS
    catraverse\*O \*V[\*L -m \*Vcacheid ] | [\*L -n \*Vfilename ]\*O
.iE
...\" 
.P
or:
.iS
    catraverse -m \*Vcacheid\*O
.iE
...\" 
.P
or:
.iS
    catraverse -n \*Vfilename\*O
.iE
...\" 
.P
Where:
...\" 
...\" 
.VL 1i
.LI "\*Vcacheid\*O"
specifies the shared memory id (obtain with ipcs)
.LI "\*Vfilename\*O"
specifies the clerk cache filename
.LE
...\"
...\"
...\"
...\"
...\"
...\" ----------------------------------------------------------------------
.H 3 "cds_dbdump"
...\" ----------------------------------------------------------------------
...\" 
.P
The \*Lcds_dbdump\*O utility is used to dump the server checkpoint,
transaction log, and name server message log files.
...\" 
...\" 
...\" ----------------------------------------------------------------------
.sp 2
.in -0.25i
\s+1\*L
Synopsis
\*O\s-1
.in +0.25i
.sp 1
...\" ----------------------------------------------------------------------
...\" 
...\" 
.P
\*Lcds_dbdump\*O is invoked as follows:
...\" 
...\" 
.iS
    \*Lcds_dbdump\*V {\*Lc|t|m\*V} filename\*O
.iE
...\" 
...\" 
...\" 
.P
The three specific ways of invoking are:
.iS
    \*Lcds_dbdump c \*Vcheckpoint_file\*O
.iE
...\" 
.P
or:
.iS
    \*Lcds_dbdump t \*Vtransaction_log\*O
.iE
...\" 
.P
or:
.iS
    \*Lcds_dbdump m \*Vmessage_log\*O
.iE
...\" 
...\" 
...\" 
.P
Where:
...\" 
...\" 
...\" 
.VL 1.5i
.LI "\*Vcheckpoint_file\*O"
specifies the checkpoint file to be dumped.
.LI "\*Vtransaction_log\*O"
specifies the transaction log file to be dumped.
.LI "\*Vmessage_log\*O
specifies the message log file to be dumped.
.LE
...\"
...\" 
...\" 
...\"
...\" ----------------------------------------------------------------------
.H 3 "cdsd_diag"
...\" ----------------------------------------------------------------------
...\"  
...\" 
.P
\*Lcdsd_diag\*O is a simple command language parser for the CDS server
diagnostic interface. It is built from
...\" 
.DS
    \*Vdce-root-dir\*L/dce/src/directory/cds/server/sdi_ui.c\*O
.DE
...\" 
.P
with the rest of CDS.
...\" 
...\" 
...\" 
.P
The following commands are available:
...\" 
.BL
...\" 
...\" 
.LI
\*Lbroadcast\*O
...\" 
...\" 
.LI
\*Lclose\*O
...\" 
...\" 
.LI
\*Ldisable\*O
...\" 
...\" 
.LI
\*Ldump\*O
...\" 
...\" 
.LI
\*Lenable\*O \*Vevent_identifier\*O
...\" 
.P
Where \*Vevent_identifier\*O is one of the following keywords:
...\" 
.BL
.LI
\*Lacs_override\*O
.LI
\*Lemaa_logging\*O
.LI
\*Levent\*O
.LI
\*Lfast_asts\*O
.LI
\*Ljanitor\*O
.LI
\*Lmem_full_abort\*O
.LI
\*Lmem_sweep\*O
.LI
\*Lmessage_logging\*O
.LI
\*Lnode_verification\*O
.LI
\*LrandomizeCH\*O
.LI
\*Lsuperchunks\*O
.LE
...\" 
...\" 
.LI
\*Lexamine\*O \*Videntifier\*O
...\" 
.P
Where \*Videntifier\*O is one of the following structure codes:
...\" 
.VL 1i
.LI "\*Ladv\*O"
Advertiser Pinger Block
...\" 
.LI "\*Laob\*O"
Asynchronous Operation Block
...\" 
.LI "\*Laoq\*O"
Asynchronous Operation Queue
...\" 
.LI "\*Laostats\*O"
Asynchronous Operation Statistics
...\" 
.LI "\*Latp\*O"
Active Thread Pool
...\" 
.LI "\*Lchb\*O"
Clearinghouse Block
...\" 
.LI "\*Lcv\*O"
Condition Variable
...\" 
.LI "\*Ldhe\*O"
Directory Hash Entry
...\" 
.LI "\*Ldht\*O"
Directory Hash Table
...\" 
.LI "\*Lfib\*O"
File Information Block
...\" 
.LI "\*Lfip\*O"
File Information Pool
...\" 
.LI "\*Lmtrace\*O"
Allocation Certificate
...\" 
.LI "\*Lmutex\*O"
Mutex
...\" 
.LI "\*Lncb\*O"
Network Control Block
...\" 
.LI "\*Lnsb\*O"
Name Server Block
...\" 
.LI "\*Lstm\*O"
Database Stream
...\" 
.LI "\*Ltcb\*O"
Thread Control Block
...\" 
.LI "\*Lthlog\*O"
Threads Log
...\" 
.LI "\*Lthstats\*O"
Thread Statistics
...\" 
.LI "\*Ltrq\*O"
Thread Run Queue
...\" 
.LI "\*Lttq\*O"
Thread Timer Queue
...\" 
.LI "\*Lvmstats\*O"
VM Statistics
...\" 
.LE
...\" 
...\" 
.LI
\*Lexit\*O
...\" 
...\" 
.LI
\*Lflush\*O
...\" 
...\" 
.LI
\*Lload\*O
...\" 
...\" 
.LI
\*Lmanage\*O \*Vsubcommand\*O
.P
Where \*Vsubcommand\*O is one of the following:
...\" 
...\" 
.BL
.LI
\*Lcc\ \*V<clearinghouse>\ <directory>\*O
.P
create \*Vclearinghouse\*O at \*Vdirectory\*O
...\" 
.LI
\*Lcs\*O
.P
create server
...\" 
.LI
\*Ldc\ \*V<clearinghouse>\*O
.P
disable \*Vclearinghouse\*O
...\" 
.LI
\*Lds\*O
.P
disable server
...\" 
.LI
\*Lec\ \*V<clearinghouse>\*O
.P
enable \*Vclearinghouse\*O
...\" 
.LI
\*Les\*O
.P
enable server
...\" 
.LI
\*Lfc\ \*V<clearinghouse>\*O
.P
forget (clear) \*Vclearinghouse\*O
...\" 
.LI
\*Lin\ \*V<name_space>\ <clearinghouse_name>\ <owner>\*O
.P
initialize \*Vname_space\*O
...\" 
.LI
\*Lrc\ \*V<clearinghouse>\*O
.P
remove \*Vclearinghouse\*O
...\" 
.LI
\*Lxs\*O
.P
delete server
...\" 
.LE
...\" 
...\" 
.LI
\*Lmark\*O
...\" 
...\" 
.LI
\*Lnavigate\*O
...\" 
...\" 
.LI
\*Lset\*O \*Videntifier\*O
...\" 
.P
Where \*Videntifier\*O is one of the following keywords:
...\" 
.BL
.LI
\*Ladv_ping \*V<adv_address>\*O
.P
Possible values are: \*Linhibit\*O, \*Lnormal\*O, \*Lstrobe_normal\*O,
\*Lforce\*O
...\" 
.LI
\*Lalt_edb\*O
.P
Possible values are: \*Lnormal\*O, \*Lallon\*O, \*Lalloff\*O, \*Llogical\*O
...\" 
.LI
\*Lcompression \*V<fib_address> <level>\*O
...\" 
.LI
\*Lforce_back \*V<fib_address>\*O
.P
Possible values are: \*Lon\*O, \*Loff\*O
...\" 
.LI
\*Lforce_ckpt \*V<fib_address>\*O
.P
Possible values are: \*Lon\*O, \*Loff\*O
...\" checkpoint
...\" 
.LI
\*Linhibit_back \*V<fib_address>\*O
.P
Possible values are: \*Lon\*O, \*Loff\*O
...\" 
.LE
...\" 
...\" 
.LI
\*Lshow\*O
...\" 
...\" 
.LI
\*Lsignal\*O
...\" 
...\" 
.LI
\*Lsummarize\*O
...\" 
...\" 
.LE
...\" 
...\" 
...\" .zZ "Added CDS utilities info"
...\" 
...\" 
...\" 
...\" ----------------------------------------------------------------------
.H 2 "Some CDS Questions and Answers"
...\" ----------------------------------------------------------------------
...\" 
...\" .zA "Added Questions and Answers"
.P
This section contains several CDS questions and answers that have arisen during
DCE porting and application development efforts so far. Some of this
material is not directly applicable to porting but is included here as useful
background information about the component and DCE.
...\" 
...\" 
.VL .5i
...\" 
...\" QUESTION 1:
.LI "\*LQ1:\*O"
Is it possible to have DCE Security \*Vcompiled\*O on, but \*Vconfigured\*O off,
(so that \*Lcdsclerk\*O doesn't try to authenticate itself or be authenticated
by \*Lcdsd\*O)?  If so, how does one go about doing this?
.LI "\*LA:\*O"
Not as the code is now, although it isn't that hard to modify the code. There
are no plans to do this in the DCE distribution sources.
...\" 
...\" 
...\" 
...\"  QUESTION 2:
.LI "\*LQ2:\*O"
Are there any \*Vunauthenticated\*O commands that \*Lcdscp\*O can make which
will communicate with the server?
.LI "\*LA:\*O"
This depends on the contents of the ACL entries. Unauthenticated ACL entries will
enable almost any operation by unauthenticated users.
...\" 
...\" 
...\" 
...\"  QUESTION 3:
.LI "\*LQ3:\*O"
If there is no CDS advertiser, how does one find out if there is an existing CDS
clerk running with the same identity?
.LI "\*LA:\*O"
You cannot run a CDS clerk on a production system without an advertiser. You can
use the \*Lps\*O command to show the command line used to start the clerk. The
user name is the value of the \*L-U\*O option.
...\" 
...\" 
...\" 
...\"  QUESTION 4:
.LI "\*LQ4:\*O"
On systems that do not support shared memory, can the CDS advertiser and the
CDS clerk be combined into one program? What needs to be done to accomplish this?
How difficult is this to do, and what would be its implications?
.LI "\*LA:\*O"
It is of course possible to do this, but it would not be a trivial task.
.P
The goal of CDS development for DCE 1.0 was to leverage
existing software (DECdns) and integrate it with DCE facilities. The result
had to be portable to UNIX systems. There has been no motivation to change
the implementation of the clerk and advertiser in DCE 1.0.
...\" 
...\" 
...\" 
...\"  QUESTION 5:
.LI "\*LQ5:\*O"
Do the \*Lcds_cache.*\*O files cache information for the CDS advertiser? Do they
also cache information for the CDS clerk?
.LI "\*LA:\*O"
Yes to both questions. The advertiser caches information it receives from local
and/or remote CDS servers, while the clerks cache information they deduce as a
result of traversing the namespace tree and that they receive from entry name and
attribute type/value mappings.
...\" 
...\" 
...\" 
...\"  QUESTION 6:
.LI "\*LQ6:\*O"
Is it possible to run two CDS servers in the same cell ?
.LI "\*LA:\*O"
Yes. Just choose the \*LCONFIGURE\*O and \*LAdditional Server Configuration\*O
options in \*Ldce_config\*O.
.P
As a matter of fact, it is \*Vrecommended\*O that you have more than one CDS
server running in a cell. When there are multiple CDS servers running, you can
have different clearinghouses on different machines, thus increasing namespace
reliability and efficiency.
...\" 
...\" 
...\" 
...\"  QUESTION 7:
.LI "\*LQ7:\*O"
Is it possible to create two new clearinghouses and then work with a replica of
the second one? 
.LI "\*LA:\*O"
You can use the
.iS
    cdscp set cdscp preferred clearinghouse
.iE
.P
command to use whatever clearinghouse you want. Note however that this is true only
for reading attribute values.
.P
In DCE 1.0 you must manually replicate directories if you want them to be held in
multiple clearinghouses.
...\" 
...\" QUESTION 8:
...\" 
.LI "\*LQ8:\*O"
Is it necessary to have the DCE Time Service running in order to run the
CDS tests?
.LI "\*LA:\*O"
No, you don't need DTS running to run the CDS tests.
.P
Strictly speaking, it is not \*Vnecessary\*O to run \*Ldtsd\*O (the DTS
server) for any part of DCE. The function of DTS is simply to synchronize
clocks, not to provide any service as such. The DTS library routines (that
is, the client side code) always get the time from the local clock, and this
is what other DCE components call. Of course, the DTS tests do require
\*Ldtsd\*O to be running, since they test synchronization.
.P
Note that the DCE Security Service assumes the existence of loosely synchronized
clocks; timestamp comparisons done by Security allow for a five-minute ``slop''
period and no more than this. Security will thus deny access to systems with
clocks which deviate from ``correct'' time (the security server's time) by more
than about five minutes. However, this clock synchronization can be done by hand
or via NTP.
...\" 
.P
What, then, is the reason for having a Distributed Time Service? DTS is an
easy-to-manage DCE-integrated time supplier that implements a single
Virtual Clock in the distributed environment, thereby enabling the reliable
comparison of timestamps generated at different sites.
...\" 
...\" 
...\" 
...\" 
...\" 
...\" 
...\" 
...\" QUESTION 9:
...\" 
.LI "\*LQ9:\*O"
Is it possible to configure a CDS server on a CDS client machine? Or,
to put it another way, can one have a clearinghouse locally on a
client?
.LI "\*LA:\*O"
Yes. The way to do this is to \*Ldce_config\*O the client machine as a
local CDS server. The client machine will then become a CDS server with
a replica clearinghouse located locally. From then on, you can create CDS
directories and show them in the new clearinghouse on the new CDS server,
whether the original CDS server is running or not.
.P
Note that the second clearinghouse can also be created this way when
running the CDS killer (\*Lcp_killer.sh\*O) tests; you don't have to create
it on the original CDS server machine.
...\" 
...\" 
...\" 
...\" QUESTION 10:
...\" 
.LI "\*LQ10:\*O"
Which machines must the \*Lcdsadv\*O daemon be running on? Clients only,
or both clients and servers?
.LI "\*LA:\*O"
You need a CDS advertiser on \*Vevery\*O machine that will make use of CDS.
This means \*Vboth\*O clients \*Vand\*O servers. The advertiser's main purpose
is to handle the advertisement protocol that finds the \*Lcdsd\*Os running in
the cell (although it does this with a broadcast which can be limited by the
physical network). The advertiser is also responsible for spawning one
CDS clerk for each user on the machine. (Note that ``user'' here means \*VUnix\*O
user, not DCE principal.)  So, if you login with the same UID twice and do two
different \*Ldce_login\*Os, both processes will be talking to the same clerk.
...\" 
...\" 
...\" QUESTION 11:
...\" 
.LI "\*LQ11:\*O"
What is the so-called ``global cache''?
...\" 
...\" 
.LI "\*LA:\*O"
There is a cache that lives in shared memory on all CDS client machines
(remember that all server machines are also client machines). This shared
memory cache is created by the CDS advertiser when it starts up. Each CDS
clerk maps the cache into its own address space, so the cache is shared. Two
types of information are stored in it:
.AL
.LI
Responses to the advertisements that the CDS advertiser receives.
.P
The responses are stored here so that any \*Lcdsclerk\*O can find one of the
known CDS servers.
.LI
Information that the clerks receive when servicing requests.  
.P
This second type of data is stored in two tables in the cache. The first
table consists of a list of all the table entries; the second table is a list,
for all the clerks on the machine, of which clerks can access which entries. If a
clerk finds that an entry it is looking for is in the cache, and that entry is
not in the access list for that clerk, it makes a call to the \*Lcdsd\*O to have
it perform an ACL check. If the clerk can access the object in question, its
list gets a pointer to the desired cache entry, with the result that this clerk
can now access the contents of this entry.
.LE
...\" 
...\" 
...\" 
...\" QUESTION 12:
...\" 
.LI "\*LQ12:\*O"
The \*VRelease Notes\*O for DCE 1.0 state that the CDS clerk dies after 20 minutes
of inactivity. Is this due to a timeout?
.LI "\*LA:\*O"
Yes. If another request is made, the advertiser will spawn a new clerk, as needed.
...\" 
...\" 
...\" 
...\" QUESTION 13:
...\" 
.LI "\*LQ13:\*O"
It is stated in the CDS part of \*VOSF DCE Administration Guide\(emCore Components\*O,
that it is not recommended that more than one clearinghouse be located on a given
machine. Does that mean that this practice is expressly forbidden, or is it just
discouraged? What are the negative consequences of having more than one clearinghouse
on a given node?
.LI "\*LA:\*O"
It is certainly possible to have more than one clearinghouse on a machine, but it is
usually a bad idea, since it will result in slower performance. Having two replicas of
the same data on the same machine will not help replication, since if the machine
goes down you will still lose both replicas.
...\" 
...\" 
...\" QUESTION 14:
...\" 
.LI "\*LQ14:\*O"
When using the \*Ldce_config\*O script, does one generally install all the desired
components before configuring any of them, or can one install-and-configure one
component after another?
.LI "\*LA:\*O"
You can do anything, as long as the component that you are attempting to configure
has previously been installed. There \*Vis\*O a definite order of things that must be
done when initializing a cell: here you \*Vmust\*O follow the configure options in
order. First you configure Security, then the initial CDS server. After that,
additional \*Lcdsd\*Os can be added at your leisure.
...\"   
...\" 
...\" 
...\" QUESTION 15:
...\" 
.LI "\*LQ15:\*O"
Why are there multiple clerks?
.LI "\*LA:\*O"
The primary reason for multiple clerks is security. 
.P
Client applications contact the advertiser when they first attempt to
contact cdsd (i.e., as the result of their first CDS access); in response,
the advertiser (as root) forks a cdsclerk process for it. This newly
created clerk then creates a socket which is owned by that requestor.
This is the way in which CDS requests from different applications can
be distinguished in regard to UNIX UID: in effect, each clerk process
embodies the principal ID (and associated permissions) of the application
whose request it was created to satisfy.
.P
Here is the key point: Since there are no ACLs implemented in the clerk,
whenever a request comes in to the advertiser that involves accessing in
any way the contents of the cache (even examining a particular entry in
the cache may not be permitted for a particular user), the advertiser has
to determine whether a request should be fulfilled by inspecting the
requestor's permissions. The advertiser does this by contacting the CDS
server, and it distinguishes requestors by clerks. The advertiser deals
with separate principals via the separate clerks: if there were only one
clerk (one socket), the advertiser could know only about one principal.
.P
In the present CDS design, the clerk becomes the principal: it does an
import_context of the client's DCE login context, and then contacts the
clearinghouse \*Vas the client principal\*O and gets back either real data
or an ACL violation.
.P
The way to think of the design of the clerk is that each clerk
maintains a separate cache of entries that the accessing principal
has been successfully granted access to. The shared memory
implementation simply saves space so that each clerk's cache need only
contain pointers to the actual clearinghouse, directory, or entry data.
If an entry is in a particular clerk's cache, it has already passed
the access control check at the server. The clerk \*Vnever\*O checks
access or determines who should have access to what.
.P
The cache is essentially managed by the advertiser. There are three major
cache areas: one for the clearinghouses; one for cached entries; and another
section partitioned into smaller sections, with each of these smaller sections
assigned to a clerk.
.P
The details are that the cache area (``in'' the advertiser) where all the
entries are kept is accessed by the clerks in order to resolve incoming
application requests. The clerks do this by first getting an ok from the
server; \(emthat is, the server tells the advertiser that the requestor has
the necessary permissions to access the data in question. The clerk is
then given a pointer to the data. From then on, the clerk has all the
rights to access this entry in the cache. The advertiser is out of the
picture at this point.
.P
An alternative to using sockets is to use secure RPC for clerk/advertiser
communications, but this would be expensive for performance.
...\"   
...\" 
...\" 
...\" QUESTION 16:
...\" 
.LI "\*LQ16:\*O"
Do I have to start the GDA, even if I am not running GDS?
.LI "\*LA:\*O"
It's always a good idea to start the GDA. Whenever CDS thinks that it might
have to cross a cell boundary, it forwards the request to the GDA. If the
GDA is not there, the scary error message
.oS
    Requested operation would result in lost connectivity to root directory
.oE
...\" 
.P
will be displayed. This can happen, for example, if a user mistypes the cell
name.
...\" 
...\" 
...\" 
...\" 
...\" 
...\" 
.LE
...\" 
...\" 
...\" .zZ "Added Questions and Answers"
...\" 
...\" .zZ "def,8422,R1.0.3,alphabetized symbol lists"
...\" 
...\" ----------------------------------------------------------------------

<!--
# @OSF_COPYRIGHT@
# 
# 
# HISTORY
# $Log: 3_programming.sgm,v $
# Revision 1.1.2.8  1996/12/14  20:23:54  wardr
# 	{edit,R1.2.2}
# 	penultimate format fixes
# 	[1996/12/14  20:21:41  wardr]
#
# Revision 1.1.2.7  1996/12/13  22:10:26  wardr
# 	{edit,R1.2.2}
# 	Fixed formatting problems
# 	[1996/12/13  22:08:16  wardr]
# 
# Revision 1.1.2.6  1996/12/12  21:30:06  wardr
# 	{edit,R1.2.2}
# 	Fixed formatting problems
# 	[1996/12/12  21:28:14  wardr]
# 
# Revision 1.1.2.5  1996/12/12  16:49:06  carrig
# 	{enh,R1.2.2}
# 	Minor edits
# 	[1996/12/12  16:46:50  carrig]
# 
# Revision 1.1.2.4  1996/12/06  21:09:45  carrig
# 	{enh,R1.2.2}
# 	Second pass for editor
# 	[1996/12/06  21:07:34  carrig]
# 
# Revision 1.1.2.3  1996/12/05  21:38:36  carrig
# 	{enh,R1.2.2}
# 	First pass to prepare for editing
# 	[1996/12/05  21:36:38  carrig]
# 
# Revision 1.1.2.2  1996/12/02  15:40:43  weir
# 	Removed thinsp entities, corrected other minor errors
# 	[1996/12/02  15:38:56  weir]
# 
# Revision 1.1.2.1  1996/12/01  20:43:07  weir
# 	Initial submission
# 	[1996/12/01  20:41:20  weir]
# 
# 	Initial submission
# 	[1996/11/29  20:35:29  weir]
# 
# $EndLog$
-->
<!-- Fragment document type declaration subset:
ArborText, Inc., 1988-1993, v.4001
<!DOCTYPE Book PUBLIC "-//Davenport//DTD DocBook V2.4//EN" [
]>
-->
<!---->
<!-- COPYRIGHT NOTICE-->
<!-- Copyright (c) 1990, 1991, 1992, 1993 Open Software Foundation, Inc.-->
<!-- ALL RIGHTS RESERVED (DCE).  See the file named COPYRIGHT.DCE in the-->
<!-- src directory for the full copyright text.-->
<!---->
<!---->
<!-- OLD HISTORY-->
<!-- Revision 1.1.6.12  1995/06/07  14:43:07  rcb-->
<!-- 	PRENTICE HALL reformat; final edits and changes-->
<!-- 	[1995/06/05  19:57:50  rcb]-->
<!---->
<!-- 	PRENTICE HALL reformat-->
<!-- 	[1995/04/13  16:33:30  rcb]-->
<!---->
<!-- 	incorporated 1.1 edits-->
<!-- 	[1995/04/13  16:09:57  rcb]-->
<!---->
<!-- Revision 1.1.6.11  1994/10/20  22:12:08  jshirley-->
<!-- 	Fixed cross references.-->
<!-- 	[1994/10/20  22:11:51  jshirley]-->
<!-- -->
<!-- Revision 1.1.6.10  1994/09/30  18:51:43  weir-->
<!-- 	Fixing internal cross-references-->
<!-- 	[1994/09/30  18:51:06  weir]-->
<!-- -->
<!-- Revision 1.1.6.9  1993/02/24  22:07:54  weir-->
<!-- 	Added a period-->
<!-- 	[1993/02/24  22:07:07  weir]-->
<!-- -->
<!-- Revision 1.1.6.8  1993/02/23  18:36:35  johnson-->
<!-- 	No changes made.-->
<!-- 	[1993/02/23  18:32:50  johnson]-->
<!-- -->
<!-- Revision 1.1.6.7  1993/02/19  20:29:11  weir-->
<!-- 	Fixed CR6766-->
<!-- 	[1993/02/19  20:28:22  weir]-->
<!-- -->
<!-- Revision 1.1.6.6  1993/01/28  18:46:46  cjd-->
<!-- 	Embedded copyright notice-->
<!-- 	[1993/01/28  18:07:52  cjd]-->
<!-- -->
<!-- Revision 1.1.6.5  1993/01/21  18:01:51  lmk-->
<!-- 	CR#4589: In response to a 1/19/93 change to the bug file, in-->
<!-- 	consultation with Howard Melman and John Dugas, decided to remove the-->
<!-- 	change I had made to the file in the last revision.  The changes-->
<!-- 	will be made instead to the Porting Guide.-->
<!-- 	[1993/01/21  17:57:51  lmk]-->
<!-- -->
<!-- Revision 1.1.6.4  1993/01/21  16:00:31  lmk-->
<!-- 	CR#4589: added Pthreads search path information-->
<!-- 	[1993/01/21  15:59:12  lmk]-->
<!-- -->
<!-- Revision 1.1.6.3  1993/01/15  19:00:21  johnson-->
<!-- 	CR#:     6452-->
<!-- 	File:    /src/app_gd/threads/3_programming.gpsml-->
<!-- 	Change:  Corrected routine names from pthread_global_lock_np and-->
<!-- 	         pthread_global_unlock_np (incorrect) to pthread_lock_global_np and-->
<!-- 	         pthread_unlock_global_np (correct)-->
<!-- 	[1993/01/15  18:59:09  johnson]-->
<!-- -->
<!-- Revision 1.1.6.2  1992/11/20  21:00:38  weir-->
<!-- 	Moved into 1.0.2doc tree-->
<!-- 	[1992/11/20  20:57:53  weir]-->
<!-- -->
<!-- Revision 1.1.4.6  1992/11/11  23:54:33  buckler-->
<!-- 	Corrected index entries-->
<!-- 	[1992/11/11  22:59:41  buckler]-->
<!-- -->
<!-- Revision 1.1.4.5  1992/11/06  16:36:40  lmk-->
<!-- 	Prentice-Hall index edits only-->
<!-- 	[1992/11/06  16:33:56  lmk]-->
<!-- -->
<!-- Revision 1.1.4.4  1992/10/12  22:19:47  casey-->
<!-- 	Index corrections for PH-->
<!-- 	[1992/10/12  22:16:32  casey]-->
<!-- -->
<!-- Revision 1.1.4.3  1992/10/08  17:45:41  lmk-->
<!-- 	Prentice-Hall edits only-->
<!-- 	[1992/10/08  17:44:04  lmk]-->
<!-- -->
<!-- Revision 1.1.4.2  1992/09/10  20:43:12  buckler-->
<!-- 	Second editorial review-->
<!-- 	[1992/09/10  20:39:20  buckler]-->
<!-- -->
<!-- Revision 1.1.2.4  1992/07/02  19:35:31  johnson-->
<!-- 	Defect:  3880-->
<!-- -->
<!-- 	File: src/app_gd/threads/3_programming.gpsml-->
<!-- 	Short description:  Corrected coding error.-->
<!-- 	[1992/07/02  19:34:10  johnson]-->
<!-- -->
<!-- Revision 1.1  1992/01/29  16:07:00  damon-->
<!-- 	Initial revision-->
<!-- -->
<!---->
<!-- Copyright 1991, Open Software Foundation, Inc.  ALL RIGHTS RESERVED.-->
<!-- ********************************************************************-->
<!--                                                                    *-->
<!-- COPYRIGHT (c) 1991 BY DIGITAL EQUIPMENT CORPORATION,               *-->
<!-- Maynard, Massachusetts                                             *-->
<!-- All Rights Reserved.                                               *-->
<!--                                                                    *-->
<!-- This document is furnished under a license and may be used and     *-->
<!-- copied only in accordance with the terms of such license and with  *-->
<!-- the inclusion of the above copyright notice.  No title to or        *-->
<!-- ownership of the document is hereby transferred.                   *-->
<!--                                                                    *-->
<!-- The information in this document is subject to change without      *-->
<!-- notice and should not be construed as a commitment by Digital      *-->
<!-- Equipment Corporation.                                             *-->
<!--                                                                    *-->
<!-- ********************************************************************-->
<Chapter Id="DCEADG.THRPR.div.1">
<Title>Programming with Threads</Title>
<IndexTerm Id="DCEADG.THRPR.indx.1">
<Primary>programming with threads</Primary>
</IndexTerm>
<Para>This chapter discusses issues you face when writing a multithreaded
program and how to deal with those issues.
</Para>
<Para>The topics discussed in this chapter are as follows:
</Para>
<ItemizedList>
<ListItem>
<Para>Calling UNIX services
</Para>
</ListItem>
<ListItem>
<Para>Using signals
</Para>
</ListItem>
<ListItem>
<Para>Nonthreaded libraries
</Para>
</ListItem>
<ListItem>
<Para>Avoiding nonreentrant software
</Para>
</ListItem>
<ListItem>
<Para>Avoiding priority inversion
</Para>
</ListItem>
<ListItem>
<Para>Using synchronization objects
</Para>
</ListItem>
<ListItem>
<Para>Signaling a condition variable
</Para>
</ListItem>
</ItemizedList>
<Sect1 Id="DCEADG.THRPR.div.2">
<Title>Calling UNIX Services</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.2">
<Primary>calling</Primary>
<Secondary>UNIX services</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.3">
<Primary>UNIX</Primary>
<Secondary>services</Secondary>
</IndexTerm>On a UNIX system that does not have kernel support for threads, making system 
and library calls from within a multithreaded
program raises the following issues:
</Para>
<ItemizedList>
<ListItem>
<Para>System calls may not be thread-reentrant.
</Para>
</ListItem>
<ListItem>
<Para>If a system call blocks, it blocks the entire process instead of
blocking the calling thread only.
</Para>
</ListItem>
</ItemizedList>
<Sect2 Id="DCEADG.THRPR.div.3">
<Title>Jacket Routines</Title>
<IndexTerm Id="DCEADG.THRPR.indx.4">
<Primary>jacket routines</Primary>
</IndexTerm>
<Para>To resolve the previous two issues, DCE Threads provides jacket
routines for a number of UNIX system calls.  Threads call the jacket routine
instead of the UNIX system service; this allows DCE Threads to
take action on behalf of the thread before or after calling the system
service.  For example, the jacket routines ensure that only one thread calls
any particular service at a time to avoid problems with system calls that
are not thread-reentrant.
</Para>
<Para>Jacket routines are provided for UNIX input and output system calls
(documented in any UNIX programmer's manual) and
the <Function>fork()</Function> and <Function>sigaction()</Function> system calls.  Jackets are not
provided for any other UNIX system calls or for any of the C runtime
library services. 
See <Filename>/usr/include/dce/cma_ux.h</Filename> for the full list of jacket routines. 
</Para>
<Sect3 Id="DCEADG.THRPR.div.4">
<Title>Input and Output Jacket Routines</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.5">
<Primary>routines</Primary>
<Secondary>jacket</Secondary>
<See>jacket routines</See>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.6">
<Primary>input jacket routines</Primary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.7">
<Primary>output jacket routines</Primary>
</IndexTerm>Jacket routines are provided for routines that perform input and output
operations.  Examples of these operations are as follows:
</Para>
<ItemizedList>
<ListItem>
<Para>Open or create files, pipe symbols, and sockets
<IndexTerm Id="DCEADG.THRPR.indx.8">
<Primary>opening files with jacket routines</Primary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.9">
<Primary>creating</Primary>
<Secondary>files with jacket routines</Secondary>
</IndexTerm></Para>
</ListItem>
<ListItem>
<Para>Send and receive messages on sockets
<IndexTerm Id="DCEADG.THRPR.indx.10">
<Primary>sending and receiving messages on sockets</Primary>
</IndexTerm></Para>
</ListItem>
<ListItem>
<Para>Read and write files and pipe symbols
<IndexTerm Id="DCEADG.THRPR.indx.11">
<Primary>file</Primary>
<Secondary>reading/writing with jacket routines</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.12">
<Primary>reading/writing files with jacket routines</Primary>
</IndexTerm></Para>
</ListItem>
</ItemizedList>
<Para><?sml-need 6>Jacket routines are provided for Input/Output services so that DCE Threads
can determine when to issue or block the service call based on
the results of the <Function>select()</Function> system call.  For these UNIX services, 
DCE Threads can determine whether issuing the system call causes the
process to block.  If the system call causes the process to block, DCE
Threads blocks only the calling thread and schedules another thread
to run in its place.
</Para>
<Para>Periodically, DCE Threads checks whether the original calling
thread can issue its operation without blocking the process.  When the thread
runs without blocking the process, that thread is placed back into the queue
of ready threads and, at its turn, the thread resumes execution and issues
the system call.  Therefore, the jacket routines provide thread-synchronous
I/O operations where otherwise the system calls block the entire process.
</Para>
</Sect3>
<Sect3 Id="DCEADG.THRPR.div.5">
<Title>The <Function>fork()</Function> Jacket Routine</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.13" SpanEnd="DCEADG.THRPR.indx.3">Jackets are provided for the <Function>fork()</Function> system
call.  A specific thread environment must exist in the forked process
when it resumes (begins) execution.  These jacket routines allow code
to be executed in the context of the new process before the user code
resumes execution in it.
</Para>
</Sect3>
<Sect3 Id="DCEADG.THRPR.div.6">
<Title>The <Function>atfork()</Function> Routine</Title>
<Para>The <Function>atfork()</Function> routine allows an application or library to ensure 
predicted behavior when the <Function>fork()</Function> routine is used in a multithreaded 
environment.
Using the <Function>fork()</Function> routine from a threaded application or from an application
that uses threaded libraries can result in unpredictable behavior.  
For example, one thread has a mutex locked, and the state covered by that
mutex is inconsistent while another thread calls the <Function>fork()</Function> 
routine.  In the
child process, the mutex will be in the locked state, and it cannot be 
unlocked because only the forking thread exists in the child process.
Having the child 
reinitialize the mutex is unsatisfactory because this approach does
not resolve the question of how to correct the inconsistent state
in the child.
</Para>
<Para><?sml-need 3>The <Function>atfork()</Function> routine provides a way for threaded applications
or libraries to protect themselves when a <Function>fork()</Function> occurs.  The 
<Function>atfork()</Function> routine
allows you to set up routines that will run at the following times:
<IndexTerm Id="DCEADG.THRPR.indx.14">
<Primary>running routines with <Function>fork()</Function></Primary>
</IndexTerm></Para>
<ItemizedList>
<ListItem>
<Para>Prior to the <Function>fork()</Function> in the parent process 
</Para>
</ListItem>
<ListItem>
<Para>After the <Function>fork()</Function> in the child process
</Para>
</ListItem>
<ListItem>
<Para>After the <Function>fork()</Function> in the parent process
</Para>
</ListItem>
</ItemizedList>
<Para>Within these routines, you can ensure that all mutexes are locked prior to 
the <Function>fork()</Function> and that they are unlocked after the <Function>fork()</Function>, thereby 
protecting any data
or resources associated with the mutexes.  You can register any number of 
sets of <Function>atfork()</Function> routines; that is, any number of
libraries or user programs can set up <Function>atfork()</Function> routines and they
will all execute at <Function>fork()</Function> time.  
</Para>
<Note>
<Para>Using the <Function>atfork()</Function> routine can
potentially cause a deadlock if two applications or libraries call
into one another using calls that require locking. 
Specifically, when these component's routines use the <Function>atfork()</Function> 
routine to run prior to the fork in the parent process, a deadlock may occur 
when these routines are executing.
</Para>
</Note>
</Sect3>
<Sect3 Id="DCEADG.THRPR.div.7">
<Title>Using the Jacketed System Calls</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.15">
<Primary>using jacketed system calls</Primary>
</IndexTerm>You do not have to rename your system calls to take advantage of the jacket
routines.  Macros put the jacket routines into place when you compile 
your program; these macros rename the jacketed system calls to 
the name of the DCE Threads jacket routine.  Thus, a reference to
the DCE Threads jacket routine is compiled into your code instead of
a reference to the system call.  When the code is executed, it calls the
jacket routine, which then calls the system on your code's behalf.
</Para>
<Para>If you do not wish to use any of the jacket routines, you can add the 
following line to your program before any of the thread header files:
</Para>
<InformalExample>
<Para><ProgramListing>#define _CMA_NOWRAPPERS_
</ProgramListing></Para>
</InformalExample>
<Para>By adding this definition, you prevent 
the jacket routines from being substituted for the real routines.
<IndexTerm Id="DCEADG.THRPR.indx.16" SpanEnd="DCEADG.THRPR.indx.4"></Para>
<Para><?sml-need 5>
<IndexTerm Id="DCEADG.THRPR.indx.17">
<Primary>undefining jackets</Primary>
</IndexTerm>If you wish to use most of the jackets but do not wish to use a specific 
jacket, you can undefine a specific jacket by adding the following 
directive after the thread header files:
</Para>
<InformalExample>
<Para><ProgramListing><UserInput>#undef <Symbol Role="Variable">routine_name
</Symbol></UserInput></ProgramListing></Para>
</InformalExample>
<Para>For example, to not use the fork jacket, you can add the following:
</Para>
<InformalExample>
<Para><ProgramListing>#undef fork
</ProgramListing></Para>
</InformalExample>
</Sect3>
</Sect2>
<Sect2 Id="DCEADG.THRPR.div.8">
<Title>Blocking System Calls</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.18">
<Primary>blocking system calls</Primary>
</IndexTerm>DCE Threads provides jacket routines that make certain system calls
thread-synchronous. 
If calling one of these jacketed system calls would
normally block the process, the jacket routine ensures that only the
calling thread is blocked and that the process remains available to
execute other threads.  Examples of jacketed system calls include
<Function>read()</Function>, <Function>write()</Function>, <Function>open()</Function>, <Function>socket()</Function>, <Function>send()</Function>, and 
<Function>recv()</Function>.
</Para>
<Para>If a thread makes a call to any of the other nonjacketed blocking
system calls (or if it calls one of the jacketed system calls without
going through the jacket), then when the system call blocks the
thread, it blocks the whole process, preventing any other threads in
the process from executing.  Examples of nonjacketed system calls 
include <Function>wait()</Function>, <Function>sigpause()</Function>, <Function>msgsnd()</Function>,
<Function>msgrcv()</Function>, and <Function>semop()</Function>. 
</Para>
<Para>Some care must be used when calling nonjacketed blocking system
calls from a multithreaded program.  Other threads in the program may
not be able to tolerate not running for an extended period of time
while the process blocks for the system call.  If your program must
make use of such system calls, the calling thread should specify a
nonblocking or polling option to the system call.  If the call is not
successful, then the calling thread
should retry; however, to prevent the retry code from becoming a hot
loop, a yield or delay function call should be inserted into the path.
This gives other threads in the program a chance to run between poll
attempts.
</Para>
</Sect2>
<Sect2 Id="DCEADG.THRPR.div.9">
<Title>Calling fork() in a Multithreaded Environment</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.19">
<Primary>calling</Primary>
<Secondary><Function>fork()</Function></Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.20">
<Primary><Function>fork()</Function></Primary>
<Secondary>calling</Secondary>
</IndexTerm>The <Function>fork()</Function> system call creates an exact duplicate of the address space
from which it is called, resulting in two address spaces executing the
same code.  Problems can occur if the forking address space has
multiple threads executing at the time of the <Function>fork()</Function>.  When
multithreading is a result of library invocation, threads are not
necessarily aware of each other's presence, purpose, actions, and so
on.  Suppose that one of the other threads (any thread other than the
one doing the <Function>fork()</Function>) has the job of deducting money from your
checking account.  Clearly, you do not want this to happen twice as a
result of some other thread's decision to call <Function>fork()</Function>.
</Para>
<Para>Because of these types of problems, which in general are problems of
threads modifying persistent state, POSIX defined the behavior of
<Function>fork()</Function> in the presence of threads to propagate only the forking
thread.  This solves the problem of improper changes being
made to persistent state.  However, it causes other problems, as 
discussed in the next paragraph.
</Para>
<Para>In the POSIX model, only the forking thread is propagated.  
All the other threads are eliminated without any
form of notice; no cancels are sent and no handlers are run.  However,
all the other portions of the address space are cloned, including
all the mutex state.  If the other thread has a mutex locked, the
mutex will be locked in the child process, but the lock owner will
not exist to unlock it.  Therefore, the resource protected by
the lock will be permanently unavailable.  
</Para>
<Para>The fact that there may be mutexes outstanding only becomes a
problem if your code attempts to lock a mutex that could be locked
by another thread at the time of the <Function>fork()</Function>.  This
means that you cannot call outside of your own code
between the call to <Function>fork()</Function> and the call to <Function>exec()</Function>.  Note that a call
to <Function>malloc()</Function>, for example, is a call outside of the currently executing
application program and may have a mutex outstanding.  
The following code obeys these guidelines and is therefore safe:
</Para>
<InformalExample>
<Para><ProgramListing>fork ();
a = 1+2;  /* some inline processing */
exec();
</ProgramListing></Para>
</InformalExample>
<Para>Similarly, if your code calls some of your own code that does not
make any calls outside of your code and does not lock any mutexes
that could possibly be locked in another thread, then your code is
safe.
</Para>
<Para>One solution to the problem of calling <Function>fork()</Function> in a multithreaded 
environment exists. (Note that this method will not
work for server application code or any other
application code that is invoked by a callback from a library.) 
Before an application performs a <Function>fork()</Function> followed by something other
than <Function>exec()</Function>, it must cancel all of the other threads.  After it joins 
the canceled threads, it can safely <Function>fork()</Function> because 
it is the only thread in
existence.  This means that libraries that create threads
must establish cancel handlers that propagate the cancel to the
created threads and join them.  The application should save
enough state so that the threads can be recreated and restarted
after the <Function>fork()</Function> processing completes.
</Para>
</Sect2>
</Sect1>
<Sect1 Id="DCEADG.THRPR.div.10">
<Title>Using Signals</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.21">
<Primary>using signals</Primary>
</IndexTerm>The following subsections cover three topics: types of 
signals, DCE Threads signal handling,  and alternatives to using signals.
</Para>
<Sect2 Id="DCEADG.THRPR.div.11">
<Title>Types of Signals</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.22">
<Primary>types</Primary>
<Secondary>of signals</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.23">
<Primary>signals</Primary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.24">
<Primary>UNIX</Primary>
<Secondary>signals</Secondary>
</IndexTerm>Signals are delivered as a result of some event.  UNIX signals are grouped
into the following four categories of pairs that are orthogonal to each other:
</Para>
<ItemizedList>
<ListItem>
<Para>Terminating and synchronous
</Para>
</ListItem>
<ListItem>
<Para>Terminating  and asynchronous 
</Para>
</ListItem>
<ListItem>
<Para>Nonterminating and synchronous  
</Para>
</ListItem>
<ListItem>
<Para>Nonterminating and asynchronous
</Para>
</ListItem>
</ItemizedList>
<Para>The action that DCE Threads takes when a particular signal is
delivered depends on the characteristics of that signal.
</Para>
<Sect3 Id="DCEADG.THRPR.div.12">
<Title>Terminating Signals</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.25">
<Primary>terminating signals</Primary>
</IndexTerm>Terminating signals result in the termination of the process by
default.  Whether a particular signal is terminating or not is independent of
whether it is synchronously or asynchronously delivered.
</Para>
</Sect3>
<Sect3 Id="DCEADG.THRPR.div.13">
<Title>Nonterminating Signals</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.26">
<Primary>nonterminating signals</Primary>
</IndexTerm>Nonterminating signals do not result in the termination of the
process by default.
</Para>
<Para>Nonterminating signals represent events that can be either internal or
external to the process.  The process may require notification or
ignore these events.  When a
nonterminating asynchronous signal is delivered to the process,
DCE Threads awakens any threads that are waiting for the signal.
This is the only action that DCE Threads takes because, by
default, the signal has no effect.
</Para>
</Sect3>
<Sect3 Id="DCEADG.THRPR.div.14">
<Title>Synchronous Signals</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.27">
<Primary>synchronous signals</Primary>
</IndexTerm>Synchronous signals are the result of an event that occurs inside
a process and are delivered synchronously with respect to that event.  For
example, if a floating-point calculation results in an overflow, then a
<Literal>SIGFPE</Literal> (floating-point exception signal) is delivered to the process
immediately following the instruction that resulted in the overflow.
<!-- -->
<!-- -->
<!-- -->
</Para>
<Para>The default behavior of DCE Threads in DCE Version 1.0.2 when a synchronous
terminating signal occurs is to dump core; that is, to not handle the
signal.  This differs from the behavior prior to DCE Version 1.0.2, in which 
such a signal would be turned into an exception and propagated out to whatever
process was the original owner of the thread (namely the client, even
though the exception might have occurred in the server).  Therefore, if
an application using DCE Threads wants to handle such signals, it must
now set up a signal handler to do so by calling <Function>sigaction()</Function>.
Note that the new DCE Threads behavior is in fact similar to the default
behavior of most UNIX programs.
<!-- -->
<!-- -->
<!-- -->
</Para>
<Para>Synchronous, terminating signals represent an error that has occurred in the
currently executing thread.
</Para>
</Sect3>
<Sect3 Id="DCEADG.THRPR.div.15">
<Title>Asynchronous Signals</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.28">
<Primary>asynchronous signals</Primary>
</IndexTerm>Asynchronous signals are the result of an event that is external
to the process and are delivered at any point in a thread's execution when
such an event occurs.  For example, when a user running a program types the
interrupt character at the terminal (generally <Literal>&lt;Ctrl-C></Literal>), a <Literal>SIGINT</Literal> 
(interrupt signal) is delivered to the process.
</Para>
<Para>Asynchronous, terminating signals represent an occurrence of an event that
is external to the process and, if unhandled, results in the termination of
the process.  When an asynchronous terminating signal is delivered, DCE
Threads catches it and checks to see if any threads are waiting for
it.  If threads are waiting, they are awakened, and the signal is considered
handled and is dismissed.  If there are no waiting threads, then DCE
Threads causes the process to be terminated as if the signal had not 
been handled.
<IndexTerm Id="DCEADG.THRPR.indx.29">
<Primary>terminating</Primary>
<Secondary>threads</Secondary>
</IndexTerm></Para>
</Sect3>
</Sect2>
<Sect2 Id="DCEADG.THRPR.div.16">
<Title>DCE Threads Signal Handling</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.30">
<Primary>DCE</Primary>
<Secondary>Threads signal handling</Secondary>
</IndexTerm>DCE Threads provides the POSIX <Function>sigwait()</Function> service to allow threads to 
perform activities similar to signal handling without having to deal with 
signals directly.  It also provides a jacket for <Function>sigaction()</Function> 
that allows each thread to have its own handler for synchronous 
signals.
</Para>
<Para><IndexTerm Id="DCEADG.THRPR.indx.31">
<Primary>signal handlers</Primary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.32">
<Primary>UNIX</Primary>
<Secondary>signals</Secondary>
<Tertiary>installing signal handlers for</Tertiary>
</IndexTerm>In order to provide these mechanisms, DCE Threads installs
signal handlers for most of the UNIX signals during initialization.
</Para>
<Para>DCE Threads do not provide handlers for several UNIX signals.
Those signals and the reasons why handlers are not provided are
shown in Table 8-1.
<IndexTerm Id="DCEADG.THRPR.indx.33">
<Primary>UNIX signals</Primary>
<Secondary>table of</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.34">
<Primary>handlers not provided with UNIX signals</Primary>
</IndexTerm></Para>
<?sml-need 2i>
<Table Frame="all" Remap="center" Orient="Port">
<Title>Signals for Which Handlers Are Not Provided</Title>
<TGroup Rowsep="1" Colsep="1" Cols="2">
<ColSpec Rowsep="1" Colsep="1" Align="Left" Colwidth="1*" Colname="col1" Colnum="1">
<ColSpec Rowsep="1" Align="Left" Colwidth="1.2*" Colname="col2" Colnum="2">
<TBody>
<Row>
<Entry Rowsep="1"><Literal>Signal</Literal></Entry>
<Entry Rowsep="1"><Literal>Reason Handler Is Not Provided</Literal></Entry>
</Row>
<Row>
<Entry><Literal>SIGKILL</Literal> and <Literal>SIGSTOP</Literal></Entry>
<Entry>These signals cannot be caught by user mode code.
</Entry>
</Row>
<Row>
<Entry><Literal>SIGTRAP</Literal></Entry>
<Entry>Catching this signal interferes with debugging.
</Entry>
</Row>
<Row>
<Entry><Literal>SIGTSTP</Literal> and <Literal>SIGQUIT</Literal></Entry>
<Entry>These signals are caught only while a thread has issued a 
<Function>sigwait()</Function> call because their default actions are otherwise valuable.
</Entry>
</Row>
</TBody>
</TGroup>
</Table>
<!-- .cS-->
<!-- .VL 15m "-->
<!-- .LI "\*LSignal\\*O"-->
<!-- \*LReason Handler Is Not Provided\*O-->
<!-- .LI "\*LSIGKILL\*O and \*LSIGSTOP\*O"-->
<!-- These signals cannot be caught by user mode-->
<!-- code.-->
<!-- .LI "\*LSIGTRAP\*O"-->
<!-- Catching this signal interferes with debugging.-->
<!-- .LI "\*LSIGTSTP\*O and \*LSIGQUIT\*O"-->
<!-- These signals are caught only while a thread-->
<!-- has issued a sigwait call, because their default actions are otherwise-->
<!-- valuable.-->
<!-- .LE-->
<!-- .cE-->
<Sect3 Id="DCEADG.THRPR.div.17">
<Title>The POSIX <Function>sigwait()</Function> Service</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.35">
<Primary>sigwait service</Primary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.36">
<Primary>POSIX</Primary>
<Secondary>sigwait service</Secondary>
</IndexTerm>The DCE Threads implementation of the POSIX <Function>sigwait()</Function> service allows
any thread to block until one of a specified set of signals is delivered.  A
thread waits for any of the asynchronous signals, except for <Literal>SIGKILL</Literal> and
<Literal>SIGSTOP</Literal>. 
</Para>
<Para>A thread cannot wait for a synchronous signal.  This is because
synchronous signals are the result of an error during the execution of a
thread; if the thread is waiting for a signal, then it is not executing.
Therefore, a synchronous signal cannot occur for a particular thread while
it is waiting, and so the thread waits forever.
POSIX stipulates that the thread must block the signals (using the 
UNIX system service <Function>sigprocmask()</Function>) it waits for
before calling <Function>sigwait()</Function>.
</Para>
<?sml-need 10>
</Sect3>
<Sect3 Id="DCEADG.THRPR.div.18">
<Title>The POSIX <Function>sigaction()</Function> Service</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.37">
<Primary>POSIX</Primary>
<Secondary>sigaction service</Secondary>
</IndexTerm>The DCE Threads implementation of the POSIX <Function>sigaction()</Function> service
allows for per-thread handlers to be installed for catching
synchronous signals.  The <Function>sigaction()</Function> routine modifies
behavior only for individual threads and works only for synchronous
signals.  Setting the signal action to <Literal>SIG_DFL</Literal> for a specific signal
will restore the thread's default behavior for that signal.
Attempting to set a signal action for an asynchronous signal is an
error.
</Para>
</Sect3>
<Sect3 Id="DCEADG.THRPR.div.19">
<Title>The <Literal>itimer VTALARM</Literal></Title>
<Para>DCE Threads installs a handler for the <Literal>itimer VTALARM</Literal>.  Therefore, 
<Literal>VTALARM</Literal> is unavailable for use by other applications.
</Para>
</Sect3>
</Sect2>
<Sect2 Id="DCEADG.THRPR.div.20">
<Title>Alternatives to Using Signals</Title>
<Para>Avoid using UNIX signals in multithreaded programs.  DCE Threads 
provides alternatives to signal handling.  These alternatives are discussed
in more detail in Sections 8.6 and 8.7.
</Para>
<Note>
<Para>In order to implement these alternatives, DCE Threads must
install its own signal handlers.  These are installed when DCE
Threads initializes itself, typically on the first
thread-function call.  At this time, any existing signal handlers are
replaced.
</Para>
</Note>
<Para>Following are several reasons for avoiding signals:
</Para>
<ItemizedList>
<ListItem>
<Para>They cannot be used in a modular way in a multithreaded program.
</Para>
</ListItem>
<ListItem>
<Para>They are unnecessary when used as an asynchronous programming technique
in a multithreaded program.
</Para>
</ListItem>
<ListItem>
<Para>There are almost no threads services available at signal level.
</Para>
</ListItem>
<ListItem>
<Para>There is no reliable, portable way to modify predicates.
</Para>
</ListItem>
<ListItem>
<Para>The signal-handler interface is unsuitable for use with threads.  (For
example, there is one signal action per signal per process, there is 
one signal mask per process, and <Function>sigpause()</Function> blocks the whole process.) 
</Para>
</ListItem>
</ItemizedList>
<Para><?sml-need 9><IndexTerm Id="DCEADG.THRPR.indx.38" SpanEnd="DCEADG.THRPR.indx.23"><IndexTerm Id="DCEADG.THRPR.indx.39" SpanEnd="DCEADG.THRPR.indx.24">In a multithreaded program, signals cannot be used in a modular way because,
on most current UNIX implementations, signals are inherently a process
construct.  There is only one instantiation of each signal and of each signal
handler routine for all of the threads in an application.  If one thread
handles a particular signal in one way, and a different thread handles the
same signal in a different way, then the thread that installs its signal
handler last handles the signal.  This applies only to asynchronously 
generated signals; synchronous signals can be handled on a per-thread 
basis using the DCE Threads <Function>sigaction()</Function> jacket.
</Para>
<Para><IndexTerm Id="DCEADG.THRPR.indx.40">
<Primary>synchronous programming techniques</Primary>
</IndexTerm>Do not use asynchronous programming techniques in conjunction with threads,
particularly those that increase parallelism such as using timer signals and
I/O signals.  These techniques can be complicated.  They are also
unnecessary because threads provide a mechanism for parallel execution that
is simpler and less prone to error where concurrence can be of value.
Furthermore, most of the threads routines
are not supported for use in interrupt routines (such as signal handlers),
and portions of runtime libraries cannot be used reliably inside a signal
handler.
</Para>
</Sect2>
</Sect1>
<Sect1 Id="DCEADG.THRPR.div.21">
<Title>Nonthreaded Libraries</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.41">
<Primary>nonthreaded libraries</Primary>
</IndexTerm>As programming with threads becomes common practice, you need to
ensure that threaded code and nonthreaded code (code that is not
designed to work with threads) work properly together in the same
application.  For example, you may write a new application that uses
threads (for example, an RPC server),  and link it with a library that
does not use threads (and is thus not thread-safe).  In such a
situation you can do one of the following:
</Para>
<ItemizedList>
<ListItem>
<Para>Work with the nonthreaded software.
</Para>
</ListItem>
<ListItem>
<Para>Change the nonthreaded software to be thread-safe.
</Para>
</ListItem>
</ItemizedList>
<Sect2 Id="DCEADG.THRPR.div.22">
<Title>Working with Nonthreaded Software</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.42">
<Primary>global lock</Primary>
</IndexTerm>Thread-safe code is code that works properly in a threaded
environment.  To work with nonthread-safe code, associate the global
lock with all calls to such code. 
</Para>
<Para><?sml-need 6>You can implement the lock on the side of the routine user or the
routine provider.  For example, you can implement the lock on the side
of the routine user if you write a new application like an RPC server
that uses threads, and you link it with a library that does not.  Or,
if you have access to the nonthreaded code, the locks can be placed on
the side of the routine provider, within the actual routine. 
Implement the locks as follows: 
</Para>
<OrderedList>
<ListItem>
<Para>Associate one lock, a global lock, with execution of such code.
</Para>
</ListItem>
<ListItem>
<Para>Require all of your threads to lock prior to execution of
nonthreaded code.
</Para>
</ListItem>
<ListItem>
<Para>Perform an unlock when execution is complete.
</Para>
</ListItem>
</OrderedList>
<Para>By using the global lock, you ensure that only one thread executes in
outside libraries, which may call each other, and in unknown code.
Using a single global lock is safer than using multiple local locks 
because it is difficult to be aware of everything a library may be
doing or of the interactions that library can have with other
libraries. 
</Para>
</Sect2>
<Sect2 Id="DCEADG.THRPR.div.23">
<Title>Making Nonthreaded Code Thread-Reentrant</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.43">
<Primary>thread</Primary>
<Secondary>reentrant</Secondary>
</IndexTerm>Thread-reentrant code is code that works properly while multiple
threads execute it concurrently.  Thread-reentrant code is
thread-safe, but thread-safe code may not be thread-reentrant. 
Document your code as being thread-safe or thread-reentrant. 
</Para>
<Para>More work is involved in making code thread-reentrant than in making
code thread-safe.  To make code thread-reentrant, do the
following:
</Para>
<OrderedList>
<ListItem>
<Para>Use proper locking protocols to access global or static variables.
</Para>
</ListItem>
<ListItem>
<Para>Use proper locking protocols when you use code that is not 
thread-safe.
</Para>
</ListItem>
<ListItem>
<Para>Store thread-specific data on the stack or heap.
</Para>
</ListItem>
<ListItem>
<Para>Ensure that the compiler produces thread-reentrant code.
</Para>
</ListItem>
<ListItem>
<Para>Document your code as being thread-reentrant.
</Para>
</ListItem>
</OrderedList>
</Sect2>
</Sect1>
<Sect1 Id="DCEADG.THRPR.div.24">
<Title>Avoiding Nonreentrant Software</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.44">
<Primary>avoiding</Primary>
<Secondary>nonreentrant software</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.45">
<Primary>nonreentrant software</Primary>
</IndexTerm>The following subsections discuss 
two methods to help you avoid the pitfalls of
nonreentrant software.  These methods are as follows:
</Para>
<ItemizedList>
<ListItem>
<Para>Global lock
</Para>
</ListItem>
<ListItem>
<Para>Thread-specific storage
</Para>
</ListItem>
</ItemizedList>
<IndexTerm Id="DCEADG.THRPR.indx.46">
<Primary>thread-specific data</Primary>
</IndexTerm>
<Sect2 Id="DCEADG.THRPR.div.25">
<Title>Global Lock</Title>
<IndexTerm Id="DCEADG.THRPR.indx.47">
<Primary>nonreentrant software</Primary>
<Secondary>using global lock to avoid</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.48">
<Primary>lock</Primary>
<Secondary>global</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.49">
<Primary>global lock</Primary>
</IndexTerm>
<Para>Use a global lock, which has the characteristics of a recursive mutex,
instead of a regular mutex when calling routines that you think are
nonreentrant. (When in doubt, assume the code is nonreentrant.)
<IndexTerm Id="DCEADG.THRPR.indx.50">
<Primary>pthread functions</Primary>
</IndexTerm></Para>
<Para>The <Function>pthread_lock_global_np()</Function> 
routine is a locking protocol that is
used to call nonreentrant routines, often found in existing library packages
that were not designed to run in a multithreaded environment.
</Para>
<Para>The way to call a library function that is not reentrant from a
multithreaded program is to protect the function with a mutex.  If every
function that calls a library locks a particular mutex before the call and
releases the mutex after the call, then the function completes without
interference.  However, this is difficult to do successfully because the 
function may be called by many libraries.  A global lock solves
this problem by providing a universal lock.  Any code that calls any
nonreentrant function uses the same lock.
</Para>
<Para>To lock a global lock, call the <Function>pthread_lock_global_np()</Function> routine.
To unlock a
global lock, call the <Function>pthread_unlock_global_np()</Function> routine.
</Para>
<Note>
<Para>Many COBOL and FORTRAN compilers generate inherently nonreentrant code. 
Many C, Ada,
Pascal, and BLISS compilers generate reentrant code by default.  It is
possible to write nonreentrant code in the reentrant languages by not
following a locking protocol.
</Para>
</Note>
<IndexTerm Id="DCEADG.THRPR.indx.51">
<Primary>compilers</Primary>
<Secondary>generating nonreentrant code</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.52">
<Primary>compilers</Primary>
<Secondary>generating reentrant code</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.53">
<Primary>COBOL compiler</Primary>
<Secondary>generating nonreentrant code</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.54">
<Primary>C</Primary>
<Secondary>compiler</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.55">
<Primary>Ada compiler</Primary>
<Secondary>generating reentrant code</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.56">
<Primary>PASCAL compiler</Primary>
<Secondary>generating reentrant code</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.57">
<Primary>BLISS compiler</Primary>
<Secondary>generating reentrant code</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.58">
<Primary>reentrant code</Primary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.59">
<Primary>nonreentrant code</Primary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.60">
<Primary>generating nonreentrant code</Primary>
</IndexTerm>
</Sect2>
<Sect2 Id="DCEADG.THRPR.div.26">
<Title>Thread-Specific Storage</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.61">
<Primary>nonreentrant software</Primary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.62">
<Primary>thread-specific storage</Primary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.63">
<Primary>thread-specific data</Primary>
</IndexTerm>To avoid nonreentrancy when writing new software, avoid using global
variables to store data that is thread-specific data. 
</Para>
<Para>Alternatively, allocate thread-specific data on the stack or heap and
explicitly pass its address to called routines.
</Para>
</Sect2>
</Sect1>
<Sect1 Id="DCEADG.THRPR.div.27">
<Title>Avoiding Priority Inversion</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.64">
<Primary>avoiding</Primary>
<Secondary>priority inversion</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.65">
<Primary>priority</Primary>
<Secondary>inversion</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.66">
<Primary>multithreaded programming</Primary>
<Secondary>potential disadvantages</Secondary>
</IndexTerm>Priority inversion occurs when interaction among three or more threads
blocks the highest-priority thread from executing.  For example, a
high-priority thread waits for a resource locked by a low-priority thread,
and the low-priority thread waits while a middle-priority thread executes.
The high-priority thread is made to wait while a thread of lower priority 
(the middle-priority thread) executes.
</Para>
<Para>To avoid priority inversion, associate a priority with each resource and
force any thread using that object to first raise its priority to that
associated with the object.  This method of avoiding priority 
inversion is not a complete solution because all threads will then block 
at the same ceiling priority and be unblocked in FIFO order rather 
than by their actual priority.
</Para>
<Para>The <Literal>SCHED_OTHER</Literal> (default) scheduling policy prevents priority inversion 
from causing a complete blockage of the high-priority thread because the
low-priority thread is permitted to execute and release the
resource.  The <Literal>SCHED_FIFO</Literal> and <Literal>SCHED_RR</Literal> policies, however, do not 
force resumption of the low-priority thread if the middle-priority thread 
executes indefinitely.
</Para>
</Sect1>
<Sect1 Id="DCEADG.THRPR.div.28">
<Title>Using Synchronization Objects</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.67">
<Primary>using synchronization objects</Primary>
</IndexTerm>The following subsections discuss the use of mutexes to prevent two potential
problems: race conditions and deadlocks.  Also discussed is why you
should signal a condition variable with the associated mutex locked.
</Para>
<Sect2 Id="DCEADG.THRPR.div.29">
<Title>Race Conditions</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.68">
<Primary>synchronization objects</Primary>
<Secondary>race conditions</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.69">
<Primary>race conditions</Primary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.70">
<Primary>multithreaded programming</Primary>
</IndexTerm>A race condition occurs when two or more threads perform an operation, and
the result of the operation depends on unpredictable timing factors;
specifically, when each thread executes and waits and when each thread
completes the operation.
</Para>
<Para>An example of a race condition is as follows:
</Para>
<OrderedList>
<ListItem>
<Para>Both A and B are executing (X = X + 1).
</Para>
</ListItem>
<ListItem>
<Para>A reads the value of X (for example, X = 5).
</Para>
</ListItem>
<ListItem>
<Para>B comes in and reads the value of X and increments it (making X = 6).
</Para>
</ListItem>
<ListItem>
<Para>A gets rescheduled and now increments X. Based on its earlier 
read operation, A thinks (X+1 = 5+1 = 6).  X is now 6.  It should 
be 7 because it was incremented once by A and once by B.
</Para>
</ListItem>
</OrderedList>
<Para><IndexTerm Id="DCEADG.THRPR.indx.71">
<Primary>avoiding</Primary>
<Secondary>race conditions</Secondary>
</IndexTerm>To avoid race conditions, ensure that any variable modified by more than one
thread has only one mutex associated with it.  Do not assume that a 
simple add operation can be completed without allowing another thread 
to execute.  Such operations are generally not portable, especially to 
multiprocessor systems.  If it is possible for two threads to share a 
data point, use a mutex.
</Para>
</Sect2>
<Sect2 Id="DCEADG.THRPR.div.30">
<Title>Deadlocks</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.72">
<Primary>avoiding</Primary>
<Secondary>deadlocks</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.73">
<Primary>synchronization objects</Primary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.74">
<Primary>deadlock </Primary>
<Secondary>avoiding</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.75">
<Primary>multithreaded programming</Primary>
<Secondary>potential disadvantages</Secondary>
</IndexTerm>A deadlock occurs when one or more threads are permanently blocked from 
executing because each thread waits on a resource held by another thread 
in the deadlock.
A thread can also deadlock on itself.
</Para>
<Para>The following is one technique for avoiding deadlocks:
</Para>
<OrderedList>
<ListItem>
<Para>Associate a sequence number with each mutex.
</Para>
</ListItem>
<ListItem>
<Para>Lock mutexes in sequence.
</Para>
</ListItem>
<ListItem>
<Para>Do not attempt to lock
a mutex with a sequence number lower than that of a mutex the thread already
holds.
</Para>
</ListItem>
</OrderedList>
<Para>Another technique, which is useful when a thread needs to lock the same mutex
more than once before unlocking it, is to use a recursive mutex.
This technique prevents a thread from deadlocking on itself.
</Para>
</Sect2>
</Sect1>
<Sect1 Id="DCEADG.THRPR.div.31">
<Title>Signaling a Condition Variable</Title>
<Para><IndexTerm Id="DCEADG.THRPR.indx.76">
<Primary>condition variable</Primary>
<Secondary>signaling</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.77">
<Primary>mutex</Primary>
<Secondary>locking before signaling condition variable</Secondary>
</IndexTerm>
<IndexTerm Id="DCEADG.THRPR.indx.78">
<Primary>locking a mutex</Primary>
</IndexTerm>When you are signaling a condition variable and that signal may cause the
condition variable to be deleted, it is recommended that you signal or
broadcast with the mutex locked.
</Para>
<Para>The recommended coding for signaling a condition variable 
appears at the end of this chapter.
The following two C code fragments show coding that is <Replaceable>not recommended</Replaceable>.
The following C code fragment is executed by a releasing thread:
</Para>
<InformalExample>
<Para><ProgramListing>pthread_mutex_lock (m);
/* Change shared variables to allow */
/* another thread to proceed */

pthread_mutex_unlock (m);	&lt;---- <Replaceable>Point A</Replaceable> 
pthread_cond_signal (cv);	&lt;---- <Replaceable>Statement 1</Replaceable>
</ProgramListing></Para>
</InformalExample>
<Para><?sml-need 7>The following C code fragment is executed by a potentially blocking thread:
</Para>
<InformalExample>
<Para><ProgramListing>pthread_mutex_lock (m);
while (!predicate ... 
	pthread_cond_wait (cv, m);

pthread_mutex_unlock (m);
</ProgramListing></Para>
</InformalExample>
<Note>
<Para>It is possible for a potentially blocking thread to be running at
<Symbol Role="Variable">Point A</Symbol> while another thread is interrupted.  The potentially blocking
thread can then see the predicate true and therefore not become blocked
on the condition variable.
</Para>
</Note>
<Para><IndexTerm Id="DCEADG.THRPR.indx.79">
<Primary>deleting</Primary>
<Secondary>condition variables</Secondary>
</IndexTerm>Signaling a condition variable without first locking a mutex is not a
problem.  However, if the released thread deletes the condition variable 
without any further
synchronization at <Symbol Role="Variable">Point A</Symbol>, then the releasing thread will fail when 
it attempts to execute <Symbol Role="Variable">Statement 1</Symbol> because the condition variable no 
longer exists.
</Para>
<Para>This problem occurs when the releasing thread is a worker thread and the
waiting thread is the boss thread, and the last worker thread tells the boss
thread to delete the variables that are being shared by boss and worker.
</Para>
<Para>The following C code fragment shows the <Replaceable>recommended</Replaceable> coding for 
signaling a condition variable while the mutex is locked:
</Para>
<InformalExample>
<Para><ProgramListing>pthread_mutex_lock (m); 
/* Change shared variables to allow */
/* some other thread to proceed */

pthread_cond_signal (cv);   &lt;---- <Replaceable>Statement 1</Replaceable>
pthread_mutex_unlock (m);
</ProgramListing></Para>
</InformalExample>
</Sect1>
</Chapter>
<!--+ 11/27/96 19:53:47
    | tagMorph:  $Id: 3_programming.sgm,v 1.1.2.8 1996/12/14 20:23:54 wardr Exp $
    | tagMorph library:  $Id: 3_programming.sgm,v 1.1.2.8 1996/12/14 20:23:54 wardr Exp $
    | sml-to-docbook:  1.25
    +-->
